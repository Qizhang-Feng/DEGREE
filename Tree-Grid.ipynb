{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd091438d8f4a01555b9299b97aac0128b6577d442ff62949df0a9ad47e58fd79db",
   "display_name": "Python 3.7.7 64-bit ('graph': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from Extractor import Extractor\n",
    "from scipy.sparse import coo_matrix,csr_matrix\n",
    "#import tensorflow as tf\n",
    "import torch\n",
    "from utils import *\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "from model import *\n",
    "from train import *\n",
    "\n",
    "from explain import *\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import sys\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "dataset_name = 'syn3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "1 <  float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree_Cycles_Dataset(Dataset):\n",
    "    def __init__(self, root, transform = None, pre_transform = None, subgraph = False, remap=False):\n",
    "        super(Tree_Cycles_Dataset, self).__init__(root, transform, pre_transform)\n",
    "        self.root = root\n",
    "        self.subgraph = subgraph\n",
    "        self.remap = remap\n",
    "        \n",
    "\n",
    "        with open(os.path.join(self.root, 'syn4.pkl'), 'rb') as fin:\n",
    "            self.adj, self.features, self.y_train, self.y_val, self.y_test, self.train_mask, self.val_mask, self.test_mask, self.edge_label_matrix  = pkl.load(fin)\n",
    "        self.hops = 3\n",
    "        self.all_label = np.logical_or(self.y_train,np.logical_or(self.y_val,self.y_test))\n",
    "        self.single_label = np.argmax(self.all_label,axis=-1)\n",
    "        self.allnodes = [i for i in range(self.single_label.shape[0]) if self.single_label[i] ==1]\n",
    "        self.csr_adj = csr_matrix(self.adj)\n",
    "        self.extractor = Extractor(self.csr_adj,self.features,self.edge_label_matrix,self.all_label,self.hops)            \n",
    "    @property\n",
    "    def num_features(self):\n",
    "        return 10\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return 2\n",
    "\n",
    "    def get_subgraph(self, idx):\n",
    "        #if self.subgraph:\n",
    "        idx = self.allnodes[idx] if self.remap else idx\n",
    "        sub_adj,sub_feature, sub_label,sub_edge_label_matrix = dataset.extractor.subgraph(idx)\n",
    "        return sub_adj,sub_feature, sub_label,sub_edge_label_matrix\n",
    "        #else:\n",
    "        #    return None\n",
    "    def len(self):\n",
    "        if self.subgraph:\n",
    "            if not self.remap:\n",
    "                return len(self.single_label)\n",
    "            return len(self.allnodes)\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    def get(self, idx):\n",
    "        if self.subgraph:\n",
    "            if self.remap:\n",
    "                idx = self.allnodes[idx]\n",
    "            sub_adj,sub_feature, sub_label,sub_edge_label_matrix = self.extractor.subgraph(idx)\n",
    "            edge_index = torch.tensor(preprocess_adj(sub_adj)[0].T, dtype = torch.long)\n",
    "            x = torch.tensor(sub_feature).float()\n",
    "            y = torch.argmax(torch.tensor(sub_label, dtype = torch.int32), dim=-1)\n",
    "            data = Data(edge_index = edge_index, x = x, y = y)\n",
    "        else:\n",
    "\n",
    "            edge_index = torch.tensor(preprocess_adj(self.adj)[0].T, dtype = torch.long)\n",
    "            x = torch.tensor(self.features).float()\n",
    "            y = torch.argmax(torch.tensor(np.logical_or(self.y_train,np.logical_or(self.y_val,self.y_test)), dtype = torch.int32), dim=-1)\n",
    "            data = Data(edge_index = edge_index, x = x, y = y)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BA_Shape_Dataset(Dataset):\n",
    "    def __init__(self, root, name, setting=1, hops=3, transform = None, pre_transform = None, subgraph = False, remap=False):\n",
    "        super(BA_Shape_Dataset, self).__init__(root, transform, pre_transform)\n",
    "        self.root = root\n",
    "        self.subgraph = subgraph\n",
    "        self.remap = remap\n",
    "        self.name = name\n",
    "        self.setting =setting\n",
    "        with open(os.path.join(self.root, name + '.pkl'), 'rb') as fin:\n",
    "            self.adj, self.features, self.y_train, self.y_val, self.y_test, self.train_mask, self.val_mask, self.test_mask, self.edge_label_matrix  = pkl.load(fin)\n",
    "        self.hops = hops\n",
    "\n",
    "        self.all_label = np.logical_or(self.y_train,np.logical_or(self.y_val,self.y_test))\n",
    "        self.single_label = np.argmax(self.all_label,axis=-1)\n",
    "        #self.allnodes = [i for i in range(self.single_label.shape[0]) if self.single_label[i] != 0] #[i for i in range(400,700,5)]\n",
    "        self.csr_adj = csr_matrix(self.adj)\n",
    "        self.extractor = Extractor(self.csr_adj,self.features,self.edge_label_matrix,self.all_label,self.hops)            \n",
    "    @property\n",
    "    def num_features(self):\n",
    "        return 10\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return self.all_label.shape[1]\n",
    "\n",
    "    @property \n",
    "    def allnodes(self):\n",
    "        if self.setting==1:\n",
    "            if self.name=='syn3':\n",
    "                allnodes = [i for i in range(511,871,6)]\n",
    "            elif self.name=='syn4':\n",
    "                allnodes = [i for i in range(511,800,1)]\n",
    "            else:\n",
    "                allnodes = [i for i in range(400,700,5)] # setting from their original paper\n",
    "        elif self.setting==2:\n",
    "            allnodes = [i for i in range(self.single_label.shape[0]) if self.single_label[i] ==1]\n",
    "        elif self.setting==3:\n",
    "            if self.name == 'syn2':\n",
    "                allnodes = [i for i in range(self.single_label.shape[0]) if self.single_label[i] != 0 and self.single_label[i] != 4]\n",
    "            else:\n",
    "                allnodes = [i for i in range(self.single_label.shape[0]) if self.single_label[i] != 0]\n",
    "        return allnodes\n",
    "\n",
    "    def set_hops(self, hops=3):\n",
    "        self.hops = hops\n",
    "        self.extractor = Extractor(self.csr_adj,self.features,self.edge_label_matrix,self.all_label,self.hops)  \n",
    "\n",
    "    def get_subgraph(self, idx):\n",
    "        #if self.subgraph:\n",
    "        idx = self.allnodes[idx] if self.remap else idx\n",
    "        sub_adj,sub_feature, sub_label,sub_edge_label_matrix = dataset.extractor.subgraph(idx)\n",
    "        return sub_adj,sub_feature, sub_label,sub_edge_label_matrix\n",
    "        #else:\n",
    "        #    return None\n",
    "    def len(self):\n",
    "        if self.subgraph:\n",
    "            if not self.remap:\n",
    "                return len(self.single_label)\n",
    "            return len(self.allnodes)\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    def get(self, idx):\n",
    "        if self.subgraph:\n",
    "            if self.remap:\n",
    "                idx = self.allnodes[idx]\n",
    "            sub_adj,sub_feature, sub_label,sub_edge_label_matrix = self.extractor.subgraph(idx)\n",
    "            edge_index = torch.tensor(preprocess_adj(sub_adj)[0].T, dtype = torch.long)\n",
    "            x = torch.tensor(sub_feature).float()\n",
    "            y = torch.argmax(torch.tensor(sub_label, dtype = torch.int32), dim=-1)\n",
    "            data = Data(edge_index = edge_index, x = x, y = y)\n",
    "        else:\n",
    "\n",
    "            edge_index = torch.tensor(preprocess_adj(self.adj)[0].T, dtype = torch.long)\n",
    "            x = torch.tensor(self.features).float()\n",
    "            y = torch.argmax(torch.tensor(np.logical_or(self.y_train,np.logical_or(self.y_val,self.y_test)), dtype = torch.int32), dim=-1)\n",
    "            data = Data(edge_index = edge_index, x = x, y = y)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATTGCN_Node(torch.nn.Module):\n",
    "    def __init__(self, dataset, num_layers, hidden, num_features = None):\n",
    "        super(ATTGCN_Node, self).__init__()\n",
    "        num_features = dataset.num_features if num_features is None else num_features\n",
    "        \n",
    "        self.conv1 = CD_GCNConv(num_features, hidden)\n",
    "       \n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for i in range(num_layers - 1):\n",
    "            self.convs.append(CD_GATConv(in_channels = hidden, out_channels = (int)(hidden/1), heads=1))\n",
    "        \n",
    "        self.lin1 = CD_Linear(hidden, hidden)\n",
    "        \n",
    "        self.lin2 = CD_Linear(hidden, dataset.num_classes)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        self.lin1.reset_parameters()\n",
    "        self.lin2.reset_parameters()\n",
    "\n",
    "    def forward(self, data, CD_explain: bool = False, mask_index = None):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        if CD_explain:\n",
    "            x = mask_x(x, mask_index)\n",
    "        x = CD_relu(self.conv1(x, edge_index))\n",
    "        for conv in self.convs:\n",
    "            x = CD_relu(conv(x, edge_index))\n",
    "        #x = CD_global_max_pool(x, batch)\n",
    "        #x = CD_feature_max_pool(x, batch)\n",
    "        #print(x.shape)\n",
    "        x = CD_relu(self.lin1(x))\n",
    "        #x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        if CD_explain:\n",
    "            return x\n",
    "        else:\n",
    "            return F.log_softmax(x, dim=-1)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "explainer\n"
     ]
    }
   ],
   "source": [
    "dataset = Tree_Cycles_Dataset(root = './dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "explainer\n"
     ]
    }
   ],
   "source": [
    "dataset = BA_Shape_Dataset(root = './dataset', name = 'syn4', setting = 3, hops=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_model = GCN_Node(dataset, 3, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "prepare dataloader\n",
      "done\n",
      "Epoch:  0 Avg loss:  0.7022877 ; acc:  0.4137308 ; epoch time:  0.3391761779785156\n",
      "eval test...\n",
      "test acc:  0.42741933\n",
      "test loss:  0.70103496\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  1 Avg loss:  0.69101644 ; acc:  0.5862692 ; epoch time:  0.34851765632629395\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6909778\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  2 Avg loss:  0.683832 ; acc:  0.5862692 ; epoch time:  0.3452157974243164\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6847662\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  3 Avg loss:  0.6789818 ; acc:  0.5862692 ; epoch time:  0.3417525291442871\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.68095934\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  4 Avg loss:  0.6764449 ; acc:  0.5862692 ; epoch time:  0.31671619415283203\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6795286\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  5 Avg loss:  0.67687815 ; acc:  0.5862692 ; epoch time:  0.3274970054626465\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.68111384\n",
      "\n",
      "\n",
      "Epoch:  6 Avg loss:  0.67921513 ; acc:  0.5862692 ; epoch time:  0.3191375732421875\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6842813\n",
      "\n",
      "\n",
      "Epoch:  7 Avg loss:  0.6800203 ; acc:  0.5862692 ; epoch time:  0.3315892219543457\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6852869\n",
      "\n",
      "\n",
      "Epoch:  8 Avg loss:  0.6790093 ; acc:  0.5862692 ; epoch time:  0.3285214900970459\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.68402976\n",
      "\n",
      "\n",
      "Epoch:  9 Avg loss:  0.6775087 ; acc:  0.5862692 ; epoch time:  0.297562837600708\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6820549\n",
      "\n",
      "\n",
      "Epoch:  10 Avg loss:  0.6765262 ; acc:  0.5862692 ; epoch time:  0.35698699951171875\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.68052775\n",
      "\n",
      "\n",
      "Epoch:  11 Avg loss:  0.67629415 ; acc:  0.5862692 ; epoch time:  0.32003307342529297\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67977214\n",
      "\n",
      "\n",
      "Epoch:  12 Avg loss:  0.67661864 ; acc:  0.5862692 ; epoch time:  0.32985448837280273\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6796606\n",
      "\n",
      "\n",
      "Epoch:  13 Avg loss:  0.67713463 ; acc:  0.5862692 ; epoch time:  0.3424363136291504\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67986417\n",
      "\n",
      "\n",
      "Epoch:  14 Avg loss:  0.6775587 ; acc:  0.5862692 ; epoch time:  0.3291890621185303\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6801086\n",
      "\n",
      "\n",
      "Epoch:  15 Avg loss:  0.67766255 ; acc:  0.5862692 ; epoch time:  0.33684277534484863\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6801695\n",
      "\n",
      "\n",
      "Epoch:  16 Avg loss:  0.67747176 ; acc:  0.5862692 ; epoch time:  0.32449960708618164\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.68005306\n",
      "\n",
      "\n",
      "Epoch:  17 Avg loss:  0.67712545 ; acc:  0.5862692 ; epoch time:  0.323375940322876\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6798678\n",
      "\n",
      "\n",
      "Epoch:  18 Avg loss:  0.67672217 ; acc:  0.5862692 ; epoch time:  0.3273508548736572\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6796985\n",
      "\n",
      "\n",
      "Epoch:  19 Avg loss:  0.67641586 ; acc:  0.5862692 ; epoch time:  0.34827327728271484\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6796718\n",
      "\n",
      "\n",
      "Epoch:  20 Avg loss:  0.67630416 ; acc:  0.5862692 ; epoch time:  0.34104490280151367\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.679854\n",
      "\n",
      "\n",
      "Epoch:  21 Avg loss:  0.676378 ; acc:  0.5862692 ; epoch time:  0.34641194343566895\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6802053\n",
      "\n",
      "\n",
      "Epoch:  22 Avg loss:  0.676566 ; acc:  0.5862692 ; epoch time:  0.3275785446166992\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6806169\n",
      "\n",
      "\n",
      "Epoch:  23 Avg loss:  0.6767397 ; acc:  0.5862692 ; epoch time:  0.3152956962585449\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6809274\n",
      "\n",
      "\n",
      "Epoch:  24 Avg loss:  0.67679644 ; acc:  0.5862692 ; epoch time:  0.36495494842529297\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6810159\n",
      "\n",
      "\n",
      "Epoch:  25 Avg loss:  0.6767034 ; acc:  0.5862692 ; epoch time:  0.33303403854370117\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6808547\n",
      "\n",
      "\n",
      "Epoch:  26 Avg loss:  0.67651564 ; acc:  0.5862692 ; epoch time:  0.3317294120788574\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6805212\n",
      "\n",
      "\n",
      "Epoch:  27 Avg loss:  0.6763337 ; acc:  0.5862692 ; epoch time:  0.3294179439544678\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6801471\n",
      "\n",
      "\n",
      "Epoch:  28 Avg loss:  0.6762456 ; acc:  0.5862692 ; epoch time:  0.30583786964416504\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6798517\n",
      "\n",
      "\n",
      "Epoch:  29 Avg loss:  0.67625636 ; acc:  0.5862692 ; epoch time:  0.3289780616760254\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67966694\n",
      "\n",
      "\n",
      "Epoch:  30 Avg loss:  0.67632926 ; acc:  0.5862692 ; epoch time:  0.36600828170776367\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6795787\n",
      "\n",
      "\n",
      "Epoch:  31 Avg loss:  0.67639685 ; acc:  0.5862692 ; epoch time:  0.31177759170532227\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6795349\n",
      "\n",
      "\n",
      "Epoch:  32 Avg loss:  0.67642903 ; acc:  0.5862692 ; epoch time:  0.31238865852355957\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67951065\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  33 Avg loss:  0.67640173 ; acc:  0.5862692 ; epoch time:  0.31566500663757324\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67948294\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  34 Avg loss:  0.6763475 ; acc:  0.5862692 ; epoch time:  0.335308313369751\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6794763\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  35 Avg loss:  0.676261 ; acc:  0.5862692 ; epoch time:  0.33705830574035645\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6794819\n",
      "\n",
      "\n",
      "Epoch:  36 Avg loss:  0.67618257 ; acc:  0.5862692 ; epoch time:  0.3345324993133545\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67952687\n",
      "\n",
      "\n",
      "Epoch:  37 Avg loss:  0.6761406 ; acc:  0.5862692 ; epoch time:  0.32874321937561035\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67961776\n",
      "\n",
      "\n",
      "Epoch:  38 Avg loss:  0.67615557 ; acc:  0.5862692 ; epoch time:  0.3383059501647949\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6797511\n",
      "\n",
      "\n",
      "Epoch:  39 Avg loss:  0.6761872 ; acc:  0.5862692 ; epoch time:  0.3468649387359619\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6798685\n",
      "\n",
      "\n",
      "Epoch:  40 Avg loss:  0.67620367 ; acc:  0.5862692 ; epoch time:  0.3193202018737793\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6799239\n",
      "\n",
      "\n",
      "Epoch:  41 Avg loss:  0.6761828 ; acc:  0.5862692 ; epoch time:  0.32916903495788574\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67989016\n",
      "\n",
      "\n",
      "Epoch:  42 Avg loss:  0.67615443 ; acc:  0.5862692 ; epoch time:  0.3292207717895508\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6797981\n",
      "\n",
      "\n",
      "Epoch:  43 Avg loss:  0.67609566 ; acc:  0.5862692 ; epoch time:  0.34863805770874023\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6796474\n",
      "\n",
      "\n",
      "Epoch:  44 Avg loss:  0.67604995 ; acc:  0.5862692 ; epoch time:  0.3327631950378418\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6794972\n",
      "\n",
      "\n",
      "Epoch:  45 Avg loss:  0.6760402 ; acc:  0.5862692 ; epoch time:  0.3466475009918213\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67938066\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  46 Avg loss:  0.67604345 ; acc:  0.5862692 ; epoch time:  0.325925350189209\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6792903\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  47 Avg loss:  0.6760478 ; acc:  0.5862692 ; epoch time:  0.35361480712890625\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67922854\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  48 Avg loss:  0.67603946 ; acc:  0.5862692 ; epoch time:  0.33634352684020996\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67918724\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  49 Avg loss:  0.67600787 ; acc:  0.5862692 ; epoch time:  0.305448055267334\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67915326\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  50 Avg loss:  0.67597634 ; acc:  0.5862692 ; epoch time:  0.311725378036499\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6791468\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  51 Avg loss:  0.675928 ; acc:  0.5862692 ; epoch time:  0.325214147567749\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6791557\n",
      "\n",
      "\n",
      "Epoch:  52 Avg loss:  0.6759059 ; acc:  0.5862692 ; epoch time:  0.33107995986938477\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6791952\n",
      "\n",
      "\n",
      "Epoch:  53 Avg loss:  0.67589563 ; acc:  0.5862692 ; epoch time:  0.3345944881439209\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6792369\n",
      "\n",
      "\n",
      "Epoch:  54 Avg loss:  0.67590207 ; acc:  0.5862692 ; epoch time:  0.33172154426574707\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6792893\n",
      "\n",
      "\n",
      "Epoch:  55 Avg loss:  0.6758984 ; acc:  0.5862692 ; epoch time:  0.35985398292541504\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67929727\n",
      "\n",
      "\n",
      "Epoch:  56 Avg loss:  0.67587465 ; acc:  0.5862692 ; epoch time:  0.31630873680114746\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6792486\n",
      "\n",
      "\n",
      "Epoch:  57 Avg loss:  0.6758397 ; acc:  0.5862692 ; epoch time:  0.3196125030517578\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67915976\n",
      "\n",
      "\n",
      "Epoch:  58 Avg loss:  0.67579126 ; acc:  0.5862692 ; epoch time:  0.3457934856414795\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6790331\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  59 Avg loss:  0.67582107 ; acc:  0.5862692 ; epoch time:  0.34122729301452637\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6789639\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  60 Avg loss:  0.6758134 ; acc:  0.5862692 ; epoch time:  0.36020994186401367\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67889035\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  61 Avg loss:  0.67579055 ; acc:  0.5862692 ; epoch time:  0.32802629470825195\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6788262\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  62 Avg loss:  0.6757171 ; acc:  0.5862692 ; epoch time:  0.3261451721191406\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6787598\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  63 Avg loss:  0.6757071 ; acc:  0.5862692 ; epoch time:  0.3132359981536865\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6787568\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  64 Avg loss:  0.67567897 ; acc:  0.5862692 ; epoch time:  0.30706334114074707\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6787439\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  65 Avg loss:  0.6756378 ; acc:  0.5862692 ; epoch time:  0.330028772354126\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6787186\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  66 Avg loss:  0.67564154 ; acc:  0.5862692 ; epoch time:  0.31186723709106445\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6787352\n",
      "\n",
      "\n",
      "Epoch:  67 Avg loss:  0.675618 ; acc:  0.5862692 ; epoch time:  0.3349637985229492\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67874616\n",
      "\n",
      "\n",
      "Epoch:  68 Avg loss:  0.67560285 ; acc:  0.5862692 ; epoch time:  0.3161184787750244\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67873806\n",
      "\n",
      "\n",
      "Epoch:  69 Avg loss:  0.67558 ; acc:  0.5862692 ; epoch time:  0.3485755920410156\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6786897\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  70 Avg loss:  0.6755482 ; acc:  0.5862692 ; epoch time:  0.347247838973999\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67860955\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  71 Avg loss:  0.6755117 ; acc:  0.5862692 ; epoch time:  0.3461439609527588\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67851686\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  72 Avg loss:  0.67548627 ; acc:  0.5862692 ; epoch time:  0.3202023506164551\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67842275\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  73 Avg loss:  0.6754571 ; acc:  0.5862692 ; epoch time:  0.334491491317749\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6783665\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  74 Avg loss:  0.6754368 ; acc:  0.5862692 ; epoch time:  0.31073665618896484\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6783158\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  75 Avg loss:  0.67538476 ; acc:  0.5862692 ; epoch time:  0.3142409324645996\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6782486\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  76 Avg loss:  0.67540556 ; acc:  0.5862692 ; epoch time:  0.29518675804138184\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67824227\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  77 Avg loss:  0.67532635 ; acc:  0.5862692 ; epoch time:  0.3089005947113037\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67819047\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  78 Avg loss:  0.67542666 ; acc:  0.5862692 ; epoch time:  0.35451173782348633\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67836785\n",
      "\n",
      "\n",
      "Epoch:  79 Avg loss:  0.6754084 ; acc:  0.5862692 ; epoch time:  0.3358633518218994\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67834073\n",
      "\n",
      "\n",
      "Epoch:  80 Avg loss:  0.67525005 ; acc:  0.5862692 ; epoch time:  0.3279132843017578\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67810476\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  81 Avg loss:  0.6752969 ; acc:  0.5862692 ; epoch time:  0.32813191413879395\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6780414\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  82 Avg loss:  0.675311 ; acc:  0.5862692 ; epoch time:  0.3419468402862549\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67798835\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  83 Avg loss:  0.67528397 ; acc:  0.5862692 ; epoch time:  0.31894612312316895\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67791504\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  84 Avg loss:  0.67526984 ; acc:  0.5862692 ; epoch time:  0.3202066421508789\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6779058\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  85 Avg loss:  0.6752524 ; acc:  0.5862692 ; epoch time:  0.33829426765441895\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67788553\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  86 Avg loss:  0.67519116 ; acc:  0.5862692 ; epoch time:  0.3190445899963379\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.677803\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  87 Avg loss:  0.67521685 ; acc:  0.5862692 ; epoch time:  0.3463468551635742\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6777836\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  88 Avg loss:  0.67519116 ; acc:  0.5862692 ; epoch time:  0.3325073719024658\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67773104\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  89 Avg loss:  0.6751654 ; acc:  0.5862692 ; epoch time:  0.34004759788513184\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6776808\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  90 Avg loss:  0.6751394 ; acc:  0.5862692 ; epoch time:  0.3312053680419922\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.677632\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  91 Avg loss:  0.6751134 ; acc:  0.5862692 ; epoch time:  0.3295094966888428\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6775834\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  92 Avg loss:  0.67508703 ; acc:  0.5862692 ; epoch time:  0.322279691696167\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.677533\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  93 Avg loss:  0.67506063 ; acc:  0.5862692 ; epoch time:  0.3231203556060791\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6774796\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  94 Avg loss:  0.6750341 ; acc:  0.5862692 ; epoch time:  0.3324713706970215\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6774236\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  95 Avg loss:  0.67500734 ; acc:  0.5862692 ; epoch time:  0.33050966262817383\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6773652\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  96 Avg loss:  0.67498034 ; acc:  0.5862692 ; epoch time:  0.3280220031738281\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6773067\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  97 Avg loss:  0.6749532 ; acc:  0.5862692 ; epoch time:  0.32676076889038086\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6772492\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  98 Avg loss:  0.674926 ; acc:  0.5862692 ; epoch time:  0.35323214530944824\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67719346\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  99 Avg loss:  0.67489827 ; acc:  0.5862692 ; epoch time:  0.34251880645751953\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6771389\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  100 Avg loss:  0.67487055 ; acc:  0.5862692 ; epoch time:  0.36204028129577637\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6770839\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  101 Avg loss:  0.67484266 ; acc:  0.5862692 ; epoch time:  0.35307860374450684\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6770274\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  102 Avg loss:  0.6748144 ; acc:  0.5862692 ; epoch time:  0.3578925132751465\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67696804\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  103 Avg loss:  0.6747859 ; acc:  0.5862692 ; epoch time:  0.3664827346801758\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67690605\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  104 Avg loss:  0.67475724 ; acc:  0.5862692 ; epoch time:  0.3512692451477051\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.676843\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  105 Avg loss:  0.6747284 ; acc:  0.5862692 ; epoch time:  0.33296656608581543\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67678005\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  106 Avg loss:  0.67469907 ; acc:  0.5862692 ; epoch time:  0.3352079391479492\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6767181\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  107 Avg loss:  0.67466974 ; acc:  0.5862692 ; epoch time:  0.32060813903808594\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6766572\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  108 Avg loss:  0.67464 ; acc:  0.5862692 ; epoch time:  0.36623501777648926\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.676596\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  109 Avg loss:  0.67460996 ; acc:  0.5862692 ; epoch time:  0.327315092086792\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6765329\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  110 Avg loss:  0.67457974 ; acc:  0.5862692 ; epoch time:  0.3237605094909668\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6764671\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  111 Avg loss:  0.6745492 ; acc:  0.5862692 ; epoch time:  0.3235433101654053\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6763994\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  112 Avg loss:  0.6745185 ; acc:  0.5862692 ; epoch time:  0.34055161476135254\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6763308\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  113 Avg loss:  0.6744876 ; acc:  0.5862692 ; epoch time:  0.30771875381469727\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67626256\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  114 Avg loss:  0.6744564 ; acc:  0.5862692 ; epoch time:  0.3301713466644287\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.676195\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  115 Avg loss:  0.67442495 ; acc:  0.5862692 ; epoch time:  0.3412811756134033\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67612773\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  116 Avg loss:  0.67439306 ; acc:  0.5862692 ; epoch time:  0.3168931007385254\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6760592\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  117 Avg loss:  0.674361 ; acc:  0.5862692 ; epoch time:  0.3219337463378906\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6759874\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  118 Avg loss:  0.6743286 ; acc:  0.5862692 ; epoch time:  0.3500528335571289\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6759132\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  119 Avg loss:  0.67429614 ; acc:  0.5862692 ; epoch time:  0.35381007194519043\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67583835\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  120 Avg loss:  0.6742633 ; acc:  0.5862692 ; epoch time:  0.3516676425933838\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6757639\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  121 Avg loss:  0.6742301 ; acc:  0.5862692 ; epoch time:  0.3494560718536377\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6756902\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  122 Avg loss:  0.67419684 ; acc:  0.5862692 ; epoch time:  0.3377976417541504\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6756158\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  123 Avg loss:  0.6741632 ; acc:  0.5862692 ; epoch time:  0.31052422523498535\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6755398\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  124 Avg loss:  0.67412937 ; acc:  0.5862692 ; epoch time:  0.34449124336242676\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6754607\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  125 Avg loss:  0.6740953 ; acc:  0.5862692 ; epoch time:  0.3442075252532959\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67538005\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  126 Avg loss:  0.67406094 ; acc:  0.5862692 ; epoch time:  0.32174038887023926\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6752992\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  127 Avg loss:  0.6740263 ; acc:  0.5862692 ; epoch time:  0.36359500885009766\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67521906\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  128 Avg loss:  0.6739916 ; acc:  0.5862692 ; epoch time:  0.3761148452758789\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67513853\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  129 Avg loss:  0.67395645 ; acc:  0.5862692 ; epoch time:  0.3427276611328125\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67505646\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  130 Avg loss:  0.67392135 ; acc:  0.5862692 ; epoch time:  0.33234548568725586\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6749717\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  131 Avg loss:  0.67388594 ; acc:  0.5862692 ; epoch time:  0.37821340560913086\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67488515\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  132 Avg loss:  0.6738504 ; acc:  0.5862692 ; epoch time:  0.3277108669281006\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6747984\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  133 Avg loss:  0.6738147 ; acc:  0.5862692 ; epoch time:  0.3418619632720947\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67471206\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  134 Avg loss:  0.6737788 ; acc:  0.5862692 ; epoch time:  0.3265531063079834\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6746251\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  135 Avg loss:  0.67374283 ; acc:  0.5862692 ; epoch time:  0.3667113780975342\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6745356\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  136 Avg loss:  0.67370665 ; acc:  0.5862692 ; epoch time:  0.34168314933776855\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67444384\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  137 Avg loss:  0.67367053 ; acc:  0.5862692 ; epoch time:  0.35395002365112305\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67435193\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  138 Avg loss:  0.67363405 ; acc:  0.5862692 ; epoch time:  0.37923622131347656\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6742604\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  139 Avg loss:  0.67359775 ; acc:  0.5862692 ; epoch time:  0.33220791816711426\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6741682\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  140 Avg loss:  0.6735613 ; acc:  0.5862692 ; epoch time:  0.3469080924987793\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67407453\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  141 Avg loss:  0.6735248 ; acc:  0.5862692 ; epoch time:  0.35530638694763184\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67397827\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  142 Avg loss:  0.6734884 ; acc:  0.5862692 ; epoch time:  0.3248865604400635\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6738815\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  143 Avg loss:  0.6734519 ; acc:  0.5862692 ; epoch time:  0.34240293502807617\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6737848\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  144 Avg loss:  0.6734155 ; acc:  0.5862692 ; epoch time:  0.33693933486938477\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6736871\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  145 Avg loss:  0.67337924 ; acc:  0.5862692 ; epoch time:  0.33520936965942383\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6735879\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  146 Avg loss:  0.67334306 ; acc:  0.5862692 ; epoch time:  0.3855435848236084\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6734878\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  147 Avg loss:  0.67330706 ; acc:  0.5862692 ; epoch time:  0.3704676628112793\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6733876\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  148 Avg loss:  0.67327106 ; acc:  0.5862692 ; epoch time:  0.3117179870605469\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6732867\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  149 Avg loss:  0.6732355 ; acc:  0.5862692 ; epoch time:  0.33127355575561523\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67318565\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  150 Avg loss:  0.6732 ; acc:  0.5862692 ; epoch time:  0.32016491889953613\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67308307\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  151 Avg loss:  0.67316484 ; acc:  0.5862692 ; epoch time:  0.36346983909606934\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67297894\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  152 Avg loss:  0.6731299 ; acc:  0.5862692 ; epoch time:  0.35590648651123047\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6728742\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  153 Avg loss:  0.67309535 ; acc:  0.5862692 ; epoch time:  0.37061166763305664\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67277074\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  154 Avg loss:  0.67306113 ; acc:  0.5862692 ; epoch time:  0.34380674362182617\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6726672\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  155 Avg loss:  0.67302734 ; acc:  0.5862692 ; epoch time:  0.32778215408325195\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.672561\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  156 Avg loss:  0.6729941 ; acc:  0.5862692 ; epoch time:  0.3313443660736084\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6724566\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  157 Avg loss:  0.67296124 ; acc:  0.5862692 ; epoch time:  0.336284875869751\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6723518\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  158 Avg loss:  0.67292875 ; acc:  0.5862692 ; epoch time:  0.33712339401245117\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67224336\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  159 Avg loss:  0.6728972 ; acc:  0.5862692 ; epoch time:  0.3378443717956543\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.672138\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  160 Avg loss:  0.67286587 ; acc:  0.5862692 ; epoch time:  0.32277774810791016\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6720348\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  161 Avg loss:  0.67283535 ; acc:  0.5862692 ; epoch time:  0.3225841522216797\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6719271\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  162 Avg loss:  0.67280537 ; acc:  0.5862692 ; epoch time:  0.32858943939208984\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67182285\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  163 Avg loss:  0.67277616 ; acc:  0.5862692 ; epoch time:  0.32313013076782227\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6717164\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  164 Avg loss:  0.6727475 ; acc:  0.5862692 ; epoch time:  0.32587409019470215\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67161155\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  165 Avg loss:  0.6727199 ; acc:  0.5862692 ; epoch time:  0.35650181770324707\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6715112\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  166 Avg loss:  0.6726927 ; acc:  0.58717257 ; epoch time:  0.305924654006958\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6714013\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  167 Avg loss:  0.6726664 ; acc:  0.58717257 ; epoch time:  0.324113130569458\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6713008\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  168 Avg loss:  0.67264086 ; acc:  0.58717257 ; epoch time:  0.355053186416626\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6712017\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  169 Avg loss:  0.67261624 ; acc:  0.5880759 ; epoch time:  0.340440034866333\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6710939\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  170 Avg loss:  0.6725922 ; acc:  0.58897924 ; epoch time:  0.3423879146575928\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6710018\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  171 Avg loss:  0.672569 ; acc:  0.58897924 ; epoch time:  0.35928964614868164\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6708937\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  172 Avg loss:  0.6725468 ; acc:  0.58897924 ; epoch time:  0.3271937370300293\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6708003\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  173 Avg loss:  0.6725253 ; acc:  0.58897924 ; epoch time:  0.34012413024902344\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6707043\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  174 Avg loss:  0.6725046 ; acc:  0.58988255 ; epoch time:  0.34133148193359375\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6706028\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  175 Avg loss:  0.6724847 ; acc:  0.58988255 ; epoch time:  0.3104546070098877\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6705181\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  176 Avg loss:  0.6724653 ; acc:  0.58988255 ; epoch time:  0.3393707275390625\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67041373\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  177 Avg loss:  0.672447 ; acc:  0.5916893 ; epoch time:  0.37887024879455566\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6703363\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  178 Avg loss:  0.6724295 ; acc:  0.5925926 ; epoch time:  0.3294258117675781\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67023057\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  179 Avg loss:  0.67241246 ; acc:  0.5925926 ; epoch time:  0.35005640983581543\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6701701\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  180 Avg loss:  0.67239743 ; acc:  0.62601626 ; epoch time:  0.35443639755249023\n",
      "eval test...\n",
      "test acc:  0.59677416\n",
      "test loss:  0.6700362\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  181 Avg loss:  0.6723863 ; acc:  0.5925926 ; epoch time:  0.34252166748046875\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67005026\n",
      "\n",
      "\n",
      "Epoch:  182 Avg loss:  0.6723907 ; acc:  0.63414633 ; epoch time:  0.3051416873931885\n",
      "eval test...\n",
      "test acc:  0.61290324\n",
      "test loss:  0.6698032\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  183 Avg loss:  0.6724647 ; acc:  0.58988255 ; epoch time:  0.34359121322631836\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6701909\n",
      "\n",
      "\n",
      "Epoch:  184 Avg loss:  0.6728003 ; acc:  0.65130985 ; epoch time:  0.32240891456604004\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66969913\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  185 Avg loss:  0.67346936 ; acc:  0.58717257 ; epoch time:  0.3227720260620117\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6716265\n",
      "\n",
      "\n",
      "Epoch:  186 Avg loss:  0.6732187 ; acc:  0.7028004 ; epoch time:  0.33631253242492676\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.66983336\n",
      "\n",
      "\n",
      "Epoch:  187 Avg loss:  0.672318 ; acc:  0.64408314 ; epoch time:  0.33908534049987793\n",
      "eval test...\n",
      "test acc:  0.62096775\n",
      "test loss:  0.6695544\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  188 Avg loss:  0.67319685 ; acc:  0.58717257 ; epoch time:  0.31554126739501953\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6711691\n",
      "\n",
      "\n",
      "Epoch:  189 Avg loss:  0.6726673 ; acc:  0.65130985 ; epoch time:  0.35119032859802246\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6694675\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  190 Avg loss:  0.6725641 ; acc:  0.65130985 ; epoch time:  0.3249657154083252\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6694118\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  191 Avg loss:  0.6728944 ; acc:  0.58897924 ; epoch time:  0.3136131763458252\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67068815\n",
      "\n",
      "\n",
      "Epoch:  192 Avg loss:  0.672294 ; acc:  0.63143635 ; epoch time:  0.3404672145843506\n",
      "eval test...\n",
      "test acc:  0.60483867\n",
      "test loss:  0.6695699\n",
      "\n",
      "\n",
      "Epoch:  193 Avg loss:  0.67280877 ; acc:  0.6729901 ; epoch time:  0.3676106929779053\n",
      "eval test...\n",
      "test acc:  0.6612903\n",
      "test loss:  0.6694593\n",
      "\n",
      "\n",
      "Epoch:  194 Avg loss:  0.67228967 ; acc:  0.63143635 ; epoch time:  0.3139002323150635\n",
      "eval test...\n",
      "test acc:  0.60483867\n",
      "test loss:  0.6695569\n",
      "\n",
      "\n",
      "Epoch:  195 Avg loss:  0.6726674 ; acc:  0.58988255 ; epoch time:  0.32526373863220215\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.67030025\n",
      "\n",
      "\n",
      "Epoch:  196 Avg loss:  0.67235774 ; acc:  0.65130985 ; epoch time:  0.30688023567199707\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6692922\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  197 Avg loss:  0.6725029 ; acc:  0.65130985 ; epoch time:  0.338010311126709\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6692862\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  198 Avg loss:  0.67239475 ; acc:  0.5925926 ; epoch time:  0.357194185256958\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6698034\n",
      "\n",
      "\n",
      "Epoch:  199 Avg loss:  0.67237794 ; acc:  0.59349597 ; epoch time:  0.3390223979949951\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.66976327\n",
      "\n",
      "\n",
      "Epoch:  200 Avg loss:  0.6724187 ; acc:  0.65130985 ; epoch time:  0.3515009880065918\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66922873\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  201 Avg loss:  0.6723031 ; acc:  0.65130985 ; epoch time:  0.31850624084472656\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6692285\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  202 Avg loss:  0.6724153 ; acc:  0.5925926 ; epoch time:  0.33698272705078125\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6698165\n",
      "\n",
      "\n",
      "Epoch:  203 Avg loss:  0.6722508 ; acc:  0.63414633 ; epoch time:  0.3380148410797119\n",
      "eval test...\n",
      "test acc:  0.61290324\n",
      "test loss:  0.6694234\n",
      "\n",
      "\n",
      "Epoch:  204 Avg loss:  0.6723909 ; acc:  0.65130985 ; epoch time:  0.326519250869751\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6691648\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  205 Avg loss:  0.67222786 ; acc:  0.65130985 ; epoch time:  0.314211368560791\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6692538\n",
      "\n",
      "\n",
      "Epoch:  206 Avg loss:  0.67236054 ; acc:  0.60252935 ; epoch time:  0.32036447525024414\n",
      "eval test...\n",
      "test acc:  0.58064514\n",
      "test loss:  0.669681\n",
      "\n",
      "\n",
      "Epoch:  207 Avg loss:  0.67221797 ; acc:  0.65130985 ; epoch time:  0.31821179389953613\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66921777\n",
      "\n",
      "\n",
      "Epoch:  208 Avg loss:  0.67231756 ; acc:  0.65130985 ; epoch time:  0.31391382217407227\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66909665\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  209 Avg loss:  0.6722164 ; acc:  0.64408314 ; epoch time:  0.3356187343597412\n",
      "eval test...\n",
      "test acc:  0.62096775\n",
      "test loss:  0.66929895\n",
      "\n",
      "\n",
      "Epoch:  210 Avg loss:  0.67227566 ; acc:  0.63143635 ; epoch time:  0.32239341735839844\n",
      "eval test...\n",
      "test acc:  0.60483867\n",
      "test loss:  0.66947085\n",
      "\n",
      "\n",
      "Epoch:  211 Avg loss:  0.6722207 ; acc:  0.65130985 ; epoch time:  0.33783912658691406\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6690828\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  212 Avg loss:  0.67223436 ; acc:  0.65130985 ; epoch time:  0.3257725238800049\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6690446\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  213 Avg loss:  0.6722218 ; acc:  0.63414633 ; epoch time:  0.34929895401000977\n",
      "eval test...\n",
      "test acc:  0.61290324\n",
      "test loss:  0.66931576\n",
      "\n",
      "\n",
      "Epoch:  214 Avg loss:  0.6721982 ; acc:  0.64408314 ; epoch time:  0.31618618965148926\n",
      "eval test...\n",
      "test acc:  0.62096775\n",
      "test loss:  0.66923755\n",
      "\n",
      "\n",
      "Epoch:  215 Avg loss:  0.6722187 ; acc:  0.65130985 ; epoch time:  0.3438129425048828\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66898394\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  216 Avg loss:  0.6721722 ; acc:  0.65130985 ; epoch time:  0.3596048355102539\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66902894\n",
      "\n",
      "\n",
      "Epoch:  217 Avg loss:  0.67220736 ; acc:  0.63414633 ; epoch time:  0.31853652000427246\n",
      "eval test...\n",
      "test acc:  0.61290324\n",
      "test loss:  0.669257\n",
      "\n",
      "\n",
      "Epoch:  218 Avg loss:  0.6721555 ; acc:  0.65130985 ; epoch time:  0.3469362258911133\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66902846\n",
      "\n",
      "\n",
      "Epoch:  219 Avg loss:  0.6721865 ; acc:  0.65130985 ; epoch time:  0.3309462070465088\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66890764\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  220 Avg loss:  0.672148 ; acc:  0.65130985 ; epoch time:  0.3317434787750244\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6690442\n",
      "\n",
      "\n",
      "Epoch:  221 Avg loss:  0.67215997 ; acc:  0.64408314 ; epoch time:  0.33490896224975586\n",
      "eval test...\n",
      "test acc:  0.62096775\n",
      "test loss:  0.669101\n",
      "\n",
      "\n",
      "Epoch:  222 Avg loss:  0.6721452 ; acc:  0.65130985 ; epoch time:  0.3562469482421875\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.668874\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  223 Avg loss:  0.6721335 ; acc:  0.65130985 ; epoch time:  0.32006144523620605\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6688659\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  224 Avg loss:  0.6721393 ; acc:  0.65130985 ; epoch time:  0.32274317741394043\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6690281\n",
      "\n",
      "\n",
      "Epoch:  225 Avg loss:  0.67211276 ; acc:  0.65130985 ; epoch time:  0.3233656883239746\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66889644\n",
      "\n",
      "\n",
      "Epoch:  226 Avg loss:  0.6721251 ; acc:  0.65130985 ; epoch time:  0.3427298069000244\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6687753\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  227 Avg loss:  0.6721011 ; acc:  0.65130985 ; epoch time:  0.3271200656890869\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66886866\n",
      "\n",
      "\n",
      "Epoch:  228 Avg loss:  0.6721037 ; acc:  0.65130985 ; epoch time:  0.3563416004180908\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.668902\n",
      "\n",
      "\n",
      "Epoch:  229 Avg loss:  0.6720941 ; acc:  0.65130985 ; epoch time:  0.32623910903930664\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6687317\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  230 Avg loss:  0.6720813 ; acc:  0.65130985 ; epoch time:  0.30869197845458984\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6687339\n",
      "\n",
      "\n",
      "Epoch:  231 Avg loss:  0.672084 ; acc:  0.65130985 ; epoch time:  0.33028101921081543\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66883737\n",
      "\n",
      "\n",
      "Epoch:  232 Avg loss:  0.672065 ; acc:  0.65130985 ; epoch time:  0.3286442756652832\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6687104\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  233 Avg loss:  0.67206585 ; acc:  0.65130985 ; epoch time:  0.3279538154602051\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6686418\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  234 Avg loss:  0.6720551 ; acc:  0.65130985 ; epoch time:  0.31460118293762207\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6687312\n",
      "\n",
      "\n",
      "Epoch:  235 Avg loss:  0.6720447 ; acc:  0.65130985 ; epoch time:  0.339569091796875\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6686838\n",
      "\n",
      "\n",
      "Epoch:  236 Avg loss:  0.6720434 ; acc:  0.65130985 ; epoch time:  0.34536290168762207\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6685747\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  237 Avg loss:  0.6720288 ; acc:  0.65130985 ; epoch time:  0.36357712745666504\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6686241\n",
      "\n",
      "\n",
      "Epoch:  238 Avg loss:  0.6720247 ; acc:  0.65130985 ; epoch time:  0.32907533645629883\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66863555\n",
      "\n",
      "\n",
      "Epoch:  239 Avg loss:  0.6720172 ; acc:  0.65130985 ; epoch time:  0.3036990165710449\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6685179\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  240 Avg loss:  0.6720052 ; acc:  0.65130985 ; epoch time:  0.3312411308288574\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6685309\n",
      "\n",
      "\n",
      "Epoch:  241 Avg loss:  0.6720016 ; acc:  0.65130985 ; epoch time:  0.3251824378967285\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66856897\n",
      "\n",
      "\n",
      "Epoch:  242 Avg loss:  0.67199093 ; acc:  0.65130985 ; epoch time:  0.3381998538970947\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6684619\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  243 Avg loss:  0.6719815 ; acc:  0.65130985 ; epoch time:  0.3430442810058594\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66845024\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  244 Avg loss:  0.67197615 ; acc:  0.65130985 ; epoch time:  0.32170677185058594\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6684936\n",
      "\n",
      "\n",
      "Epoch:  245 Avg loss:  0.67196494 ; acc:  0.65130985 ; epoch time:  0.3719639778137207\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6684009\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  246 Avg loss:  0.6719564 ; acc:  0.65130985 ; epoch time:  0.35080742835998535\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6683773\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  247 Avg loss:  0.6719496 ; acc:  0.65130985 ; epoch time:  0.3434011936187744\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6684164\n",
      "\n",
      "\n",
      "Epoch:  248 Avg loss:  0.67193854 ; acc:  0.65130985 ; epoch time:  0.34282898902893066\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6683334\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  249 Avg loss:  0.6719296 ; acc:  0.65130985 ; epoch time:  0.3294954299926758\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6683084\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  250 Avg loss:  0.6719217 ; acc:  0.65130985 ; epoch time:  0.31243085861206055\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66833925\n",
      "\n",
      "\n",
      "Epoch:  251 Avg loss:  0.67191046 ; acc:  0.65130985 ; epoch time:  0.32425570487976074\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66826886\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  252 Avg loss:  0.6719007 ; acc:  0.65130985 ; epoch time:  0.35735464096069336\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6682416\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  253 Avg loss:  0.6718902 ; acc:  0.65130985 ; epoch time:  0.32843446731567383\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66826165\n",
      "\n",
      "\n",
      "Epoch:  254 Avg loss:  0.67184734 ; acc:  0.65130985 ; epoch time:  0.36428165435791016\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6682274\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  255 Avg loss:  0.6715197 ; acc:  0.65130985 ; epoch time:  0.3785696029663086\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66823554\n",
      "\n",
      "\n",
      "Epoch:  256 Avg loss:  0.6704948 ; acc:  0.60252935 ; epoch time:  0.35865259170532227\n",
      "eval test...\n",
      "test acc:  0.58064514\n",
      "test loss:  0.6679293\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  257 Avg loss:  0.67064726 ; acc:  0.67479676 ; epoch time:  0.3426191806793213\n",
      "eval test...\n",
      "test acc:  0.6612903\n",
      "test loss:  0.6672239\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  258 Avg loss:  0.6702562 ; acc:  0.65130985 ; epoch time:  0.37178850173950195\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6673305\n",
      "\n",
      "\n",
      "Epoch:  259 Avg loss:  0.67094994 ; acc:  0.58988255 ; epoch time:  0.3427906036376953\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6690226\n",
      "\n",
      "\n",
      "Epoch:  260 Avg loss:  0.66906655 ; acc:  0.65130985 ; epoch time:  0.3506646156311035\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6663868\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  261 Avg loss:  0.66916364 ; acc:  0.67479676 ; epoch time:  0.3451387882232666\n",
      "eval test...\n",
      "test acc:  0.6612903\n",
      "test loss:  0.6661732\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  262 Avg loss:  0.66970956 ; acc:  0.60794944 ; epoch time:  0.3724665641784668\n",
      "eval test...\n",
      "test acc:  0.58870965\n",
      "test loss:  0.66750854\n",
      "\n",
      "\n",
      "Epoch:  263 Avg loss:  0.6710678 ; acc:  0.65130985 ; epoch time:  0.34052157402038574\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6679705\n",
      "\n",
      "\n",
      "Epoch:  264 Avg loss:  0.6708734 ; acc:  0.63414633 ; epoch time:  0.35772228240966797\n",
      "eval test...\n",
      "test acc:  0.61290324\n",
      "test loss:  0.6681928\n",
      "\n",
      "\n",
      "Epoch:  265 Avg loss:  0.67103356 ; acc:  0.58717257 ; epoch time:  0.35471105575561523\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6694372\n",
      "\n",
      "\n",
      "Epoch:  266 Avg loss:  0.6697148 ; acc:  0.67479676 ; epoch time:  0.3435807228088379\n",
      "eval test...\n",
      "test acc:  0.6612903\n",
      "test loss:  0.66656774\n",
      "\n",
      "\n",
      "Epoch:  267 Avg loss:  0.6712587 ; acc:  0.75790423 ; epoch time:  0.35714054107666016\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6674829\n",
      "\n",
      "\n",
      "Epoch:  268 Avg loss:  0.66971475 ; acc:  0.58988255 ; epoch time:  0.3639545440673828\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.66789514\n",
      "\n",
      "\n",
      "Epoch:  269 Avg loss:  0.6706524 ; acc:  0.58717257 ; epoch time:  0.3171548843383789\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6691878\n",
      "\n",
      "\n",
      "Epoch:  270 Avg loss:  0.6705859 ; acc:  0.75790423 ; epoch time:  0.3498830795288086\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6665556\n",
      "\n",
      "\n",
      "Epoch:  271 Avg loss:  0.6679969 ; acc:  0.65130985 ; epoch time:  0.325214147567749\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66517955\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  272 Avg loss:  0.66731846 ; acc:  0.65130985 ; epoch time:  0.3261749744415283\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66516024\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  273 Avg loss:  0.6669699 ; acc:  0.65130985 ; epoch time:  0.3668210506439209\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66457033\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  274 Avg loss:  0.6677776 ; acc:  0.75790423 ; epoch time:  0.3582618236541748\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6643775\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  275 Avg loss:  0.667681 ; acc:  0.6729901 ; epoch time:  0.3427605628967285\n",
      "eval test...\n",
      "test acc:  0.6612903\n",
      "test loss:  0.6644531\n",
      "\n",
      "\n",
      "Epoch:  276 Avg loss:  0.6678707 ; acc:  0.64408314 ; epoch time:  0.31572628021240234\n",
      "eval test...\n",
      "test acc:  0.62096775\n",
      "test loss:  0.66562426\n",
      "\n",
      "\n",
      "Epoch:  277 Avg loss:  0.6662702 ; acc:  0.75790423 ; epoch time:  0.31911301612854004\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6629888\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  278 Avg loss:  0.6656516 ; acc:  0.7028004 ; epoch time:  0.3276374340057373\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.66263205\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  279 Avg loss:  0.6654089 ; acc:  0.6729901 ; epoch time:  0.3516228199005127\n",
      "eval test...\n",
      "test acc:  0.6612903\n",
      "test loss:  0.6624843\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  280 Avg loss:  0.6653646 ; acc:  0.75790423 ; epoch time:  0.3435490131378174\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6618806\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  281 Avg loss:  0.6686153 ; acc:  0.7524842 ; epoch time:  0.3629307746887207\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.66376233\n",
      "\n",
      "\n",
      "Epoch:  282 Avg loss:  0.6692861 ; acc:  0.58988255 ; epoch time:  0.3352084159851074\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6679136\n",
      "\n",
      "\n",
      "Epoch:  283 Avg loss:  0.6676861 ; acc:  0.59349597 ; epoch time:  0.3344721794128418\n",
      "eval test...\n",
      "test acc:  0.58064514\n",
      "test loss:  0.6663386\n",
      "\n",
      "\n",
      "Epoch:  284 Avg loss:  0.66425484 ; acc:  0.75790423 ; epoch time:  0.34855222702026367\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6606482\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  285 Avg loss:  0.6711564 ; acc:  0.5781391 ; epoch time:  0.36374878883361816\n",
      "eval test...\n",
      "test acc:  0.58064514\n",
      "test loss:  0.6652417\n",
      "\n",
      "\n",
      "Epoch:  286 Avg loss:  0.66651726 ; acc:  0.60794944 ; epoch time:  0.303722620010376\n",
      "eval test...\n",
      "test acc:  0.58870965\n",
      "test loss:  0.6652139\n",
      "\n",
      "\n",
      "Epoch:  287 Avg loss:  0.66618073 ; acc:  0.60794944 ; epoch time:  0.34098339080810547\n",
      "eval test...\n",
      "test acc:  0.58870965\n",
      "test loss:  0.66490245\n",
      "\n",
      "\n",
      "Epoch:  288 Avg loss:  0.66448903 ; acc:  0.67479676 ; epoch time:  0.33568668365478516\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.6597138\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  289 Avg loss:  0.6669683 ; acc:  0.5745258 ; epoch time:  0.3401205539703369\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6613099\n",
      "\n",
      "\n",
      "Epoch:  290 Avg loss:  0.6624784 ; acc:  0.65672994 ; epoch time:  0.3528573513031006\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6599965\n",
      "\n",
      "\n",
      "Epoch:  291 Avg loss:  0.66582936 ; acc:  0.59349597 ; epoch time:  0.32060837745666504\n",
      "eval test...\n",
      "test acc:  0.58064514\n",
      "test loss:  0.66495144\n",
      "\n",
      "\n",
      "Epoch:  292 Avg loss:  0.661854 ; acc:  0.7028004 ; epoch time:  0.3108842372894287\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.6589847\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  293 Avg loss:  0.66452396 ; acc:  0.5745258 ; epoch time:  0.3542952537536621\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6589374\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  294 Avg loss:  0.66104275 ; acc:  0.75790423 ; epoch time:  0.3470292091369629\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6581142\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  295 Avg loss:  0.66445297 ; acc:  0.64408314 ; epoch time:  0.3493826389312744\n",
      "eval test...\n",
      "test acc:  0.62096775\n",
      "test loss:  0.663236\n",
      "\n",
      "\n",
      "Epoch:  296 Avg loss:  0.660532 ; acc:  0.75790423 ; epoch time:  0.3623671531677246\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6577059\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  297 Avg loss:  0.6622336 ; acc:  0.6242096 ; epoch time:  0.3272366523742676\n",
      "eval test...\n",
      "test acc:  0.6532258\n",
      "test loss:  0.65723604\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  298 Avg loss:  0.662064 ; acc:  0.5745258 ; epoch time:  0.35985541343688965\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6568303\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  299 Avg loss:  0.6594612 ; acc:  0.75609756 ; epoch time:  0.33327150344848633\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6552656\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  300 Avg loss:  0.6597117 ; acc:  0.67479676 ; epoch time:  0.3428041934967041\n",
      "eval test...\n",
      "test acc:  0.6612903\n",
      "test loss:  0.65739787\n",
      "\n",
      "\n",
      "Epoch:  301 Avg loss:  0.660254 ; acc:  0.65130985 ; epoch time:  0.33223485946655273\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.65821576\n",
      "\n",
      "\n",
      "Epoch:  302 Avg loss:  0.65811884 ; acc:  0.75790423 ; epoch time:  0.36994314193725586\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.65445685\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  303 Avg loss:  0.66051424 ; acc:  0.6242096 ; epoch time:  0.3203253746032715\n",
      "eval test...\n",
      "test acc:  0.6532258\n",
      "test loss:  0.65489626\n",
      "\n",
      "\n",
      "Epoch:  304 Avg loss:  0.6570874 ; acc:  0.75790423 ; epoch time:  0.35416698455810547\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6528067\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  305 Avg loss:  0.6573285 ; acc:  0.75790423 ; epoch time:  0.316756010055542\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6540793\n",
      "\n",
      "\n",
      "Epoch:  306 Avg loss:  0.65685767 ; acc:  0.75790423 ; epoch time:  0.32619428634643555\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.65376335\n",
      "\n",
      "\n",
      "Epoch:  307 Avg loss:  0.65600973 ; acc:  0.75790423 ; epoch time:  0.32726192474365234\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.65207493\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  308 Avg loss:  0.65581244 ; acc:  0.6838302 ; epoch time:  0.34369826316833496\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.6511702\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  309 Avg loss:  0.6553887 ; acc:  0.6838302 ; epoch time:  0.3337082862854004\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.65082824\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  310 Avg loss:  0.6546026 ; acc:  0.75790423 ; epoch time:  0.3147702217102051\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.65091336\n",
      "\n",
      "\n",
      "Epoch:  311 Avg loss:  0.6541811 ; acc:  0.75790423 ; epoch time:  0.34775519371032715\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.65124637\n",
      "\n",
      "\n",
      "Epoch:  312 Avg loss:  0.6535976 ; acc:  0.75790423 ; epoch time:  0.33208727836608887\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6505368\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  313 Avg loss:  0.652801 ; acc:  0.7533876 ; epoch time:  0.3443922996520996\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.64883846\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  314 Avg loss:  0.6524042 ; acc:  0.74887085 ; epoch time:  0.3566882610321045\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.6482948\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  315 Avg loss:  0.65465456 ; acc:  0.75790423 ; epoch time:  0.3548159599304199\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.65202016\n",
      "\n",
      "\n",
      "Epoch:  316 Avg loss:  0.6512924 ; acc:  0.75790423 ; epoch time:  0.3591463565826416\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6477454\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  317 Avg loss:  0.6593837 ; acc:  0.5754291 ; epoch time:  0.313586950302124\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6528733\n",
      "\n",
      "\n",
      "Epoch:  318 Avg loss:  0.65828073 ; acc:  0.65130985 ; epoch time:  0.35120177268981934\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6587681\n",
      "\n",
      "\n",
      "Epoch:  319 Avg loss:  0.66144496 ; acc:  0.63414633 ; epoch time:  0.31574344635009766\n",
      "eval test...\n",
      "test acc:  0.61290324\n",
      "test loss:  0.66244954\n",
      "\n",
      "\n",
      "Epoch:  320 Avg loss:  0.6520841 ; acc:  0.5745258 ; epoch time:  0.3412024974822998\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.64689416\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  321 Avg loss:  0.6853316 ; acc:  0.61246616 ; epoch time:  0.3334317207336426\n",
      "eval test...\n",
      "test acc:  0.62096775\n",
      "test loss:  0.674013\n",
      "\n",
      "\n",
      "Epoch:  322 Avg loss:  0.65049803 ; acc:  0.7028004 ; epoch time:  0.3571465015411377\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.64932656\n",
      "\n",
      "\n",
      "Epoch:  323 Avg loss:  0.66666996 ; acc:  0.58988255 ; epoch time:  0.33585405349731445\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6680455\n",
      "\n",
      "\n",
      "Epoch:  324 Avg loss:  0.6680519 ; acc:  0.58897924 ; epoch time:  0.3649921417236328\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6692668\n",
      "\n",
      "\n",
      "Epoch:  325 Avg loss:  0.6631954 ; acc:  0.63414633 ; epoch time:  0.3321225643157959\n",
      "eval test...\n",
      "test acc:  0.61290324\n",
      "test loss:  0.6635247\n",
      "\n",
      "\n",
      "Epoch:  326 Avg loss:  0.6533057 ; acc:  0.75790423 ; epoch time:  0.35753941535949707\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6511928\n",
      "\n",
      "\n",
      "Epoch:  327 Avg loss:  0.6736714 ; acc:  0.6007227 ; epoch time:  0.323688268661499\n",
      "eval test...\n",
      "test acc:  0.62096775\n",
      "test loss:  0.6652656\n",
      "\n",
      "\n",
      "Epoch:  328 Avg loss:  0.6647819 ; acc:  0.59981936 ; epoch time:  0.3462188243865967\n",
      "eval test...\n",
      "test acc:  0.62096775\n",
      "test loss:  0.6584551\n",
      "\n",
      "\n",
      "Epoch:  329 Avg loss:  0.65383404 ; acc:  0.7028004 ; epoch time:  0.33814144134521484\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.6534389\n",
      "\n",
      "\n",
      "Epoch:  330 Avg loss:  0.6588459 ; acc:  0.65130985 ; epoch time:  0.32665133476257324\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.66038305\n",
      "\n",
      "\n",
      "Epoch:  331 Avg loss:  0.6478889 ; acc:  0.75790423 ; epoch time:  0.3416118621826172\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6476741\n",
      "\n",
      "\n",
      "Epoch:  332 Avg loss:  0.64822334 ; acc:  0.7533876 ; epoch time:  0.3318502902984619\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.6456901\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  333 Avg loss:  0.6484149 ; acc:  0.6233063 ; epoch time:  0.3627490997314453\n",
      "eval test...\n",
      "test acc:  0.6532258\n",
      "test loss:  0.6446738\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  334 Avg loss:  0.647811 ; acc:  0.67479676 ; epoch time:  0.3175487518310547\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.64412904\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  335 Avg loss:  0.64924496 ; acc:  0.75790423 ; epoch time:  0.4066619873046875\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6473985\n",
      "\n",
      "\n",
      "Epoch:  336 Avg loss:  0.64921606 ; acc:  0.75790423 ; epoch time:  0.33611106872558594\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6473221\n",
      "\n",
      "\n",
      "Epoch:  337 Avg loss:  0.65323275 ; acc:  0.67479676 ; epoch time:  0.3462338447570801\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.6480611\n",
      "\n",
      "\n",
      "Epoch:  338 Avg loss:  0.64896655 ; acc:  0.75790423 ; epoch time:  0.3444828987121582\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.64744484\n",
      "\n",
      "\n",
      "Epoch:  339 Avg loss:  0.64771 ; acc:  0.75790423 ; epoch time:  0.34399986267089844\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.64662635\n",
      "\n",
      "\n",
      "Epoch:  340 Avg loss:  0.6449425 ; acc:  0.7524842 ; epoch time:  0.3418447971343994\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.64179045\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  341 Avg loss:  0.64931136 ; acc:  0.5745258 ; epoch time:  0.33609867095947266\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6437428\n",
      "\n",
      "\n",
      "Epoch:  342 Avg loss:  0.6447826 ; acc:  0.75790423 ; epoch time:  0.3559377193450928\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6439972\n",
      "\n",
      "\n",
      "Epoch:  343 Avg loss:  0.648279 ; acc:  0.65130985 ; epoch time:  0.3310849666595459\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.65031874\n",
      "\n",
      "\n",
      "Epoch:  344 Avg loss:  0.6439625 ; acc:  0.67479676 ; epoch time:  0.3256063461303711\n",
      "eval test...\n",
      "test acc:  0.6612903\n",
      "test loss:  0.64503646\n",
      "\n",
      "\n",
      "Epoch:  345 Avg loss:  0.64314854 ; acc:  0.75609756 ; epoch time:  0.3367762565612793\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6413508\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  346 Avg loss:  0.64505726 ; acc:  0.5745258 ; epoch time:  0.33525609970092773\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6412616\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  347 Avg loss:  0.64483505 ; acc:  0.5745258 ; epoch time:  0.3310964107513428\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6412581\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  348 Avg loss:  0.6411688 ; acc:  0.75609756 ; epoch time:  0.32331037521362305\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6395606\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  349 Avg loss:  0.64754295 ; acc:  0.6729901 ; epoch time:  0.32982349395751953\n",
      "eval test...\n",
      "test acc:  0.6612903\n",
      "test loss:  0.6486168\n",
      "\n",
      "\n",
      "Epoch:  350 Avg loss:  0.6419428 ; acc:  0.75790423 ; epoch time:  0.34423184394836426\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.64185816\n",
      "\n",
      "\n",
      "Epoch:  351 Avg loss:  0.6447748 ; acc:  0.5745258 ; epoch time:  0.3294081687927246\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6406005\n",
      "\n",
      "\n",
      "Epoch:  352 Avg loss:  0.6422718 ; acc:  0.5745258 ; epoch time:  0.33559751510620117\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.63853437\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  353 Avg loss:  0.63932157 ; acc:  0.75609756 ; epoch time:  0.33354902267456055\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.63801193\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  354 Avg loss:  0.64038914 ; acc:  0.6729901 ; epoch time:  0.32016587257385254\n",
      "eval test...\n",
      "test acc:  0.6612903\n",
      "test loss:  0.64227605\n",
      "\n",
      "\n",
      "Epoch:  355 Avg loss:  0.6392548 ; acc:  0.6729901 ; epoch time:  0.3313331604003906\n",
      "eval test...\n",
      "test acc:  0.6612903\n",
      "test loss:  0.6412794\n",
      "\n",
      "\n",
      "Epoch:  356 Avg loss:  0.63808674 ; acc:  0.75790423 ; epoch time:  0.33702611923217773\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6377605\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  357 Avg loss:  0.6394868 ; acc:  0.6233063 ; epoch time:  0.3481125831604004\n",
      "eval test...\n",
      "test acc:  0.6532258\n",
      "test loss:  0.6354864\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  358 Avg loss:  0.6400756 ; acc:  0.5745258 ; epoch time:  0.3626265525817871\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6354243\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  359 Avg loss:  0.63786954 ; acc:  0.67479676 ; epoch time:  0.37387895584106445\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.6344736\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  360 Avg loss:  0.6354521 ; acc:  0.75790423 ; epoch time:  0.3295166492462158\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6345048\n",
      "\n",
      "\n",
      "Epoch:  361 Avg loss:  0.6386323 ; acc:  0.75790423 ; epoch time:  0.3635408878326416\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.63947016\n",
      "\n",
      "\n",
      "Epoch:  362 Avg loss:  0.6345362 ; acc:  0.75790423 ; epoch time:  0.3433663845062256\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6330904\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  363 Avg loss:  0.63538766 ; acc:  0.67479676 ; epoch time:  0.33128929138183594\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.6319242\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  364 Avg loss:  0.6353367 ; acc:  0.6233063 ; epoch time:  0.3394331932067871\n",
      "eval test...\n",
      "test acc:  0.6532258\n",
      "test loss:  0.63164437\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  365 Avg loss:  0.6331048 ; acc:  0.7542909 ; epoch time:  0.3287642002105713\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6306838\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  366 Avg loss:  0.6355096 ; acc:  0.75790423 ; epoch time:  0.34128737449645996\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6347175\n",
      "\n",
      "\n",
      "Epoch:  367 Avg loss:  0.63234293 ; acc:  0.75609756 ; epoch time:  0.34485435485839844\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.630183\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  368 Avg loss:  0.6337272 ; acc:  0.6242096 ; epoch time:  0.34432435035705566\n",
      "eval test...\n",
      "test acc:  0.6532258\n",
      "test loss:  0.629848\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  369 Avg loss:  0.6321604 ; acc:  0.67479676 ; epoch time:  0.3157472610473633\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.62869257\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  370 Avg loss:  0.63187414 ; acc:  0.75790423 ; epoch time:  0.3560171127319336\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6307437\n",
      "\n",
      "\n",
      "Epoch:  371 Avg loss:  0.63021266 ; acc:  0.75790423 ; epoch time:  0.3551194667816162\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6288121\n",
      "\n",
      "\n",
      "Epoch:  372 Avg loss:  0.63034964 ; acc:  0.74887085 ; epoch time:  0.3247106075286865\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.6273582\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  373 Avg loss:  0.6292083 ; acc:  0.7524842 ; epoch time:  0.3337070941925049\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.6268615\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  374 Avg loss:  0.62997913 ; acc:  0.75790423 ; epoch time:  0.3108823299407959\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6306231\n",
      "\n",
      "\n",
      "Epoch:  375 Avg loss:  0.62739325 ; acc:  0.75609756 ; epoch time:  0.3424394130706787\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.626393\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  376 Avg loss:  0.62831175 ; acc:  0.74887085 ; epoch time:  0.35291242599487305\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.6261207\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  377 Avg loss:  0.62607217 ; acc:  0.75790423 ; epoch time:  0.3489065170288086\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.62579083\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  378 Avg loss:  0.62803066 ; acc:  0.75790423 ; epoch time:  0.32387757301330566\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.63042754\n",
      "\n",
      "\n",
      "Epoch:  379 Avg loss:  0.6246946 ; acc:  0.75790423 ; epoch time:  0.3368034362792969\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6266284\n",
      "\n",
      "\n",
      "Epoch:  380 Avg loss:  0.62533593 ; acc:  0.7533876 ; epoch time:  0.3346123695373535\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.6252494\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  381 Avg loss:  0.62441486 ; acc:  0.75609756 ; epoch time:  0.3380908966064453\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.62506056\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  382 Avg loss:  0.621466 ; acc:  0.75790423 ; epoch time:  0.34342384338378906\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6240901\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  383 Avg loss:  0.62073654 ; acc:  0.75790423 ; epoch time:  0.35292911529541016\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6236088\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  384 Avg loss:  0.6216761 ; acc:  0.75790423 ; epoch time:  0.32758164405822754\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6228664\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  385 Avg loss:  0.61954427 ; acc:  0.75790423 ; epoch time:  0.32161498069763184\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.62133205\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  386 Avg loss:  0.6258189 ; acc:  0.67479676 ; epoch time:  0.31663060188293457\n",
      "eval test...\n",
      "test acc:  0.6612903\n",
      "test loss:  0.6298607\n",
      "\n",
      "\n",
      "Epoch:  387 Avg loss:  0.6251622 ; acc:  0.6242096 ; epoch time:  0.3334066867828369\n",
      "eval test...\n",
      "test acc:  0.6532258\n",
      "test loss:  0.6229256\n",
      "\n",
      "\n",
      "Epoch:  388 Avg loss:  0.63001746 ; acc:  0.5745258 ; epoch time:  0.3453645706176758\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.62508065\n",
      "\n",
      "\n",
      "Epoch:  389 Avg loss:  0.6182524 ; acc:  0.75790423 ; epoch time:  0.3391430377960205\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6195038\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  390 Avg loss:  0.6411822 ; acc:  0.65130985 ; epoch time:  0.35309267044067383\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.64768255\n",
      "\n",
      "\n",
      "Epoch:  391 Avg loss:  0.61732304 ; acc:  0.75609756 ; epoch time:  0.32828855514526367\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6183617\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  392 Avg loss:  0.6255332 ; acc:  0.5745258 ; epoch time:  0.33078432083129883\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.62099725\n",
      "\n",
      "\n",
      "Epoch:  393 Avg loss:  0.62024236 ; acc:  0.6847335 ; epoch time:  0.3820798397064209\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.6183964\n",
      "\n",
      "\n",
      "Epoch:  394 Avg loss:  0.61665326 ; acc:  0.75790423 ; epoch time:  0.3238677978515625\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6208161\n",
      "\n",
      "\n",
      "Epoch:  395 Avg loss:  0.6179273 ; acc:  0.75790423 ; epoch time:  0.34078478813171387\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.62234527\n",
      "\n",
      "\n",
      "Epoch:  396 Avg loss:  0.61967844 ; acc:  0.6729901 ; epoch time:  0.3578341007232666\n",
      "eval test...\n",
      "test acc:  0.6774193\n",
      "test loss:  0.6172375\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  397 Avg loss:  0.6231986 ; acc:  0.5745258 ; epoch time:  0.35642194747924805\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6187568\n",
      "\n",
      "\n",
      "Epoch:  398 Avg loss:  0.6124037 ; acc:  0.75790423 ; epoch time:  0.3382241725921631\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.61477417\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  399 Avg loss:  0.639152 ; acc:  0.65130985 ; epoch time:  0.3569176197052002\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.64697975\n",
      "\n",
      "\n",
      "Epoch:  400 Avg loss:  0.61110103 ; acc:  0.75790423 ; epoch time:  0.31349658966064453\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6134833\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  401 Avg loss:  0.6182799 ; acc:  0.6242096 ; epoch time:  0.3354930877685547\n",
      "eval test...\n",
      "test acc:  0.6532258\n",
      "test loss:  0.61603683\n",
      "\n",
      "\n",
      "Epoch:  402 Avg loss:  0.6132701 ; acc:  0.74887085 ; epoch time:  0.32130956649780273\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.61424947\n",
      "\n",
      "\n",
      "Epoch:  403 Avg loss:  0.60893285 ; acc:  0.75790423 ; epoch time:  0.3260185718536377\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6144583\n",
      "\n",
      "\n",
      "Epoch:  404 Avg loss:  0.60795355 ; acc:  0.75790423 ; epoch time:  0.3398866653442383\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.61067176\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  405 Avg loss:  0.6062944 ; acc:  0.75790423 ; epoch time:  0.32869601249694824\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.60941285\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  406 Avg loss:  0.61057323 ; acc:  0.75790423 ; epoch time:  0.3355998992919922\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6165031\n",
      "\n",
      "\n",
      "Epoch:  407 Avg loss:  0.6097636 ; acc:  0.74887085 ; epoch time:  0.3618042469024658\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.6114006\n",
      "\n",
      "\n",
      "Epoch:  408 Avg loss:  0.61087906 ; acc:  0.6838302 ; epoch time:  0.31725525856018066\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.61161065\n",
      "\n",
      "\n",
      "Epoch:  409 Avg loss:  0.6025755 ; acc:  0.75790423 ; epoch time:  0.3125646114349365\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6064691\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  410 Avg loss:  0.6261387 ; acc:  0.65130985 ; epoch time:  0.34636545181274414\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6343459\n",
      "\n",
      "\n",
      "Epoch:  411 Avg loss:  0.60692775 ; acc:  0.74887085 ; epoch time:  0.3383307456970215\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.6089916\n",
      "\n",
      "\n",
      "Epoch:  412 Avg loss:  0.6169232 ; acc:  0.5745258 ; epoch time:  0.33896923065185547\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.6133284\n",
      "\n",
      "\n",
      "Epoch:  413 Avg loss:  0.60436535 ; acc:  0.7542909 ; epoch time:  0.3059360980987549\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6071758\n",
      "\n",
      "\n",
      "Epoch:  414 Avg loss:  0.6218774 ; acc:  0.65130985 ; epoch time:  0.330777645111084\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.63070136\n",
      "\n",
      "\n",
      "Epoch:  415 Avg loss:  0.60001826 ; acc:  0.75790423 ; epoch time:  0.3264586925506592\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6043142\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  416 Avg loss:  0.6052607 ; acc:  0.7461608 ; epoch time:  0.3362851142883301\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.60671175\n",
      "\n",
      "\n",
      "Epoch:  417 Avg loss:  0.60164034 ; acc:  0.7542909 ; epoch time:  0.33176112174987793\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.60492474\n",
      "\n",
      "\n",
      "Epoch:  418 Avg loss:  0.60157514 ; acc:  0.75790423 ; epoch time:  0.319272518157959\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6094952\n",
      "\n",
      "\n",
      "Epoch:  419 Avg loss:  0.5968863 ; acc:  0.75790423 ; epoch time:  0.34860682487487793\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6015244\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  420 Avg loss:  0.5964656 ; acc:  0.75790423 ; epoch time:  0.35460591316223145\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6010132\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  421 Avg loss:  0.59624326 ; acc:  0.75790423 ; epoch time:  0.3133082389831543\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6041081\n",
      "\n",
      "\n",
      "Epoch:  422 Avg loss:  0.5983221 ; acc:  0.7524842 ; epoch time:  0.35483407974243164\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.6020699\n",
      "\n",
      "\n",
      "Epoch:  423 Avg loss:  0.59612256 ; acc:  0.7542909 ; epoch time:  0.34897351264953613\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6003685\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  424 Avg loss:  0.5991198 ; acc:  0.75790423 ; epoch time:  0.33698225021362305\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.6074447\n",
      "\n",
      "\n",
      "Epoch:  425 Avg loss:  0.59798914 ; acc:  0.74887085 ; epoch time:  0.34037351608276367\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.60149366\n",
      "\n",
      "\n",
      "Epoch:  426 Avg loss:  0.59982526 ; acc:  0.6847335 ; epoch time:  0.353985071182251\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.60216576\n",
      "\n",
      "\n",
      "Epoch:  427 Avg loss:  0.58916247 ; acc:  0.75790423 ; epoch time:  0.3472762107849121\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.59534353\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  428 Avg loss:  0.6149309 ; acc:  0.65130985 ; epoch time:  0.33111119270324707\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.62634355\n",
      "\n",
      "\n",
      "Epoch:  429 Avg loss:  0.5920158 ; acc:  0.75519425 ; epoch time:  0.3293721675872803\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5972503\n",
      "\n",
      "\n",
      "Epoch:  430 Avg loss:  0.59902626 ; acc:  0.67479676 ; epoch time:  0.37781572341918945\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.600017\n",
      "\n",
      "\n",
      "Epoch:  431 Avg loss:  0.5899008 ; acc:  0.75609756 ; epoch time:  0.3076624870300293\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.59574485\n",
      "\n",
      "\n",
      "Epoch:  432 Avg loss:  0.6056806 ; acc:  0.65672994 ; epoch time:  0.3102288246154785\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6172246\n",
      "\n",
      "\n",
      "Epoch:  433 Avg loss:  0.5866514 ; acc:  0.75790423 ; epoch time:  0.35452747344970703\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.593226\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  434 Avg loss:  0.5920509 ; acc:  0.74887085 ; epoch time:  0.30516910552978516\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.59656614\n",
      "\n",
      "\n",
      "Epoch:  435 Avg loss:  0.58552825 ; acc:  0.75790423 ; epoch time:  0.36168670654296875\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.59217995\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  436 Avg loss:  0.59660894 ; acc:  0.67479676 ; epoch time:  0.3011820316314697\n",
      "eval test...\n",
      "test acc:  0.6612903\n",
      "test loss:  0.6075023\n",
      "\n",
      "\n",
      "Epoch:  437 Avg loss:  0.58611655 ; acc:  0.7542909 ; epoch time:  0.3563516139984131\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.59249026\n",
      "\n",
      "\n",
      "Epoch:  438 Avg loss:  0.5888647 ; acc:  0.74887085 ; epoch time:  0.3556222915649414\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.59411174\n",
      "\n",
      "\n",
      "Epoch:  439 Avg loss:  0.5792186 ; acc:  0.75790423 ; epoch time:  0.30727314949035645\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5876552\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  440 Avg loss:  0.60066634 ; acc:  0.65672994 ; epoch time:  0.3112802505493164\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6135233\n",
      "\n",
      "\n",
      "Epoch:  441 Avg loss:  0.5840401 ; acc:  0.7542909 ; epoch time:  0.3302884101867676\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.59086764\n",
      "\n",
      "\n",
      "Epoch:  442 Avg loss:  0.5902947 ; acc:  0.67479676 ; epoch time:  0.3227708339691162\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.59314567\n",
      "\n",
      "\n",
      "Epoch:  443 Avg loss:  0.5791215 ; acc:  0.75790423 ; epoch time:  0.34282636642456055\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5875091\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  444 Avg loss:  0.5984287 ; acc:  0.65130985 ; epoch time:  0.35214662551879883\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.6128954\n",
      "\n",
      "\n",
      "Epoch:  445 Avg loss:  0.57628256 ; acc:  0.75790423 ; epoch time:  0.3315091133117676\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5853904\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  446 Avg loss:  0.5826 ; acc:  0.74887085 ; epoch time:  0.32952260971069336\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.5892727\n",
      "\n",
      "\n",
      "Epoch:  447 Avg loss:  0.57690465 ; acc:  0.75609756 ; epoch time:  0.3422732353210449\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5856119\n",
      "\n",
      "\n",
      "Epoch:  448 Avg loss:  0.582291 ; acc:  0.7028004 ; epoch time:  0.3389620780944824\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.59619725\n",
      "\n",
      "\n",
      "Epoch:  449 Avg loss:  0.57568485 ; acc:  0.75609756 ; epoch time:  0.33164024353027344\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5846257\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  450 Avg loss:  0.5774802 ; acc:  0.7524842 ; epoch time:  0.3302781581878662\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.5857202\n",
      "\n",
      "\n",
      "Epoch:  451 Avg loss:  0.5685566 ; acc:  0.75790423 ; epoch time:  0.34171128273010254\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.58105975\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  452 Avg loss:  0.5720519 ; acc:  0.75790423 ; epoch time:  0.3399953842163086\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5868849\n",
      "\n",
      "\n",
      "Epoch:  453 Avg loss:  0.57424563 ; acc:  0.7542909 ; epoch time:  0.3475773334503174\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5833425\n",
      "\n",
      "\n",
      "Epoch:  454 Avg loss:  0.57397646 ; acc:  0.7533876 ; epoch time:  0.3198206424713135\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.5830101\n",
      "\n",
      "\n",
      "Epoch:  455 Avg loss:  0.56645614 ; acc:  0.75790423 ; epoch time:  0.349686861038208\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.58095855\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  456 Avg loss:  0.5657033 ; acc:  0.75790423 ; epoch time:  0.32283759117126465\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.58051926\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  457 Avg loss:  0.569692 ; acc:  0.75519425 ; epoch time:  0.341494083404541\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5801001\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  458 Avg loss:  0.5651688 ; acc:  0.75790423 ; epoch time:  0.3435328006744385\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5768101\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  459 Avg loss:  0.5708359 ; acc:  0.7028004 ; epoch time:  0.32569313049316406\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.5874351\n",
      "\n",
      "\n",
      "Epoch:  460 Avg loss:  0.56564236 ; acc:  0.75609756 ; epoch time:  0.32759547233581543\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5770577\n",
      "\n",
      "\n",
      "Epoch:  461 Avg loss:  0.56615174 ; acc:  0.75609756 ; epoch time:  0.31678271293640137\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5773504\n",
      "\n",
      "\n",
      "Epoch:  462 Avg loss:  0.5611483 ; acc:  0.75790423 ; epoch time:  0.3126797676086426\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5783116\n",
      "\n",
      "\n",
      "Epoch:  463 Avg loss:  0.5581647 ; acc:  0.75790423 ; epoch time:  0.36205220222473145\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.57195586\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  464 Avg loss:  0.5573963 ; acc:  0.75790423 ; epoch time:  0.356964111328125\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5711381\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  465 Avg loss:  0.557138 ; acc:  0.75790423 ; epoch time:  0.33178234100341797\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.57401234\n",
      "\n",
      "\n",
      "Epoch:  466 Avg loss:  0.55478525 ; acc:  0.75790423 ; epoch time:  0.3463294506072998\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.56904763\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  467 Avg loss:  0.5535138 ; acc:  0.75790423 ; epoch time:  0.3283567428588867\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5680665\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  468 Avg loss:  0.5548598 ; acc:  0.75790423 ; epoch time:  0.34034204483032227\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5722176\n",
      "\n",
      "\n",
      "Epoch:  469 Avg loss:  0.5571045 ; acc:  0.75609756 ; epoch time:  0.3429300785064697\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5698573\n",
      "\n",
      "\n",
      "Epoch:  470 Avg loss:  0.551433 ; acc:  0.75790423 ; epoch time:  0.3342094421386719\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.56580657\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  471 Avg loss:  0.5633645 ; acc:  0.7028004 ; epoch time:  0.35319972038269043\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.58251494\n",
      "\n",
      "\n",
      "Epoch:  472 Avg loss:  0.5667146 ; acc:  0.7461608 ; epoch time:  0.35605573654174805\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.575224\n",
      "\n",
      "\n",
      "Epoch:  473 Avg loss:  0.57241756 ; acc:  0.6729901 ; epoch time:  0.3460216522216797\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.5774967\n",
      "\n",
      "\n",
      "Epoch:  474 Avg loss:  0.5491276 ; acc:  0.75790423 ; epoch time:  0.3208651542663574\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5675392\n",
      "\n",
      "\n",
      "Epoch:  475 Avg loss:  0.5735283 ; acc:  0.65672994 ; epoch time:  0.318007230758667\n",
      "eval test...\n",
      "test acc:  0.62903225\n",
      "test loss:  0.5952776\n",
      "\n",
      "\n",
      "Epoch:  476 Avg loss:  0.5640106 ; acc:  0.7461608 ; epoch time:  0.3569669723510742\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.57279783\n",
      "\n",
      "\n",
      "Epoch:  477 Avg loss:  0.58041644 ; acc:  0.5745258 ; epoch time:  0.3189430236816406\n",
      "eval test...\n",
      "test acc:  0.57258064\n",
      "test loss:  0.5822621\n",
      "\n",
      "\n",
      "Epoch:  478 Avg loss:  0.54367054 ; acc:  0.75790423 ; epoch time:  0.3252263069152832\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.56181043\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  479 Avg loss:  0.59548813 ; acc:  0.6793135 ; epoch time:  0.3261444568634033\n",
      "eval test...\n",
      "test acc:  0.63709676\n",
      "test loss:  0.62070036\n",
      "\n",
      "\n",
      "Epoch:  480 Avg loss:  0.5503039 ; acc:  0.75519425 ; epoch time:  0.3424341678619385\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5648963\n",
      "\n",
      "\n",
      "Epoch:  481 Avg loss:  0.5668381 ; acc:  0.6729901 ; epoch time:  0.3243217468261719\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.5731671\n",
      "\n",
      "\n",
      "Epoch:  482 Avg loss:  0.5432261 ; acc:  0.75790423 ; epoch time:  0.3595595359802246\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5601268\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  483 Avg loss:  0.58551353 ; acc:  0.6793135 ; epoch time:  0.34456753730773926\n",
      "eval test...\n",
      "test acc:  0.63709676\n",
      "test loss:  0.61187404\n",
      "\n",
      "\n",
      "Epoch:  484 Avg loss:  0.54095066 ; acc:  0.75790423 ; epoch time:  0.336564302444458\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.55892956\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  485 Avg loss:  0.5562087 ; acc:  0.7461608 ; epoch time:  0.3263356685638428\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.56722105\n",
      "\n",
      "\n",
      "Epoch:  486 Avg loss:  0.5468428 ; acc:  0.75519425 ; epoch time:  0.3589143753051758\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5628975\n",
      "\n",
      "\n",
      "Epoch:  487 Avg loss:  0.5503288 ; acc:  0.73080397 ; epoch time:  0.35465478897094727\n",
      "eval test...\n",
      "test acc:  0.6774193\n",
      "test loss:  0.5751167\n",
      "\n",
      "\n",
      "Epoch:  488 Avg loss:  0.5390014 ; acc:  0.7642276 ; epoch time:  0.3465399742126465\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5576236\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  489 Avg loss:  0.5431925 ; acc:  0.75790423 ; epoch time:  0.3506498336791992\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.560553\n",
      "\n",
      "\n",
      "Epoch:  490 Avg loss:  0.5348236 ; acc:  0.78500456 ; epoch time:  0.3613262176513672\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.55688053\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  491 Avg loss:  0.5418171 ; acc:  0.7931346 ; epoch time:  0.34804487228393555\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.56742024\n",
      "\n",
      "\n",
      "Epoch:  492 Avg loss:  0.54228324 ; acc:  0.76784104 ; epoch time:  0.3376946449279785\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.5597694\n",
      "\n",
      "\n",
      "Epoch:  493 Avg loss:  0.54337114 ; acc:  0.75609756 ; epoch time:  0.33084654808044434\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5602025\n",
      "\n",
      "\n",
      "Epoch:  494 Avg loss:  0.5315244 ; acc:  0.77868116 ; epoch time:  0.33040738105773926\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.5541633\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  495 Avg loss:  0.55022544 ; acc:  0.728094 ; epoch time:  0.34859299659729004\n",
      "eval test...\n",
      "test acc:  0.7016129\n",
      "test loss:  0.5781626\n",
      "\n",
      "\n",
      "Epoch:  496 Avg loss:  0.5429912 ; acc:  0.7524842 ; epoch time:  0.34371066093444824\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.55938166\n",
      "\n",
      "\n",
      "Epoch:  497 Avg loss:  0.5617503 ; acc:  0.6233063 ; epoch time:  0.33861255645751953\n",
      "eval test...\n",
      "test acc:  0.6532258\n",
      "test loss:  0.56800455\n",
      "\n",
      "\n",
      "Epoch:  498 Avg loss:  0.5292893 ; acc:  0.7777778 ; epoch time:  0.35634398460388184\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.5516962\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  499 Avg loss:  0.5840974 ; acc:  0.6775068 ; epoch time:  0.3411273956298828\n",
      "eval test...\n",
      "test acc:  0.60483867\n",
      "test loss:  0.6169668\n",
      "\n",
      "\n",
      "Epoch:  500 Avg loss:  0.52826524 ; acc:  0.7777778 ; epoch time:  0.3385810852050781\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.5510623\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  501 Avg loss:  0.54949313 ; acc:  0.6847335 ; epoch time:  0.33861446380615234\n",
      "eval test...\n",
      "test acc:  0.6693548\n",
      "test loss:  0.5603347\n",
      "\n",
      "\n",
      "Epoch:  502 Avg loss:  0.535584 ; acc:  0.77416444 ; epoch time:  0.3278357982635498\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.5550518\n",
      "\n",
      "\n",
      "Epoch:  503 Avg loss:  0.5370136 ; acc:  0.7542909 ; epoch time:  0.3333144187927246\n",
      "eval test...\n",
      "test acc:  0.7096774\n",
      "test loss:  0.5675518\n",
      "\n",
      "\n",
      "Epoch:  504 Avg loss:  0.5236807 ; acc:  0.79223126 ; epoch time:  0.3592054843902588\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.5494582\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  505 Avg loss:  0.5316997 ; acc:  0.77868116 ; epoch time:  0.3436150550842285\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.5523899\n",
      "\n",
      "\n",
      "Epoch:  506 Avg loss:  0.52757317 ; acc:  0.78771454 ; epoch time:  0.34758663177490234\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.54998654\n",
      "\n",
      "\n",
      "Epoch:  507 Avg loss:  0.5286108 ; acc:  0.78048784 ; epoch time:  0.33449864387512207\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.5589603\n",
      "\n",
      "\n",
      "Epoch:  508 Avg loss:  0.5202898 ; acc:  0.8075881 ; epoch time:  0.3181114196777344\n",
      "eval test...\n",
      "test acc:  0.79838705\n",
      "test loss:  0.54729116\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  509 Avg loss:  0.5246659 ; acc:  0.78771454 ; epoch time:  0.34429097175598145\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.54801774\n",
      "\n",
      "\n",
      "Epoch:  510 Avg loss:  0.51878357 ; acc:  0.81120145 ; epoch time:  0.33481764793395996\n",
      "eval test...\n",
      "test acc:  0.79838705\n",
      "test loss:  0.54455507\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  511 Avg loss:  0.52361065 ; acc:  0.78048784 ; epoch time:  0.35515880584716797\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.55501825\n",
      "\n",
      "\n",
      "Epoch:  512 Avg loss:  0.518062 ; acc:  0.81029814 ; epoch time:  0.3396773338317871\n",
      "eval test...\n",
      "test acc:  0.79838705\n",
      "test loss:  0.5437415\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  513 Avg loss:  0.51942444 ; acc:  0.7895212 ; epoch time:  0.3459634780883789\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.54442394\n",
      "\n",
      "\n",
      "Epoch:  514 Avg loss:  0.5151971 ; acc:  0.8075881 ; epoch time:  0.32744574546813965\n",
      "eval test...\n",
      "test acc:  0.79838705\n",
      "test loss:  0.54390466\n",
      "\n",
      "\n",
      "Epoch:  515 Avg loss:  0.518383 ; acc:  0.78048784 ; epoch time:  0.3384208679199219\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.5503301\n",
      "\n",
      "\n",
      "Epoch:  516 Avg loss:  0.51542705 ; acc:  0.7886179 ; epoch time:  0.34224939346313477\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.54072964\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  517 Avg loss:  0.5139175 ; acc:  0.79132795 ; epoch time:  0.31477880477905273\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.5393488\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  518 Avg loss:  0.517056 ; acc:  0.7841012 ; epoch time:  0.3367581367492676\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.5496424\n",
      "\n",
      "\n",
      "Epoch:  519 Avg loss:  0.51165164 ; acc:  0.79403794 ; epoch time:  0.372844934463501\n",
      "eval test...\n",
      "test acc:  0.78225803\n",
      "test loss:  0.537245\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  520 Avg loss:  0.5105011 ; acc:  0.81662154 ; epoch time:  0.32134556770324707\n",
      "eval test...\n",
      "test acc:  0.79838705\n",
      "test loss:  0.53621244\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  521 Avg loss:  0.5158976 ; acc:  0.78139114 ; epoch time:  0.33876609802246094\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.5489285\n",
      "\n",
      "\n",
      "Epoch:  522 Avg loss:  0.50873303 ; acc:  0.7931346 ; epoch time:  0.3553805351257324\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.53454214\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  523 Avg loss:  0.508007 ; acc:  0.79132795 ; epoch time:  0.3324871063232422\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.53380424\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  524 Avg loss:  0.51145583 ; acc:  0.78048784 ; epoch time:  0.3526945114135742\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.544826\n",
      "\n",
      "\n",
      "Epoch:  525 Avg loss:  0.5055142 ; acc:  0.79132795 ; epoch time:  0.3620116710662842\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.531612\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  526 Avg loss:  0.5028564 ; acc:  0.81120145 ; epoch time:  0.33801984786987305\n",
      "eval test...\n",
      "test acc:  0.79838705\n",
      "test loss:  0.529647\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  527 Avg loss:  0.507637 ; acc:  0.7831978 ; epoch time:  0.32087087631225586\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.5409834\n",
      "\n",
      "\n",
      "Epoch:  528 Avg loss:  0.5058186 ; acc:  0.81029814 ; epoch time:  0.3740065097808838\n",
      "eval test...\n",
      "test acc:  0.79838705\n",
      "test loss:  0.5312028\n",
      "\n",
      "\n",
      "Epoch:  529 Avg loss:  0.49777082 ; acc:  0.78139114 ; epoch time:  0.34250831604003906\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5260922\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  530 Avg loss:  0.5084786 ; acc:  0.7904246 ; epoch time:  0.3672919273376465\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.54226196\n",
      "\n",
      "\n",
      "Epoch:  531 Avg loss:  0.51038057 ; acc:  0.78590786 ; epoch time:  0.3334164619445801\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.5348708\n",
      "\n",
      "\n",
      "Epoch:  532 Avg loss:  0.4949717 ; acc:  0.8075881 ; epoch time:  0.3354158401489258\n",
      "eval test...\n",
      "test acc:  0.79838705\n",
      "test loss:  0.52352834\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  533 Avg loss:  0.5181975 ; acc:  0.7931346 ; epoch time:  0.3296523094177246\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.5535319\n",
      "\n",
      "\n",
      "Epoch:  534 Avg loss:  0.52207947 ; acc:  0.7714544 ; epoch time:  0.3416757583618164\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.54372084\n",
      "\n",
      "\n",
      "Epoch:  535 Avg loss:  0.50533193 ; acc:  0.7841012 ; epoch time:  0.33553194999694824\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.53081584\n",
      "\n",
      "\n",
      "Epoch:  536 Avg loss:  0.540135 ; acc:  0.7118338 ; epoch time:  0.3657410144805908\n",
      "eval test...\n",
      "test acc:  0.6532258\n",
      "test loss:  0.5798774\n",
      "\n",
      "\n",
      "Epoch:  537 Avg loss:  0.49351096 ; acc:  0.8030714 ; epoch time:  0.3259730339050293\n",
      "eval test...\n",
      "test acc:  0.79838705\n",
      "test loss:  0.5215767\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  538 Avg loss:  0.5141078 ; acc:  0.7777778 ; epoch time:  0.3386209011077881\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.5372035\n",
      "\n",
      "\n",
      "Epoch:  539 Avg loss:  0.49323827 ; acc:  0.78048784 ; epoch time:  0.3285648822784424\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.5262248\n",
      "\n",
      "\n",
      "Epoch:  540 Avg loss:  0.49600133 ; acc:  0.7831978 ; epoch time:  0.3622417449951172\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.5303672\n",
      "\n",
      "\n",
      "Epoch:  541 Avg loss:  0.50124764 ; acc:  0.7895212 ; epoch time:  0.3316619396209717\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.5268718\n",
      "\n",
      "\n",
      "Epoch:  542 Avg loss:  0.48737884 ; acc:  0.7822945 ; epoch time:  0.3807637691497803\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.51641595\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  543 Avg loss:  0.50798136 ; acc:  0.79223126 ; epoch time:  0.3473079204559326\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.54351014\n",
      "\n",
      "\n",
      "Epoch:  544 Avg loss:  0.50819093 ; acc:  0.7822945 ; epoch time:  0.34157419204711914\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.53240466\n",
      "\n",
      "\n",
      "Epoch:  545 Avg loss:  0.4867402 ; acc:  0.8075881 ; epoch time:  0.31142330169677734\n",
      "eval test...\n",
      "test acc:  0.79838705\n",
      "test loss:  0.515142\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  546 Avg loss:  0.5321304 ; acc:  0.71906054 ; epoch time:  0.35458803176879883\n",
      "eval test...\n",
      "test acc:  0.6612903\n",
      "test loss:  0.57127726\n",
      "\n",
      "\n",
      "Epoch:  547 Avg loss:  0.4930002 ; acc:  0.8093948 ; epoch time:  0.30942296981811523\n",
      "eval test...\n",
      "test acc:  0.79838705\n",
      "test loss:  0.51962876\n",
      "\n",
      "\n",
      "Epoch:  548 Avg loss:  0.49219808 ; acc:  0.8157182 ; epoch time:  0.3278818130493164\n",
      "eval test...\n",
      "test acc:  0.80645156\n",
      "test loss:  0.5191404\n",
      "\n",
      "\n",
      "Epoch:  549 Avg loss:  0.5144452 ; acc:  0.80036134 ; epoch time:  0.34648990631103516\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5521935\n",
      "\n",
      "\n",
      "Epoch:  550 Avg loss:  0.4835617 ; acc:  0.78139114 ; epoch time:  0.3444545269012451\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5129742\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  551 Avg loss:  0.494813 ; acc:  0.80668473 ; epoch time:  0.305295467376709\n",
      "eval test...\n",
      "test acc:  0.79838705\n",
      "test loss:  0.5220626\n",
      "\n",
      "\n",
      "Epoch:  552 Avg loss:  0.4882641 ; acc:  0.7831978 ; epoch time:  0.3258512020111084\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.52513576\n",
      "\n",
      "\n",
      "Epoch:  553 Avg loss:  0.48091966 ; acc:  0.78139114 ; epoch time:  0.32453274726867676\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.51472986\n",
      "\n",
      "\n",
      "Epoch:  554 Avg loss:  0.48928115 ; acc:  0.8084914 ; epoch time:  0.3334236145019531\n",
      "eval test...\n",
      "test acc:  0.79838705\n",
      "test loss:  0.51734096\n",
      "\n",
      "\n",
      "Epoch:  555 Avg loss:  0.47880057 ; acc:  0.78500456 ; epoch time:  0.3405475616455078\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.5128019\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  556 Avg loss:  0.48116583 ; acc:  0.78139114 ; epoch time:  0.35562682151794434\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.51730293\n",
      "\n",
      "\n",
      "Epoch:  557 Avg loss:  0.48833144 ; acc:  0.80487806 ; epoch time:  0.3403024673461914\n",
      "eval test...\n",
      "test acc:  0.79838705\n",
      "test loss:  0.51610625\n",
      "\n",
      "\n",
      "Epoch:  558 Avg loss:  0.47663268 ; acc:  0.78590786 ; epoch time:  0.3093605041503906\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.51201427\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  559 Avg loss:  0.475016 ; acc:  0.78139114 ; epoch time:  0.3506343364715576\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.5103486\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  560 Avg loss:  0.48566648 ; acc:  0.8075881 ; epoch time:  0.3932983875274658\n",
      "eval test...\n",
      "test acc:  0.79838705\n",
      "test loss:  0.51326084\n",
      "\n",
      "\n",
      "Epoch:  561 Avg loss:  0.47839487 ; acc:  0.7904246 ; epoch time:  0.36091065406799316\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.51472646\n",
      "\n",
      "\n",
      "Epoch:  562 Avg loss:  0.47129825 ; acc:  0.78048784 ; epoch time:  0.3531227111816406\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.5046796\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  563 Avg loss:  0.47218043 ; acc:  0.78048784 ; epoch time:  0.3388521671295166\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.5029474\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  564 Avg loss:  0.48082173 ; acc:  0.7958446 ; epoch time:  0.36840033531188965\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.51785344\n",
      "\n",
      "\n",
      "Epoch:  565 Avg loss:  0.49109426 ; acc:  0.80397475 ; epoch time:  0.3203892707824707\n",
      "eval test...\n",
      "test acc:  0.79032254\n",
      "test loss:  0.51915485\n",
      "\n",
      "\n",
      "Epoch:  566 Avg loss:  0.47186422 ; acc:  0.7895212 ; epoch time:  0.353623628616333\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.50883764\n",
      "\n",
      "\n",
      "Epoch:  567 Avg loss:  0.47122085 ; acc:  0.78590786 ; epoch time:  0.33856844902038574\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.5081848\n",
      "\n",
      "\n",
      "Epoch:  568 Avg loss:  0.47313637 ; acc:  0.7831978 ; epoch time:  0.357438325881958\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.50429946\n",
      "\n",
      "\n",
      "Epoch:  569 Avg loss:  0.46893927 ; acc:  0.78139114 ; epoch time:  0.32878637313842773\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.5045391\n",
      "\n",
      "\n",
      "Epoch:  570 Avg loss:  0.4686726 ; acc:  0.78500456 ; epoch time:  0.3724637031555176\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.50556284\n",
      "\n",
      "\n",
      "Epoch:  571 Avg loss:  0.46736252 ; acc:  0.78048784 ; epoch time:  0.35795068740844727\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.4998821\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  572 Avg loss:  0.46509516 ; acc:  0.7841012 ; epoch time:  0.36133337020874023\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.50123477\n",
      "\n",
      "\n",
      "Epoch:  573 Avg loss:  0.46339557 ; acc:  0.78139114 ; epoch time:  0.3443300724029541\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.49932912\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  574 Avg loss:  0.46339518 ; acc:  0.78500456 ; epoch time:  0.35033440589904785\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.49585164\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  575 Avg loss:  0.46789914 ; acc:  0.7931346 ; epoch time:  0.32985544204711914\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.50525934\n",
      "\n",
      "\n",
      "Epoch:  576 Avg loss:  0.4684033 ; acc:  0.78048784 ; epoch time:  0.37276601791381836\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4988252\n",
      "\n",
      "\n",
      "Epoch:  577 Avg loss:  0.46664262 ; acc:  0.7931346 ; epoch time:  0.3214073181152344\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.50399035\n",
      "\n",
      "\n",
      "Epoch:  578 Avg loss:  0.46724722 ; acc:  0.78048784 ; epoch time:  0.3482780456542969\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.49790922\n",
      "\n",
      "\n",
      "Epoch:  579 Avg loss:  0.46526852 ; acc:  0.7931346 ; epoch time:  0.3563547134399414\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.50327903\n",
      "\n",
      "\n",
      "Epoch:  580 Avg loss:  0.45898432 ; acc:  0.78139114 ; epoch time:  0.35626673698425293\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.49230126\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  581 Avg loss:  0.45791414 ; acc:  0.78500456 ; epoch time:  0.34403038024902344\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.49236786\n",
      "\n",
      "\n",
      "Epoch:  582 Avg loss:  0.4586648 ; acc:  0.78590786 ; epoch time:  0.3761000633239746\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.496741\n",
      "\n",
      "\n",
      "Epoch:  583 Avg loss:  0.45800155 ; acc:  0.78681123 ; epoch time:  0.36917757987976074\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.49165475\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  584 Avg loss:  0.45813447 ; acc:  0.7895212 ; epoch time:  0.32107973098754883\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.49661237\n",
      "\n",
      "\n",
      "Epoch:  585 Avg loss:  0.45833698 ; acc:  0.78139114 ; epoch time:  0.3633730411529541\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.49157733\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  586 Avg loss:  0.4588234 ; acc:  0.7895212 ; epoch time:  0.3368542194366455\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.49773648\n",
      "\n",
      "\n",
      "Epoch:  587 Avg loss:  0.4556189 ; acc:  0.77958447 ; epoch time:  0.3815760612487793\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.48930344\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  588 Avg loss:  0.45284453 ; acc:  0.7841012 ; epoch time:  0.35761594772338867\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.48977908\n",
      "\n",
      "\n",
      "Epoch:  589 Avg loss:  0.45619035 ; acc:  0.79223126 ; epoch time:  0.33592987060546875\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.49481663\n",
      "\n",
      "\n",
      "Epoch:  590 Avg loss:  0.46241403 ; acc:  0.77868116 ; epoch time:  0.30635523796081543\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.49372214\n",
      "\n",
      "\n",
      "Epoch:  591 Avg loss:  0.47013053 ; acc:  0.802168 ; epoch time:  0.38730788230895996\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5096346\n",
      "\n",
      "\n",
      "Epoch:  592 Avg loss:  0.46539566 ; acc:  0.7777778 ; epoch time:  0.31549692153930664\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.49610546\n",
      "\n",
      "\n",
      "Epoch:  593 Avg loss:  0.45648348 ; acc:  0.7931346 ; epoch time:  0.34470653533935547\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4954676\n",
      "\n",
      "\n",
      "Epoch:  594 Avg loss:  0.45654276 ; acc:  0.77958447 ; epoch time:  0.3391706943511963\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.48934555\n",
      "\n",
      "\n",
      "Epoch:  595 Avg loss:  0.4625376 ; acc:  0.796748 ; epoch time:  0.357654333114624\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.50256944\n",
      "\n",
      "\n",
      "Epoch:  596 Avg loss:  0.46094817 ; acc:  0.7777778 ; epoch time:  0.3520171642303467\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.49345994\n",
      "\n",
      "\n",
      "Epoch:  597 Avg loss:  0.45936626 ; acc:  0.796748 ; epoch time:  0.32776451110839844\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.49988738\n",
      "\n",
      "\n",
      "Epoch:  598 Avg loss:  0.45436662 ; acc:  0.78139114 ; epoch time:  0.35201239585876465\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.48847565\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  599 Avg loss:  0.44910797 ; acc:  0.7895212 ; epoch time:  0.35010385513305664\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.48921138\n",
      "\n",
      "\n",
      "Epoch:  600 Avg loss:  0.44780925 ; acc:  0.78139114 ; epoch time:  0.34402966499328613\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.48604333\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  601 Avg loss:  0.4474197 ; acc:  0.78500456 ; epoch time:  0.3345921039581299\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.48446432\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  602 Avg loss:  0.44606715 ; acc:  0.78590786 ; epoch time:  0.32651662826538086\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4857342\n",
      "\n",
      "\n",
      "Epoch:  603 Avg loss:  0.44484165 ; acc:  0.78139114 ; epoch time:  0.341109037399292\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4836152\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  604 Avg loss:  0.44398287 ; acc:  0.78590786 ; epoch time:  0.3159050941467285\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.48381484\n",
      "\n",
      "\n",
      "Epoch:  605 Avg loss:  0.4430762 ; acc:  0.78139114 ; epoch time:  0.36246228218078613\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4820034\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  606 Avg loss:  0.44370958 ; acc:  0.78139114 ; epoch time:  0.31859779357910156\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4820411\n",
      "\n",
      "\n",
      "Epoch:  607 Avg loss:  0.45673856 ; acc:  0.802168 ; epoch time:  0.3389132022857666\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.49731806\n",
      "\n",
      "\n",
      "Epoch:  608 Avg loss:  0.47189388 ; acc:  0.7759711 ; epoch time:  0.36127662658691406\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.50231993\n",
      "\n",
      "\n",
      "Epoch:  609 Avg loss:  0.4649941 ; acc:  0.80668473 ; epoch time:  0.39492201805114746\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.50713474\n",
      "\n",
      "\n",
      "Epoch:  610 Avg loss:  0.4440999 ; acc:  0.78500456 ; epoch time:  0.3540618419647217\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4817902\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  611 Avg loss:  0.44183 ; acc:  0.7841012 ; epoch time:  0.38086700439453125\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4806689\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  612 Avg loss:  0.4593299 ; acc:  0.80036134 ; epoch time:  0.34975743293762207\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5015262\n",
      "\n",
      "\n",
      "Epoch:  613 Avg loss:  0.46257642 ; acc:  0.7768744 ; epoch time:  0.3573305606842041\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.49569574\n",
      "\n",
      "\n",
      "Epoch:  614 Avg loss:  0.45833555 ; acc:  0.80668473 ; epoch time:  0.3533957004547119\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.500852\n",
      "\n",
      "\n",
      "Epoch:  615 Avg loss:  0.44095117 ; acc:  0.78139114 ; epoch time:  0.35414958000183105\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.47930297\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  616 Avg loss:  0.44946924 ; acc:  0.7777778 ; epoch time:  0.3661770820617676\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4849327\n",
      "\n",
      "\n",
      "Epoch:  617 Avg loss:  0.46888024 ; acc:  0.81029814 ; epoch time:  0.3458716869354248\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.51382136\n",
      "\n",
      "\n",
      "Epoch:  618 Avg loss:  0.44192147 ; acc:  0.78500456 ; epoch time:  0.3493492603302002\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.47947404\n",
      "\n",
      "\n",
      "Epoch:  619 Avg loss:  0.4466599 ; acc:  0.77868116 ; epoch time:  0.38136887550354004\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.4825864\n",
      "\n",
      "\n",
      "Epoch:  620 Avg loss:  0.469326 ; acc:  0.8084914 ; epoch time:  0.33742809295654297\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.5146983\n",
      "\n",
      "\n",
      "Epoch:  621 Avg loss:  0.44013926 ; acc:  0.78500456 ; epoch time:  0.3370678424835205\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.47759977\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  622 Avg loss:  0.45160004 ; acc:  0.7777778 ; epoch time:  0.3634378910064697\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.48624355\n",
      "\n",
      "\n",
      "Epoch:  623 Avg loss:  0.501158 ; acc:  0.7777778 ; epoch time:  0.35903263092041016\n",
      "eval test...\n",
      "test acc:  0.7177419\n",
      "test loss:  0.5514847\n",
      "\n",
      "\n",
      "Epoch:  624 Avg loss:  0.4368901 ; acc:  0.7841012 ; epoch time:  0.3257777690887451\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4753257\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  625 Avg loss:  0.4736522 ; acc:  0.802168 ; epoch time:  0.39769840240478516\n",
      "eval test...\n",
      "test acc:  0.78225803\n",
      "test loss:  0.50516087\n",
      "\n",
      "\n",
      "Epoch:  626 Avg loss:  0.50448465 ; acc:  0.7777778 ; epoch time:  0.35527825355529785\n",
      "eval test...\n",
      "test acc:  0.7177419\n",
      "test loss:  0.55590826\n",
      "\n",
      "\n",
      "Epoch:  627 Avg loss:  0.4367083 ; acc:  0.78590786 ; epoch time:  0.3565044403076172\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4775039\n",
      "\n",
      "\n",
      "Epoch:  628 Avg loss:  0.54161847 ; acc:  0.7037037 ; epoch time:  0.3572087287902832\n",
      "eval test...\n",
      "test acc:  0.6774193\n",
      "test loss:  0.5684103\n",
      "\n",
      "\n",
      "Epoch:  629 Avg loss:  0.46087283 ; acc:  0.7958446 ; epoch time:  0.36215901374816895\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.50570816\n",
      "\n",
      "\n",
      "Epoch:  630 Avg loss:  0.47776386 ; acc:  0.80036134 ; epoch time:  0.3501920700073242\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.52608836\n",
      "\n",
      "\n",
      "Epoch:  631 Avg loss:  0.4846637 ; acc:  0.7822945 ; epoch time:  0.35222744941711426\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.5143864\n",
      "\n",
      "\n",
      "Epoch:  632 Avg loss:  0.43860352 ; acc:  0.78139114 ; epoch time:  0.3299832344055176\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.47737283\n",
      "\n",
      "\n",
      "Epoch:  633 Avg loss:  0.48988146 ; acc:  0.8274616 ; epoch time:  0.349790096282959\n",
      "eval test...\n",
      "test acc:  0.78225803\n",
      "test loss:  0.53943384\n",
      "\n",
      "\n",
      "Epoch:  634 Avg loss:  0.43446395 ; acc:  0.78139114 ; epoch time:  0.3876614570617676\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.47399566\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  635 Avg loss:  0.46318677 ; acc:  0.77416444 ; epoch time:  0.3300790786743164\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4955927\n",
      "\n",
      "\n",
      "Epoch:  636 Avg loss:  0.47632664 ; acc:  0.8328817 ; epoch time:  0.40357065200805664\n",
      "eval test...\n",
      "test acc:  0.80645156\n",
      "test loss:  0.5223175\n",
      "\n",
      "\n",
      "Epoch:  637 Avg loss:  0.43749335 ; acc:  0.796748 ; epoch time:  0.3920407295227051\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.47875974\n",
      "\n",
      "\n",
      "Epoch:  638 Avg loss:  0.52222747 ; acc:  0.7199639 ; epoch time:  0.3814208507537842\n",
      "eval test...\n",
      "test acc:  0.6774193\n",
      "test loss:  0.5516344\n",
      "\n",
      "\n",
      "Epoch:  639 Avg loss:  0.44753736 ; acc:  0.7931346 ; epoch time:  0.38149285316467285\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4904178\n",
      "\n",
      "\n",
      "Epoch:  640 Avg loss:  0.47341448 ; acc:  0.80036134 ; epoch time:  0.3982360363006592\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.5219392\n",
      "\n",
      "\n",
      "Epoch:  641 Avg loss:  0.45295578 ; acc:  0.80487806 ; epoch time:  0.34741902351379395\n",
      "eval test...\n",
      "test acc:  0.79838705\n",
      "test loss:  0.4876267\n",
      "\n",
      "\n",
      "Epoch:  642 Avg loss:  0.43998712 ; acc:  0.7822945 ; epoch time:  0.43335437774658203\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.47753203\n",
      "\n",
      "\n",
      "Epoch:  643 Avg loss:  0.461962 ; acc:  0.80668473 ; epoch time:  0.3916587829589844\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.5077998\n",
      "\n",
      "\n",
      "Epoch:  644 Avg loss:  0.43249825 ; acc:  0.7931346 ; epoch time:  0.3946878910064697\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.47433665\n",
      "\n",
      "\n",
      "Epoch:  645 Avg loss:  0.4729026 ; acc:  0.7714544 ; epoch time:  0.3828132152557373\n",
      "eval test...\n",
      "test acc:  0.7177419\n",
      "test loss:  0.50649333\n",
      "\n",
      "\n",
      "Epoch:  646 Avg loss:  0.45481047 ; acc:  0.8256549 ; epoch time:  0.4059114456176758\n",
      "eval test...\n",
      "test acc:  0.78225803\n",
      "test loss:  0.49800843\n",
      "\n",
      "\n",
      "Epoch:  647 Avg loss:  0.44618183 ; acc:  0.8157182 ; epoch time:  0.38144922256469727\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.48867688\n",
      "\n",
      "\n",
      "Epoch:  648 Avg loss:  0.47109288 ; acc:  0.7732611 ; epoch time:  0.38938355445861816\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.5045444\n",
      "\n",
      "\n",
      "Epoch:  649 Avg loss:  0.43292415 ; acc:  0.79223126 ; epoch time:  0.34963178634643555\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.47484127\n",
      "\n",
      "\n",
      "Epoch:  650 Avg loss:  0.44824216 ; acc:  0.7958446 ; epoch time:  0.335773229598999\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.49201974\n",
      "\n",
      "\n",
      "Epoch:  651 Avg loss:  0.43557957 ; acc:  0.78048784 ; epoch time:  0.34368228912353516\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.47413537\n",
      "\n",
      "\n",
      "Epoch:  652 Avg loss:  0.43353754 ; acc:  0.78139114 ; epoch time:  0.43524837493896484\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.47257152\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  653 Avg loss:  0.4461145 ; acc:  0.80036134 ; epoch time:  0.4586458206176758\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.48935848\n",
      "\n",
      "\n",
      "Epoch:  654 Avg loss:  0.4288135 ; acc:  0.7931346 ; epoch time:  0.46828770637512207\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4705944\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  655 Avg loss:  0.4491902 ; acc:  0.78139114 ; epoch time:  0.41193675994873047\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.48464325\n",
      "\n",
      "\n",
      "Epoch:  656 Avg loss:  0.44565743 ; acc:  0.8193315 ; epoch time:  0.38167691230773926\n",
      "eval test...\n",
      "test acc:  0.7741935\n",
      "test loss:  0.488165\n",
      "\n",
      "\n",
      "Epoch:  657 Avg loss:  0.434603 ; acc:  0.8030714 ; epoch time:  0.4369370937347412\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.47645906\n",
      "\n",
      "\n",
      "Epoch:  658 Avg loss:  0.46646342 ; acc:  0.7714544 ; epoch time:  0.39850902557373047\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.49999574\n",
      "\n",
      "\n",
      "Epoch:  659 Avg loss:  0.43462723 ; acc:  0.7958446 ; epoch time:  0.4476456642150879\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.47665244\n",
      "\n",
      "\n",
      "Epoch:  660 Avg loss:  0.4422375 ; acc:  0.796748 ; epoch time:  0.36529088020324707\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.48542032\n",
      "\n",
      "\n",
      "Epoch:  661 Avg loss:  0.43817544 ; acc:  0.77868116 ; epoch time:  0.41515254974365234\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.47536558\n",
      "\n",
      "\n",
      "Epoch:  662 Avg loss:  0.4291336 ; acc:  0.78500456 ; epoch time:  0.35524630546569824\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.47001594\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  663 Avg loss:  0.44654876 ; acc:  0.8030714 ; epoch time:  0.3936464786529541\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.49064755\n",
      "\n",
      "\n",
      "Epoch:  664 Avg loss:  0.42637268 ; acc:  0.7931346 ; epoch time:  0.3709712028503418\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4682859\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  665 Avg loss:  0.44843534 ; acc:  0.77958447 ; epoch time:  0.3523225784301758\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.48401573\n",
      "\n",
      "\n",
      "Epoch:  666 Avg loss:  0.44085193 ; acc:  0.8130081 ; epoch time:  0.3960838317871094\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.48353985\n",
      "\n",
      "\n",
      "Epoch:  667 Avg loss:  0.43488297 ; acc:  0.8057814 ; epoch time:  0.37415122985839844\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.4772467\n",
      "\n",
      "\n",
      "Epoch:  668 Avg loss:  0.45215806 ; acc:  0.7759711 ; epoch time:  0.41649627685546875\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.48749748\n",
      "\n",
      "\n",
      "Epoch:  669 Avg loss:  0.4290906 ; acc:  0.7958446 ; epoch time:  0.3731117248535156\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.4713211\n",
      "\n",
      "\n",
      "Epoch:  670 Avg loss:  0.4323377 ; acc:  0.7958446 ; epoch time:  0.41445374488830566\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.47486767\n",
      "\n",
      "\n",
      "Epoch:  671 Avg loss:  0.43314534 ; acc:  0.77958447 ; epoch time:  0.40494608879089355\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.47169918\n",
      "\n",
      "\n",
      "Epoch:  672 Avg loss:  0.42446083 ; acc:  0.78139114 ; epoch time:  0.3881988525390625\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4665239\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  673 Avg loss:  0.4308093 ; acc:  0.7958446 ; epoch time:  0.40826940536499023\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.47336504\n",
      "\n",
      "\n",
      "Epoch:  674 Avg loss:  0.42422405 ; acc:  0.78590786 ; epoch time:  0.4215247631072998\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46646947\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  675 Avg loss:  0.43022588 ; acc:  0.77868116 ; epoch time:  0.3637266159057617\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46941853\n",
      "\n",
      "\n",
      "Epoch:  676 Avg loss:  0.43418804 ; acc:  0.8084914 ; epoch time:  0.3765223026275635\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.47699854\n",
      "\n",
      "\n",
      "Epoch:  677 Avg loss:  0.42411023 ; acc:  0.796748 ; epoch time:  0.34122133255004883\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.46665445\n",
      "\n",
      "\n",
      "Epoch:  678 Avg loss:  0.4335136 ; acc:  0.78139114 ; epoch time:  0.37207889556884766\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4717694\n",
      "\n",
      "\n",
      "Epoch:  679 Avg loss:  0.42557904 ; acc:  0.796748 ; epoch time:  0.429394006729126\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.46807343\n",
      "\n",
      "\n",
      "Epoch:  680 Avg loss:  0.42322046 ; acc:  0.7931346 ; epoch time:  0.35892295837402344\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46573752\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  681 Avg loss:  0.4298018 ; acc:  0.7822945 ; epoch time:  0.4252762794494629\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46935928\n",
      "\n",
      "\n",
      "Epoch:  682 Avg loss:  0.42518225 ; acc:  0.7958446 ; epoch time:  0.3499624729156494\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.46787125\n",
      "\n",
      "\n",
      "Epoch:  683 Avg loss:  0.4222552 ; acc:  0.7931346 ; epoch time:  0.39296507835388184\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46501476\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  684 Avg loss:  0.4234757 ; acc:  0.78139114 ; epoch time:  0.3479278087615967\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46568343\n",
      "\n",
      "\n",
      "Epoch:  685 Avg loss:  0.4215605 ; acc:  0.7931346 ; epoch time:  0.39279890060424805\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46438447\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  686 Avg loss:  0.4229179 ; acc:  0.7931346 ; epoch time:  0.38588547706604004\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46574935\n",
      "\n",
      "\n",
      "Epoch:  687 Avg loss:  0.4268272 ; acc:  0.77958447 ; epoch time:  0.37625837326049805\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46755874\n",
      "\n",
      "\n",
      "Epoch:  688 Avg loss:  0.42506677 ; acc:  0.796748 ; epoch time:  0.35431623458862305\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.46805376\n",
      "\n",
      "\n",
      "Epoch:  689 Avg loss:  0.42070302 ; acc:  0.7931346 ; epoch time:  0.37381410598754883\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46366295\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  690 Avg loss:  0.42386225 ; acc:  0.78590786 ; epoch time:  0.38486146926879883\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46580046\n",
      "\n",
      "\n",
      "Epoch:  691 Avg loss:  0.4286467 ; acc:  0.8030714 ; epoch time:  0.37863922119140625\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.47208533\n",
      "\n",
      "\n",
      "Epoch:  692 Avg loss:  0.42003223 ; acc:  0.7931346 ; epoch time:  0.3615117073059082\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46314403\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  693 Avg loss:  0.42800218 ; acc:  0.78048784 ; epoch time:  0.3791325092315674\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46843344\n",
      "\n",
      "\n",
      "Epoch:  694 Avg loss:  0.42651135 ; acc:  0.80036134 ; epoch time:  0.3983137607574463\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.47000977\n",
      "\n",
      "\n",
      "Epoch:  695 Avg loss:  0.4209444 ; acc:  0.7931346 ; epoch time:  0.4048309326171875\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46417522\n",
      "\n",
      "\n",
      "Epoch:  696 Avg loss:  0.43815055 ; acc:  0.78139114 ; epoch time:  0.41114354133605957\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.47595498\n",
      "\n",
      "\n",
      "Epoch:  697 Avg loss:  0.4319956 ; acc:  0.8030714 ; epoch time:  0.37212514877319336\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.4763944\n",
      "\n",
      "\n",
      "Epoch:  698 Avg loss:  0.42786735 ; acc:  0.80036134 ; epoch time:  0.4014401435852051\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.47181377\n",
      "\n",
      "\n",
      "Epoch:  699 Avg loss:  0.4388981 ; acc:  0.7768744 ; epoch time:  0.3863224983215332\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.47670352\n",
      "\n",
      "\n",
      "Epoch:  700 Avg loss:  0.42280957 ; acc:  0.7931346 ; epoch time:  0.391035795211792\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4663565\n",
      "\n",
      "\n",
      "Epoch:  701 Avg loss:  0.4256072 ; acc:  0.796748 ; epoch time:  0.40027523040771484\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.4694455\n",
      "\n",
      "\n",
      "Epoch:  702 Avg loss:  0.42662013 ; acc:  0.7822945 ; epoch time:  0.38263869285583496\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46772805\n",
      "\n",
      "\n",
      "Epoch:  703 Avg loss:  0.41861582 ; acc:  0.7931346 ; epoch time:  0.3711104393005371\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46214134\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  704 Avg loss:  0.42079553 ; acc:  0.796748 ; epoch time:  0.35657238960266113\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.46446857\n",
      "\n",
      "\n",
      "Epoch:  705 Avg loss:  0.42305028 ; acc:  0.7831978 ; epoch time:  0.4030318260192871\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46529296\n",
      "\n",
      "\n",
      "Epoch:  706 Avg loss:  0.4213155 ; acc:  0.80036134 ; epoch time:  0.3864631652832031\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.46514106\n",
      "\n",
      "\n",
      "Epoch:  707 Avg loss:  0.4178271 ; acc:  0.7958446 ; epoch time:  0.38519811630249023\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.46179187\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  708 Avg loss:  0.4195563 ; acc:  0.7895212 ; epoch time:  0.41294074058532715\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46331477\n",
      "\n",
      "\n",
      "Epoch:  709 Avg loss:  0.41853252 ; acc:  0.7958446 ; epoch time:  0.35979747772216797\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.46218914\n",
      "\n",
      "\n",
      "Epoch:  710 Avg loss:  0.41688788 ; acc:  0.79223126 ; epoch time:  0.3679780960083008\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4605535\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  711 Avg loss:  0.41814935 ; acc:  0.78590786 ; epoch time:  0.37798619270324707\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46168512\n",
      "\n",
      "\n",
      "Epoch:  712 Avg loss:  0.42010897 ; acc:  0.7958446 ; epoch time:  0.34858059883117676\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.46357256\n",
      "\n",
      "\n",
      "Epoch:  713 Avg loss:  0.416273 ; acc:  0.79223126 ; epoch time:  0.3789985179901123\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45983663\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  714 Avg loss:  0.41966602 ; acc:  0.78590786 ; epoch time:  0.40059852600097656\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46326247\n",
      "\n",
      "\n",
      "Epoch:  715 Avg loss:  0.4204732 ; acc:  0.80036134 ; epoch time:  0.3732945919036865\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.4642189\n",
      "\n",
      "\n",
      "Epoch:  716 Avg loss:  0.41611776 ; acc:  0.7958446 ; epoch time:  0.3741593360900879\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.46000993\n",
      "\n",
      "\n",
      "Epoch:  717 Avg loss:  0.41900912 ; acc:  0.78771454 ; epoch time:  0.3944404125213623\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46307984\n",
      "\n",
      "\n",
      "Epoch:  718 Avg loss:  0.42275578 ; acc:  0.8030714 ; epoch time:  0.3974292278289795\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.4669714\n",
      "\n",
      "\n",
      "Epoch:  719 Avg loss:  0.41571394 ; acc:  0.7931346 ; epoch time:  0.38193655014038086\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45983782\n",
      "\n",
      "\n",
      "Epoch:  720 Avg loss:  0.42137262 ; acc:  0.77958447 ; epoch time:  0.3801698684692383\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46450818\n",
      "\n",
      "\n",
      "Epoch:  721 Avg loss:  0.4274289 ; acc:  0.80668473 ; epoch time:  0.35640430450439453\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.47250813\n",
      "\n",
      "\n",
      "Epoch:  722 Avg loss:  0.4177976 ; acc:  0.7931346 ; epoch time:  0.3534998893737793\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46181396\n",
      "\n",
      "\n",
      "Epoch:  723 Avg loss:  0.43732515 ; acc:  0.7777778 ; epoch time:  0.3709545135498047\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.47606343\n",
      "\n",
      "\n",
      "Epoch:  724 Avg loss:  0.42337662 ; acc:  0.80036134 ; epoch time:  0.36905503273010254\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.46801376\n",
      "\n",
      "\n",
      "Epoch:  725 Avg loss:  0.42536244 ; acc:  0.80036134 ; epoch time:  0.3839230537414551\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.4703833\n",
      "\n",
      "\n",
      "Epoch:  726 Avg loss:  0.42626128 ; acc:  0.78139114 ; epoch time:  0.4214310646057129\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46794003\n",
      "\n",
      "\n",
      "Epoch:  727 Avg loss:  0.41518685 ; acc:  0.7931346 ; epoch time:  0.39138126373291016\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45921472\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  728 Avg loss:  0.4157665 ; acc:  0.7958446 ; epoch time:  0.3810248374938965\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.46000376\n",
      "\n",
      "\n",
      "Epoch:  729 Avg loss:  0.41864458 ; acc:  0.7822945 ; epoch time:  0.38080310821533203\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46276057\n",
      "\n",
      "\n",
      "Epoch:  730 Avg loss:  0.42250285 ; acc:  0.8084914 ; epoch time:  0.39850354194641113\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.46724084\n",
      "\n",
      "\n",
      "Epoch:  731 Avg loss:  0.4148499 ; acc:  0.796748 ; epoch time:  0.39149904251098633\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45954826\n",
      "\n",
      "\n",
      "Epoch:  732 Avg loss:  0.41944075 ; acc:  0.7822945 ; epoch time:  0.42685437202453613\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46326613\n",
      "\n",
      "\n",
      "Epoch:  733 Avg loss:  0.42349485 ; acc:  0.8084914 ; epoch time:  0.4083089828491211\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.46829924\n",
      "\n",
      "\n",
      "Epoch:  734 Avg loss:  0.4158231 ; acc:  0.7958446 ; epoch time:  0.38062500953674316\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45994577\n",
      "\n",
      "\n",
      "Epoch:  735 Avg loss:  0.4325529 ; acc:  0.78139114 ; epoch time:  0.41745686531066895\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4725692\n",
      "\n",
      "\n",
      "Epoch:  736 Avg loss:  0.41902205 ; acc:  0.7958446 ; epoch time:  0.3978297710418701\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.4632858\n",
      "\n",
      "\n",
      "Epoch:  737 Avg loss:  0.42285213 ; acc:  0.80036134 ; epoch time:  0.3743886947631836\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.46774\n",
      "\n",
      "\n",
      "Epoch:  738 Avg loss:  0.4201033 ; acc:  0.7831978 ; epoch time:  0.37879252433776855\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46399724\n",
      "\n",
      "\n",
      "Epoch:  739 Avg loss:  0.41318554 ; acc:  0.79223126 ; epoch time:  0.37299323081970215\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4572373\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  740 Avg loss:  0.4189991 ; acc:  0.80036134 ; epoch time:  0.38321399688720703\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.4633249\n",
      "\n",
      "\n",
      "Epoch:  741 Avg loss:  0.41321215 ; acc:  0.7931346 ; epoch time:  0.40026283264160156\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45769575\n",
      "\n",
      "\n",
      "Epoch:  742 Avg loss:  0.4173857 ; acc:  0.7822945 ; epoch time:  0.39264678955078125\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46196344\n",
      "\n",
      "\n",
      "Epoch:  743 Avg loss:  0.42078763 ; acc:  0.8084914 ; epoch time:  0.35665345191955566\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.46525857\n",
      "\n",
      "\n",
      "Epoch:  744 Avg loss:  0.41371515 ; acc:  0.796748 ; epoch time:  0.4201319217681885\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.4578226\n",
      "\n",
      "\n",
      "Epoch:  745 Avg loss:  0.43328172 ; acc:  0.78139114 ; epoch time:  0.39574575424194336\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.47327796\n",
      "\n",
      "\n",
      "Epoch:  746 Avg loss:  0.42192468 ; acc:  0.80668473 ; epoch time:  0.4157247543334961\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.46670374\n",
      "\n",
      "\n",
      "Epoch:  747 Avg loss:  0.42138103 ; acc:  0.8030714 ; epoch time:  0.3887801170349121\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.46618322\n",
      "\n",
      "\n",
      "Epoch:  748 Avg loss:  0.42605564 ; acc:  0.7841012 ; epoch time:  0.39017200469970703\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46794245\n",
      "\n",
      "\n",
      "Epoch:  749 Avg loss:  0.41433978 ; acc:  0.79223126 ; epoch time:  0.3892171382904053\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4579861\n",
      "\n",
      "\n",
      "Epoch:  750 Avg loss:  0.4170793 ; acc:  0.7931346 ; epoch time:  0.39787983894348145\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46112338\n",
      "\n",
      "\n",
      "Epoch:  751 Avg loss:  0.4133878 ; acc:  0.78590786 ; epoch time:  0.3886260986328125\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45749694\n",
      "\n",
      "\n",
      "Epoch:  752 Avg loss:  0.41168657 ; acc:  0.7931346 ; epoch time:  0.40138769149780273\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4558803\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  753 Avg loss:  0.41167846 ; acc:  0.7931346 ; epoch time:  0.40238118171691895\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45612285\n",
      "\n",
      "\n",
      "Epoch:  754 Avg loss:  0.41186228 ; acc:  0.7958446 ; epoch time:  0.36653566360473633\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45644626\n",
      "\n",
      "\n",
      "Epoch:  755 Avg loss:  0.4118611 ; acc:  0.796748 ; epoch time:  0.3768775463104248\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.4565345\n",
      "\n",
      "\n",
      "Epoch:  756 Avg loss:  0.4115917 ; acc:  0.7958446 ; epoch time:  0.39597010612487793\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45626074\n",
      "\n",
      "\n",
      "Epoch:  757 Avg loss:  0.41112775 ; acc:  0.7931346 ; epoch time:  0.4044921398162842\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45548904\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  758 Avg loss:  0.4112661 ; acc:  0.7931346 ; epoch time:  0.39804911613464355\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4551641\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  759 Avg loss:  0.41685605 ; acc:  0.77958447 ; epoch time:  0.3615422248840332\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46065226\n",
      "\n",
      "\n",
      "Epoch:  760 Avg loss:  0.41637766 ; acc:  0.80036134 ; epoch time:  0.3615429401397705\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.46029556\n",
      "\n",
      "\n",
      "Epoch:  761 Avg loss:  0.4140166 ; acc:  0.7958446 ; epoch time:  0.36690735816955566\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45769605\n",
      "\n",
      "\n",
      "Epoch:  762 Avg loss:  0.42002887 ; acc:  0.77868116 ; epoch time:  0.3536982536315918\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46366575\n",
      "\n",
      "\n",
      "Epoch:  763 Avg loss:  0.41214773 ; acc:  0.7931346 ; epoch time:  0.3565256595611572\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45601395\n",
      "\n",
      "\n",
      "Epoch:  764 Avg loss:  0.41260806 ; acc:  0.7958446 ; epoch time:  0.43407130241394043\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45662883\n",
      "\n",
      "\n",
      "Epoch:  765 Avg loss:  0.41523704 ; acc:  0.78681123 ; epoch time:  0.36302947998046875\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.46016422\n",
      "\n",
      "\n",
      "Epoch:  766 Avg loss:  0.4133946 ; acc:  0.80036134 ; epoch time:  0.3663475513458252\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45802245\n",
      "\n",
      "\n",
      "Epoch:  767 Avg loss:  0.41112313 ; acc:  0.796748 ; epoch time:  0.38995909690856934\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45605224\n",
      "\n",
      "\n",
      "Epoch:  768 Avg loss:  0.41423118 ; acc:  0.7895212 ; epoch time:  0.3792095184326172\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4600426\n",
      "\n",
      "\n",
      "Epoch:  769 Avg loss:  0.41432515 ; acc:  0.8030714 ; epoch time:  0.3664529323577881\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.4594366\n",
      "\n",
      "\n",
      "Epoch:  770 Avg loss:  0.41120613 ; acc:  0.7958446 ; epoch time:  0.387096643447876\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45644048\n",
      "\n",
      "\n",
      "Epoch:  771 Avg loss:  0.421998 ; acc:  0.7777778 ; epoch time:  0.38144993782043457\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.465662\n",
      "\n",
      "\n",
      "Epoch:  772 Avg loss:  0.4238703 ; acc:  0.8130081 ; epoch time:  0.40634584426879883\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.47041327\n",
      "\n",
      "\n",
      "Epoch:  773 Avg loss:  0.41689134 ; acc:  0.80036134 ; epoch time:  0.39795827865600586\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.4622919\n",
      "\n",
      "\n",
      "Epoch:  774 Avg loss:  0.4288803 ; acc:  0.7831978 ; epoch time:  0.3892343044281006\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.47099212\n",
      "\n",
      "\n",
      "Epoch:  775 Avg loss:  0.41432026 ; acc:  0.7931346 ; epoch time:  0.3684380054473877\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4593325\n",
      "\n",
      "\n",
      "Epoch:  776 Avg loss:  0.4201175 ; acc:  0.802168 ; epoch time:  0.38484811782836914\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.46614525\n",
      "\n",
      "\n",
      "Epoch:  777 Avg loss:  0.41310403 ; acc:  0.78139114 ; epoch time:  0.3865487575531006\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.45844924\n",
      "\n",
      "\n",
      "Epoch:  778 Avg loss:  0.41453785 ; acc:  0.77958447 ; epoch time:  0.3710594177246094\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4599932\n",
      "\n",
      "\n",
      "Epoch:  779 Avg loss:  0.4238171 ; acc:  0.8148148 ; epoch time:  0.33579111099243164\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.47041783\n",
      "\n",
      "\n",
      "Epoch:  780 Avg loss:  0.41304463 ; acc:  0.80036134 ; epoch time:  0.3648862838745117\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45795816\n",
      "\n",
      "\n",
      "Epoch:  781 Avg loss:  0.43200496 ; acc:  0.77958447 ; epoch time:  0.3318173885345459\n",
      "eval test...\n",
      "test acc:  0.7258064\n",
      "test loss:  0.4732968\n",
      "\n",
      "\n",
      "Epoch:  782 Avg loss:  0.4183689 ; acc:  0.8084914 ; epoch time:  0.3654813766479492\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.46372455\n",
      "\n",
      "\n",
      "Epoch:  783 Avg loss:  0.41966718 ; acc:  0.8084914 ; epoch time:  0.387378454208374\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.4653459\n",
      "\n",
      "\n",
      "Epoch:  784 Avg loss:  0.42050293 ; acc:  0.78139114 ; epoch time:  0.38785791397094727\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46454927\n",
      "\n",
      "\n",
      "Epoch:  785 Avg loss:  0.41160482 ; acc:  0.7931346 ; epoch time:  0.38847947120666504\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4554822\n",
      "\n",
      "\n",
      "Epoch:  786 Avg loss:  0.4145151 ; acc:  0.7958446 ; epoch time:  0.32758617401123047\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45879388\n",
      "\n",
      "\n",
      "Epoch:  787 Avg loss:  0.41077688 ; acc:  0.78500456 ; epoch time:  0.3886301517486572\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45449626\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  788 Avg loss:  0.4095454 ; acc:  0.7931346 ; epoch time:  0.3980741500854492\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45328993\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  789 Avg loss:  0.40849793 ; acc:  0.79223126 ; epoch time:  0.39981579780578613\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45280594\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  790 Avg loss:  0.4093834 ; acc:  0.7958446 ; epoch time:  0.3637523651123047\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45361075\n",
      "\n",
      "\n",
      "Epoch:  791 Avg loss:  0.40971318 ; acc:  0.7931346 ; epoch time:  0.37303638458251953\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.454815\n",
      "\n",
      "\n",
      "Epoch:  792 Avg loss:  0.41263807 ; acc:  0.8030714 ; epoch time:  0.3944814205169678\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45718914\n",
      "\n",
      "\n",
      "Epoch:  793 Avg loss:  0.4089191 ; acc:  0.796748 ; epoch time:  0.37285804748535156\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45380536\n",
      "\n",
      "\n",
      "Epoch:  794 Avg loss:  0.4257952 ; acc:  0.7768744 ; epoch time:  0.4233431816101074\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46869087\n",
      "\n",
      "\n",
      "Epoch:  795 Avg loss:  0.42850646 ; acc:  0.8256549 ; epoch time:  0.3919796943664551\n",
      "eval test...\n",
      "test acc:  0.78225803\n",
      "test loss:  0.47610244\n",
      "\n",
      "\n",
      "Epoch:  796 Avg loss:  0.41753313 ; acc:  0.8030714 ; epoch time:  0.3500518798828125\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.46304923\n",
      "\n",
      "\n",
      "Epoch:  797 Avg loss:  0.43296847 ; acc:  0.77868116 ; epoch time:  0.39374685287475586\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.47390082\n",
      "\n",
      "\n",
      "Epoch:  798 Avg loss:  0.4112402 ; acc:  0.7895212 ; epoch time:  0.3811302185058594\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4550532\n",
      "\n",
      "\n",
      "Epoch:  799 Avg loss:  0.42156795 ; acc:  0.80036134 ; epoch time:  0.36563563346862793\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.46844804\n",
      "\n",
      "\n",
      "Epoch:  800 Avg loss:  0.41030365 ; acc:  0.78139114 ; epoch time:  0.3861227035522461\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.45392898\n",
      "\n",
      "\n",
      "Epoch:  801 Avg loss:  0.4302168 ; acc:  0.77868116 ; epoch time:  0.3743171691894531\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.47182584\n",
      "\n",
      "\n",
      "Epoch:  802 Avg loss:  0.4206769 ; acc:  0.8084914 ; epoch time:  0.3956291675567627\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.4671546\n",
      "\n",
      "\n",
      "Epoch:  803 Avg loss:  0.42179933 ; acc:  0.8148148 ; epoch time:  0.37374019622802734\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.4683767\n",
      "\n",
      "\n",
      "Epoch:  804 Avg loss:  0.4218188 ; acc:  0.7777778 ; epoch time:  0.36799192428588867\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46563882\n",
      "\n",
      "\n",
      "Epoch:  805 Avg loss:  0.4096092 ; acc:  0.796748 ; epoch time:  0.3998692035675049\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.4537066\n",
      "\n",
      "\n",
      "Epoch:  806 Avg loss:  0.41246536 ; acc:  0.8030714 ; epoch time:  0.41301560401916504\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.4567931\n",
      "\n",
      "\n",
      "Epoch:  807 Avg loss:  0.40852594 ; acc:  0.79223126 ; epoch time:  0.4388613700866699\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4532214\n",
      "\n",
      "\n",
      "Epoch:  808 Avg loss:  0.40799996 ; acc:  0.7931346 ; epoch time:  0.37673354148864746\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4521609\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  809 Avg loss:  0.4072526 ; acc:  0.7931346 ; epoch time:  0.3779103755950928\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45174783\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  810 Avg loss:  0.4085721 ; acc:  0.7958446 ; epoch time:  0.335629940032959\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.4526301\n",
      "\n",
      "\n",
      "Epoch:  811 Avg loss:  0.40722415 ; acc:  0.7931346 ; epoch time:  0.3209352493286133\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45167986\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  812 Avg loss:  0.40790892 ; acc:  0.7931346 ; epoch time:  0.3176126480102539\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45192727\n",
      "\n",
      "\n",
      "Epoch:  813 Avg loss:  0.40746525 ; acc:  0.79223126 ; epoch time:  0.31809568405151367\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45187578\n",
      "\n",
      "\n",
      "Epoch:  814 Avg loss:  0.4116268 ; acc:  0.802168 ; epoch time:  0.31151676177978516\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.4558314\n",
      "\n",
      "\n",
      "Epoch:  815 Avg loss:  0.40837848 ; acc:  0.7958446 ; epoch time:  0.3224637508392334\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45245054\n",
      "\n",
      "\n",
      "Epoch:  816 Avg loss:  0.4169958 ; acc:  0.77868116 ; epoch time:  0.32989954948425293\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46206176\n",
      "\n",
      "\n",
      "Epoch:  817 Avg loss:  0.4121765 ; acc:  0.8030714 ; epoch time:  0.3591609001159668\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45671836\n",
      "\n",
      "\n",
      "Epoch:  818 Avg loss:  0.4129541 ; acc:  0.8030714 ; epoch time:  0.32958078384399414\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45773533\n",
      "\n",
      "\n",
      "Epoch:  819 Avg loss:  0.41148776 ; acc:  0.7822945 ; epoch time:  0.32815074920654297\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45672378\n",
      "\n",
      "\n",
      "Epoch:  820 Avg loss:  0.40800366 ; acc:  0.7931346 ; epoch time:  0.313183069229126\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45239198\n",
      "\n",
      "\n",
      "Epoch:  821 Avg loss:  0.40842935 ; acc:  0.7958446 ; epoch time:  0.3155548572540283\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45289052\n",
      "\n",
      "\n",
      "Epoch:  822 Avg loss:  0.40830418 ; acc:  0.7895212 ; epoch time:  0.3314087390899658\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45374703\n",
      "\n",
      "\n",
      "Epoch:  823 Avg loss:  0.40724078 ; acc:  0.7931346 ; epoch time:  0.29784250259399414\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4520843\n",
      "\n",
      "\n",
      "Epoch:  824 Avg loss:  0.4068174 ; acc:  0.7931346 ; epoch time:  0.3315856456756592\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4519476\n",
      "\n",
      "\n",
      "Epoch:  825 Avg loss:  0.4103322 ; acc:  0.78681123 ; epoch time:  0.3321399688720703\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45644864\n",
      "\n",
      "\n",
      "Epoch:  826 Avg loss:  0.4142834 ; acc:  0.8084914 ; epoch time:  0.2987983226776123\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.45968422\n",
      "\n",
      "\n",
      "Epoch:  827 Avg loss:  0.40934914 ; acc:  0.80036134 ; epoch time:  0.3169991970062256\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45434806\n",
      "\n",
      "\n",
      "Epoch:  828 Avg loss:  0.41727117 ; acc:  0.7777778 ; epoch time:  0.30849719047546387\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4629651\n",
      "\n",
      "\n",
      "Epoch:  829 Avg loss:  0.41793194 ; acc:  0.8121048 ; epoch time:  0.33719873428344727\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.46435058\n",
      "\n",
      "\n",
      "Epoch:  830 Avg loss:  0.41396007 ; acc:  0.8030714 ; epoch time:  0.3097662925720215\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.459482\n",
      "\n",
      "\n",
      "Epoch:  831 Avg loss:  0.417198 ; acc:  0.7831978 ; epoch time:  0.31772851943969727\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46199012\n",
      "\n",
      "\n",
      "Epoch:  832 Avg loss:  0.40756616 ; acc:  0.7895212 ; epoch time:  0.2951533794403076\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45157567\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  833 Avg loss:  0.40962285 ; acc:  0.7931346 ; epoch time:  0.3142740726470947\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45378587\n",
      "\n",
      "\n",
      "Epoch:  834 Avg loss:  0.40717742 ; acc:  0.7931346 ; epoch time:  0.35262179374694824\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45130366\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  835 Avg loss:  0.41355252 ; acc:  0.77868116 ; epoch time:  0.33160996437072754\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4588159\n",
      "\n",
      "\n",
      "Epoch:  836 Avg loss:  0.4128331 ; acc:  0.8084914 ; epoch time:  0.31514906883239746\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.45797473\n",
      "\n",
      "\n",
      "Epoch:  837 Avg loss:  0.4114105 ; acc:  0.8057814 ; epoch time:  0.3183472156524658\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45627725\n",
      "\n",
      "\n",
      "Epoch:  838 Avg loss:  0.41441894 ; acc:  0.78681123 ; epoch time:  0.29204678535461426\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4604548\n",
      "\n",
      "\n",
      "Epoch:  839 Avg loss:  0.40786687 ; acc:  0.80036134 ; epoch time:  0.32183289527893066\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45247635\n",
      "\n",
      "\n",
      "Epoch:  840 Avg loss:  0.408893 ; acc:  0.80036134 ; epoch time:  0.30518054962158203\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45353785\n",
      "\n",
      "\n",
      "Epoch:  841 Avg loss:  0.40709597 ; acc:  0.79223126 ; epoch time:  0.30025386810302734\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4524452\n",
      "\n",
      "\n",
      "Epoch:  842 Avg loss:  0.40772748 ; acc:  0.7958446 ; epoch time:  0.30960702896118164\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.4521847\n",
      "\n",
      "\n",
      "Epoch:  843 Avg loss:  0.40733975 ; acc:  0.7931346 ; epoch time:  0.31316280364990234\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4517642\n",
      "\n",
      "\n",
      "Epoch:  844 Avg loss:  0.4079044 ; acc:  0.7895212 ; epoch time:  0.3002893924713135\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45321724\n",
      "\n",
      "\n",
      "Epoch:  845 Avg loss:  0.4087986 ; acc:  0.80036134 ; epoch time:  0.30559635162353516\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45349184\n",
      "\n",
      "\n",
      "Epoch:  846 Avg loss:  0.40805078 ; acc:  0.7958446 ; epoch time:  0.3209717273712158\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45274845\n",
      "\n",
      "\n",
      "Epoch:  847 Avg loss:  0.40833148 ; acc:  0.78771454 ; epoch time:  0.3305349349975586\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4541403\n",
      "\n",
      "\n",
      "Epoch:  848 Avg loss:  0.40834987 ; acc:  0.80036134 ; epoch time:  0.3104672431945801\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45327175\n",
      "\n",
      "\n",
      "Epoch:  849 Avg loss:  0.40802425 ; acc:  0.80036134 ; epoch time:  0.35471439361572266\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45300016\n",
      "\n",
      "\n",
      "Epoch:  850 Avg loss:  0.407808 ; acc:  0.7904246 ; epoch time:  0.28703737258911133\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4539016\n",
      "\n",
      "\n",
      "Epoch:  851 Avg loss:  0.40623033 ; acc:  0.7931346 ; epoch time:  0.3268013000488281\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4512448\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  852 Avg loss:  0.4062292 ; acc:  0.7931346 ; epoch time:  0.3316981792449951\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45116916\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  853 Avg loss:  0.40695304 ; acc:  0.7904246 ; epoch time:  0.3111429214477539\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4527023\n",
      "\n",
      "\n",
      "Epoch:  854 Avg loss:  0.40674433 ; acc:  0.7958446 ; epoch time:  0.3019745349884033\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45137724\n",
      "\n",
      "\n",
      "Epoch:  855 Avg loss:  0.40623415 ; acc:  0.7931346 ; epoch time:  0.3079946041107178\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4508674\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  856 Avg loss:  0.40842226 ; acc:  0.78771454 ; epoch time:  0.3118560314178467\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45383272\n",
      "\n",
      "\n",
      "Epoch:  857 Avg loss:  0.41048682 ; acc:  0.8030714 ; epoch time:  0.31311821937561035\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45548537\n",
      "\n",
      "\n",
      "Epoch:  858 Avg loss:  0.40823922 ; acc:  0.80036134 ; epoch time:  0.3078179359436035\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45269707\n",
      "\n",
      "\n",
      "Epoch:  859 Avg loss:  0.4113794 ; acc:  0.7822945 ; epoch time:  0.30389881134033203\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45674157\n",
      "\n",
      "\n",
      "Epoch:  860 Avg loss:  0.40855235 ; acc:  0.80036134 ; epoch time:  0.3056769371032715\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45302844\n",
      "\n",
      "\n",
      "Epoch:  861 Avg loss:  0.409239 ; acc:  0.80036134 ; epoch time:  0.33823180198669434\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45393288\n",
      "\n",
      "\n",
      "Epoch:  862 Avg loss:  0.4071586 ; acc:  0.7895212 ; epoch time:  0.3271667957305908\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45208055\n",
      "\n",
      "\n",
      "Epoch:  863 Avg loss:  0.4067798 ; acc:  0.7958446 ; epoch time:  0.3040294647216797\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45116335\n",
      "\n",
      "\n",
      "Epoch:  864 Avg loss:  0.40660945 ; acc:  0.7958446 ; epoch time:  0.2917633056640625\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45108277\n",
      "\n",
      "\n",
      "Epoch:  865 Avg loss:  0.4060683 ; acc:  0.79223126 ; epoch time:  0.31240034103393555\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45143184\n",
      "\n",
      "\n",
      "Epoch:  866 Avg loss:  0.4083376 ; acc:  0.802168 ; epoch time:  0.30092716217041016\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45321438\n",
      "\n",
      "\n",
      "Epoch:  867 Avg loss:  0.4068116 ; acc:  0.80036134 ; epoch time:  0.3385488986968994\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45164093\n",
      "\n",
      "\n",
      "Epoch:  868 Avg loss:  0.4087026 ; acc:  0.78681123 ; epoch time:  0.3142106533050537\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45486093\n",
      "\n",
      "\n",
      "Epoch:  869 Avg loss:  0.4102493 ; acc:  0.8030714 ; epoch time:  0.3045032024383545\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45555997\n",
      "\n",
      "\n",
      "Epoch:  870 Avg loss:  0.40830445 ; acc:  0.802168 ; epoch time:  0.32489538192749023\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.4533536\n",
      "\n",
      "\n",
      "Epoch:  871 Avg loss:  0.4105004 ; acc:  0.7822945 ; epoch time:  0.31293320655822754\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45664006\n",
      "\n",
      "\n",
      "Epoch:  872 Avg loss:  0.40795255 ; acc:  0.80036134 ; epoch time:  0.32886481285095215\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45288906\n",
      "\n",
      "\n",
      "Epoch:  873 Avg loss:  0.4088551 ; acc:  0.80036134 ; epoch time:  0.3283214569091797\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45387784\n",
      "\n",
      "\n",
      "Epoch:  874 Avg loss:  0.40620285 ; acc:  0.7895212 ; epoch time:  0.3167426586151123\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4516228\n",
      "\n",
      "\n",
      "Epoch:  875 Avg loss:  0.40514714 ; acc:  0.79223126 ; epoch time:  0.30005478858947754\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45008674\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  876 Avg loss:  0.40493172 ; acc:  0.79223126 ; epoch time:  0.343097448348999\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.44987935\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  877 Avg loss:  0.40554357 ; acc:  0.79223126 ; epoch time:  0.29309988021850586\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4510416\n",
      "\n",
      "\n",
      "Epoch:  878 Avg loss:  0.40790176 ; acc:  0.802168 ; epoch time:  0.3073387145996094\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45263472\n",
      "\n",
      "\n",
      "Epoch:  879 Avg loss:  0.40642545 ; acc:  0.80036134 ; epoch time:  0.3209958076477051\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45096382\n",
      "\n",
      "\n",
      "Epoch:  880 Avg loss:  0.40949425 ; acc:  0.78681123 ; epoch time:  0.29732728004455566\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45520172\n",
      "\n",
      "\n",
      "Epoch:  881 Avg loss:  0.4100282 ; acc:  0.8057814 ; epoch time:  0.3148159980773926\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.4550895\n",
      "\n",
      "\n",
      "Epoch:  882 Avg loss:  0.40800583 ; acc:  0.802168 ; epoch time:  0.31604576110839844\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45243934\n",
      "\n",
      "\n",
      "Epoch:  883 Avg loss:  0.4104065 ; acc:  0.7822945 ; epoch time:  0.2905855178833008\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4553514\n",
      "\n",
      "\n",
      "Epoch:  884 Avg loss:  0.40657517 ; acc:  0.7958446 ; epoch time:  0.2911510467529297\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45060316\n",
      "\n",
      "\n",
      "Epoch:  885 Avg loss:  0.407889 ; acc:  0.80036134 ; epoch time:  0.29892969131469727\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45223606\n",
      "\n",
      "\n",
      "Epoch:  886 Avg loss:  0.40559906 ; acc:  0.7895212 ; epoch time:  0.2935323715209961\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4497208\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  887 Avg loss:  0.4051808 ; acc:  0.79223126 ; epoch time:  0.33345723152160645\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4498203\n",
      "\n",
      "\n",
      "Epoch:  888 Avg loss:  0.40551454 ; acc:  0.7958446 ; epoch time:  0.30059361457824707\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.4501561\n",
      "\n",
      "\n",
      "Epoch:  889 Avg loss:  0.40528506 ; acc:  0.796748 ; epoch time:  0.33186793327331543\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.45047575\n",
      "\n",
      "\n",
      "Epoch:  890 Avg loss:  0.4071453 ; acc:  0.7904246 ; epoch time:  0.3156163692474365\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45406473\n",
      "\n",
      "\n",
      "Epoch:  891 Avg loss:  0.40728512 ; acc:  0.8030714 ; epoch time:  0.3216569423675537\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45284492\n",
      "\n",
      "\n",
      "Epoch:  892 Avg loss:  0.40618038 ; acc:  0.80036134 ; epoch time:  0.31005382537841797\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.4516765\n",
      "\n",
      "\n",
      "Epoch:  893 Avg loss:  0.4086461 ; acc:  0.78681123 ; epoch time:  0.3476583957672119\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45551285\n",
      "\n",
      "\n",
      "Epoch:  894 Avg loss:  0.4093447 ; acc:  0.8030714 ; epoch time:  0.35697221755981445\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.4548579\n",
      "\n",
      "\n",
      "Epoch:  895 Avg loss:  0.40823844 ; acc:  0.80036134 ; epoch time:  0.3763117790222168\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45345345\n",
      "\n",
      "\n",
      "Epoch:  896 Avg loss:  0.40820846 ; acc:  0.77958447 ; epoch time:  0.3414335250854492\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4537883\n",
      "\n",
      "\n",
      "Epoch:  897 Avg loss:  0.4062817 ; acc:  0.7931346 ; epoch time:  0.3689863681793213\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45081124\n",
      "\n",
      "\n",
      "Epoch:  898 Avg loss:  0.40771276 ; acc:  0.7958446 ; epoch time:  0.37028980255126953\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.4526497\n",
      "\n",
      "\n",
      "Epoch:  899 Avg loss:  0.40482387 ; acc:  0.79223126 ; epoch time:  0.3653285503387451\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4495344\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  900 Avg loss:  0.41335547 ; acc:  0.77868116 ; epoch time:  0.38643336296081543\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.45947814\n",
      "\n",
      "\n",
      "Epoch:  901 Avg loss:  0.41622648 ; acc:  0.81752485 ; epoch time:  0.3721272945404053\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.46349102\n",
      "\n",
      "\n",
      "Epoch:  902 Avg loss:  0.41072768 ; acc:  0.8084914 ; epoch time:  0.3644425868988037\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.45647877\n",
      "\n",
      "\n",
      "Epoch:  903 Avg loss:  0.41970682 ; acc:  0.7777778 ; epoch time:  0.3582441806793213\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.46562362\n",
      "\n",
      "\n",
      "Epoch:  904 Avg loss:  0.41305247 ; acc:  0.8084914 ; epoch time:  0.34926772117614746\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.45953065\n",
      "\n",
      "\n",
      "Epoch:  905 Avg loss:  0.41301614 ; acc:  0.8057814 ; epoch time:  0.362640380859375\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45955622\n",
      "\n",
      "\n",
      "Epoch:  906 Avg loss:  0.41124228 ; acc:  0.77958447 ; epoch time:  0.37160348892211914\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.45535117\n",
      "\n",
      "\n",
      "Epoch:  907 Avg loss:  0.405464 ; acc:  0.7895212 ; epoch time:  0.3414621353149414\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.448803\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  908 Avg loss:  0.4106667 ; acc:  0.802168 ; epoch time:  0.33941102027893066\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.4563707\n",
      "\n",
      "\n",
      "Epoch:  909 Avg loss:  0.40559635 ; acc:  0.7931346 ; epoch time:  0.342893123626709\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.44934723\n",
      "\n",
      "\n",
      "Epoch:  910 Avg loss:  0.41237015 ; acc:  0.77868116 ; epoch time:  0.4014253616333008\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.45739558\n",
      "\n",
      "\n",
      "Epoch:  911 Avg loss:  0.40877306 ; acc:  0.8030714 ; epoch time:  0.35875582695007324\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45371842\n",
      "\n",
      "\n",
      "Epoch:  912 Avg loss:  0.40993452 ; acc:  0.8084914 ; epoch time:  0.36713194847106934\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.4552028\n",
      "\n",
      "\n",
      "Epoch:  913 Avg loss:  0.40739164 ; acc:  0.78681123 ; epoch time:  0.31424951553344727\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45288682\n",
      "\n",
      "\n",
      "Epoch:  914 Avg loss:  0.40471727 ; acc:  0.7958446 ; epoch time:  0.37131261825561523\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.44903976\n",
      "\n",
      "\n",
      "Epoch:  915 Avg loss:  0.40567926 ; acc:  0.80036134 ; epoch time:  0.39321136474609375\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.44999617\n",
      "\n",
      "\n",
      "Epoch:  916 Avg loss:  0.40369177 ; acc:  0.7931346 ; epoch time:  0.36837148666381836\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4484344\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  917 Avg loss:  0.41158378 ; acc:  0.77868116 ; epoch time:  0.3308603763580322\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.45753494\n",
      "\n",
      "\n",
      "Epoch:  918 Avg loss:  0.41540673 ; acc:  0.8148148 ; epoch time:  0.3841817378997803\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.46241564\n",
      "\n",
      "\n",
      "Epoch:  919 Avg loss:  0.41028464 ; acc:  0.8030714 ; epoch time:  0.33189821243286133\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.4558662\n",
      "\n",
      "\n",
      "Epoch:  920 Avg loss:  0.41324693 ; acc:  0.77868116 ; epoch time:  0.3657975196838379\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.45867658\n",
      "\n",
      "\n",
      "Epoch:  921 Avg loss:  0.4050883 ; acc:  0.7931346 ; epoch time:  0.35100579261779785\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.44891903\n",
      "\n",
      "\n",
      "Epoch:  922 Avg loss:  0.40905905 ; acc:  0.802168 ; epoch time:  0.35717010498046875\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45429334\n",
      "\n",
      "\n",
      "Epoch:  923 Avg loss:  0.4044035 ; acc:  0.79223126 ; epoch time:  0.3515350818634033\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.44824123\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  924 Avg loss:  0.41196343 ; acc:  0.77868116 ; epoch time:  0.35712385177612305\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4572933\n",
      "\n",
      "\n",
      "Epoch:  925 Avg loss:  0.4122908 ; acc:  0.8084914 ; epoch time:  0.37295103073120117\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.45849282\n",
      "\n",
      "\n",
      "Epoch:  926 Avg loss:  0.41008496 ; acc:  0.8057814 ; epoch time:  0.37244129180908203\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45553344\n",
      "\n",
      "\n",
      "Epoch:  927 Avg loss:  0.41012466 ; acc:  0.77868116 ; epoch time:  0.3309760093688965\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.45562625\n",
      "\n",
      "\n",
      "Epoch:  928 Avg loss:  0.40443256 ; acc:  0.7958446 ; epoch time:  0.3497927188873291\n",
      "eval test...\n",
      "test acc:  0.75\n",
      "test loss:  0.44838583\n",
      "\n",
      "\n",
      "Epoch:  929 Avg loss:  0.40673956 ; acc:  0.802168 ; epoch time:  0.36060523986816406\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45115986\n",
      "\n",
      "\n",
      "Epoch:  930 Avg loss:  0.40351897 ; acc:  0.7931346 ; epoch time:  0.369844913482666\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.44759837\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  931 Avg loss:  0.41330993 ; acc:  0.7777778 ; epoch time:  0.31543779373168945\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4588815\n",
      "\n",
      "\n",
      "Epoch:  932 Avg loss:  0.41394982 ; acc:  0.8148148 ; epoch time:  0.35028767585754395\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.46052074\n",
      "\n",
      "\n",
      "Epoch:  933 Avg loss:  0.41095775 ; acc:  0.8084914 ; epoch time:  0.3703289031982422\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.45671627\n",
      "\n",
      "\n",
      "Epoch:  934 Avg loss:  0.41121173 ; acc:  0.77868116 ; epoch time:  0.32631993293762207\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4560672\n",
      "\n",
      "\n",
      "Epoch:  935 Avg loss:  0.4041381 ; acc:  0.7931346 ; epoch time:  0.3499751091003418\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.44754347\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  936 Avg loss:  0.40702924 ; acc:  0.80036134 ; epoch time:  0.33963847160339355\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45145592\n",
      "\n",
      "\n",
      "Epoch:  937 Avg loss:  0.40393123 ; acc:  0.7931346 ; epoch time:  0.35986804962158203\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.44726542\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  938 Avg loss:  0.40887624 ; acc:  0.77868116 ; epoch time:  0.3369600772857666\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.45334813\n",
      "\n",
      "\n",
      "Epoch:  939 Avg loss:  0.40846992 ; acc:  0.8030714 ; epoch time:  0.37589287757873535\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.453439\n",
      "\n",
      "\n",
      "Epoch:  940 Avg loss:  0.40878102 ; acc:  0.8030714 ; epoch time:  0.3649590015411377\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45383945\n",
      "\n",
      "\n",
      "Epoch:  941 Avg loss:  0.40580243 ; acc:  0.78681123 ; epoch time:  0.3785543441772461\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45048144\n",
      "\n",
      "\n",
      "Epoch:  942 Avg loss:  0.40380803 ; acc:  0.7931346 ; epoch time:  0.3441181182861328\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.44760954\n",
      "\n",
      "\n",
      "Epoch:  943 Avg loss:  0.40472353 ; acc:  0.80036134 ; epoch time:  0.3431737422943115\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.44851652\n",
      "\n",
      "\n",
      "Epoch:  944 Avg loss:  0.40316156 ; acc:  0.7931346 ; epoch time:  0.34589481353759766\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.44726685\n",
      "\n",
      "\n",
      "Epoch:  945 Avg loss:  0.40879664 ; acc:  0.7822945 ; epoch time:  0.3381221294403076\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4542987\n",
      "\n",
      "\n",
      "Epoch:  946 Avg loss:  0.4114315 ; acc:  0.8121048 ; epoch time:  0.368884801864624\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.4573555\n",
      "\n",
      "\n",
      "Epoch:  947 Avg loss:  0.40789983 ; acc:  0.8030714 ; epoch time:  0.3589043617248535\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45279342\n",
      "\n",
      "\n",
      "Epoch:  948 Avg loss:  0.40940526 ; acc:  0.77868116 ; epoch time:  0.3724358081817627\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.4545594\n",
      "\n",
      "\n",
      "Epoch:  949 Avg loss:  0.4038363 ; acc:  0.7931346 ; epoch time:  0.3573493957519531\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4474469\n",
      "\n",
      "\n",
      "Epoch:  950 Avg loss:  0.40652412 ; acc:  0.80036134 ; epoch time:  0.35979795455932617\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45101205\n",
      "\n",
      "\n",
      "Epoch:  951 Avg loss:  0.40353078 ; acc:  0.7931346 ; epoch time:  0.35447144508361816\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.44707638\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  952 Avg loss:  0.40800396 ; acc:  0.77868116 ; epoch time:  0.3233516216278076\n",
      "eval test...\n",
      "test acc:  0.7338709\n",
      "test loss:  0.45268825\n",
      "\n",
      "\n",
      "Epoch:  953 Avg loss:  0.40835917 ; acc:  0.8030714 ; epoch time:  0.4160935878753662\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45354387\n",
      "\n",
      "\n",
      "Epoch:  954 Avg loss:  0.40826628 ; acc:  0.8030714 ; epoch time:  0.3744773864746094\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.45340288\n",
      "\n",
      "\n",
      "Epoch:  955 Avg loss:  0.4054658 ; acc:  0.7822945 ; epoch time:  0.3606445789337158\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.45018843\n",
      "\n",
      "\n",
      "Epoch:  956 Avg loss:  0.40365005 ; acc:  0.7931346 ; epoch time:  0.3713386058807373\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.44738698\n",
      "\n",
      "\n",
      "Epoch:  957 Avg loss:  0.40480608 ; acc:  0.80036134 ; epoch time:  0.35213637351989746\n",
      "eval test...\n",
      "test acc:  0.7580645\n",
      "test loss:  0.44869906\n",
      "\n",
      "\n",
      "Epoch:  958 Avg loss:  0.4029638 ; acc:  0.7931346 ; epoch time:  0.38709425926208496\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.44699055\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  959 Avg loss:  0.40784785 ; acc:  0.7822945 ; epoch time:  0.3768727779388428\n",
      "eval test...\n",
      "test acc:  0.7419355\n",
      "test loss:  0.4533382\n",
      "\n",
      "\n",
      "Epoch:  960 Avg loss:  0.41108736 ; acc:  0.8121048 ; epoch time:  0.3638041019439697\n",
      "eval test...\n",
      "test acc:  0.766129\n",
      "test loss:  0.4570162\n",
      "\n",
      "\n",
      "Exception ignored in: <function _releaseLock at 0x7f2ded28b5f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-51c2b114b34e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#train(gcn_model, dataset, max_epoch=1000, lr=0.005, train_batch_size = 1024, temp_name = 'community_temp')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnode_pred_task_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'grid_temp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/nightknight//git/hierarchcal-gnn-interpretations/train.py\u001b[0m in \u001b[0;36mnode_pred_task_train\u001b[0;34m(model, train_dataset, max_epoch, lr, train_batch_size, save_model, temp_name, train_rate)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mtotal_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0;31m#print(data.batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset.setting = 3\n",
    "dataset.subgraph = False\n",
    "dataset.remap = True\n",
    "#train(gcn_model, dataset, max_epoch=1000, lr=0.005, train_batch_size = 1024, temp_name = 'community_temp')\n",
    "node_pred_task_train(gcn_model, dataset, max_epoch=1000, lr=0.005, temp_name='grid_temp', train_rate = 0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "prepare dataloader\n",
      "done\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f7bcbb66ef0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f7bcbb66ef0>\n",
      "    Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7f7bcbb66ef0>\n",
      "\n",
      "      File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "self._shutdown_workers()  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7f7bcbb66ef0>self._shutdown_workers()\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)    \n",
      "w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()        \n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'assert self._parent_pid == os.getpid(), 'can only join a child process'    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    \n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionErrorAssertionError: can only join a child process\n",
      "Exception ignored in:     : <function _MultiProcessingDataLoaderIter.__del__ at 0x7f7bcbb66ef0>assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "\n",
      "    \n",
      "AssertionErrorself._shutdown_workers()Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f7bcbb66ef0>\n",
      "can only join a child processTraceback (most recent call last):\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "AssertionError:     can only join a child process: w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "can only join a child process\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "\n",
      "        assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "AssertionError:   File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionErrorcan only join a child process\n",
      ": can only join a child process\n",
      "Epoch:  0 Avg loss:  0.40357456 ; acc:  0.88285124 ; epoch time:  5.462222099304199\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Epoch:  1 Avg loss:  0.35714155 ; acc:  0.8461038 ; epoch time:  0.31096363067626953\n",
      "Epoch:  2 Avg loss:  0.35565862 ; acc:  0.86148036 ; epoch time:  0.2978708744049072\n",
      "Epoch:  3 Avg loss:  0.34551296 ; acc:  0.8526193 ; epoch time:  0.30245399475097656\n",
      "Epoch:  4 Avg loss:  0.3348266 ; acc:  0.8461038 ; epoch time:  0.30026888847351074\n",
      "Epoch:  5 Avg loss:  0.32270122 ; acc:  0.8573105 ; epoch time:  0.3187687397003174\n",
      "Epoch:  6 Avg loss:  0.3201576 ; acc:  0.87620544 ; epoch time:  0.2972133159637451\n",
      "Epoch:  7 Avg loss:  0.30944198 ; acc:  0.86121976 ; epoch time:  0.30271172523498535\n",
      "Epoch:  8 Avg loss:  0.30607358 ; acc:  0.86121976 ; epoch time:  0.2693314552307129\n",
      "Epoch:  9 Avg loss:  0.3003269 ; acc:  0.87255675 ; epoch time:  0.2797379493713379\n",
      "Epoch:  10 Avg loss:  0.29691172 ; acc:  0.8874121 ; epoch time:  0.293834924697876\n",
      "Epoch:  11 Avg loss:  0.29353994 ; acc:  0.88962734 ; epoch time:  0.2932589054107666\n",
      "Epoch:  12 Avg loss:  0.29041028 ; acc:  0.87920254 ; epoch time:  0.30799436569213867\n",
      "Epoch:  13 Avg loss:  0.28560925 ; acc:  0.9018765 ; epoch time:  0.30919504165649414\n",
      "Epoch:  14 Avg loss:  0.2806146 ; acc:  0.901225 ; epoch time:  0.2840909957885742\n",
      "Epoch:  15 Avg loss:  0.28248847 ; acc:  0.8909305 ; epoch time:  0.3043355941772461\n",
      "Epoch:  16 Avg loss:  0.2891435 ; acc:  0.90330994 ; epoch time:  0.29387402534484863\n",
      "Epoch:  17 Avg loss:  0.27324936 ; acc:  0.90226746 ; epoch time:  0.3056361675262451\n",
      "Epoch:  18 Avg loss:  0.26859626 ; acc:  0.90526456 ; epoch time:  0.29378437995910645\n",
      "Epoch:  19 Avg loss:  0.2641987 ; acc:  0.91073763 ; epoch time:  0.3064117431640625\n",
      "Epoch:  20 Avg loss:  0.26063418 ; acc:  0.90904355 ; epoch time:  0.31113696098327637\n",
      "Epoch:  21 Avg loss:  0.26048672 ; acc:  0.9108679 ; epoch time:  0.3084371089935303\n",
      "Epoch:  22 Avg loss:  0.25755823 ; acc:  0.9141257 ; epoch time:  0.2915313243865967\n",
      "Epoch:  23 Avg loss:  0.2553112 ; acc:  0.9119104 ; epoch time:  0.29827070236206055\n",
      "Epoch:  24 Avg loss:  0.24993405 ; acc:  0.9113892 ; epoch time:  0.2996656894683838\n",
      "Epoch:  25 Avg loss:  0.24659497 ; acc:  0.91164976 ; epoch time:  0.28685903549194336\n",
      "Epoch:  26 Avg loss:  0.24407803 ; acc:  0.9139954 ; epoch time:  0.31954383850097656\n",
      "Epoch:  27 Avg loss:  0.23967066 ; acc:  0.9132135 ; epoch time:  0.31216979026794434\n",
      "Epoch:  28 Avg loss:  0.24281791 ; acc:  0.9108679 ; epoch time:  0.29738426208496094\n",
      "Epoch:  29 Avg loss:  0.24092536 ; acc:  0.9215534 ; epoch time:  0.2966499328613281\n",
      "Epoch:  30 Avg loss:  0.23531571 ; acc:  0.9149075 ; epoch time:  0.3002610206604004\n",
      "Epoch:  31 Avg loss:  0.23416452 ; acc:  0.92011994 ; epoch time:  0.30069541931152344\n",
      "Epoch:  32 Avg loss:  0.23426887 ; acc:  0.923508 ; epoch time:  0.29673314094543457\n",
      "Epoch:  33 Avg loss:  0.23135424 ; acc:  0.9223352 ; epoch time:  0.2849597930908203\n",
      "Epoch:  34 Avg loss:  0.2344018 ; acc:  0.92754763 ; epoch time:  0.3092920780181885\n",
      "Epoch:  35 Avg loss:  0.22974774 ; acc:  0.9298932 ; epoch time:  0.2997782230377197\n",
      "Epoch:  36 Avg loss:  0.22640643 ; acc:  0.9296326 ; epoch time:  0.2910346984863281\n",
      "Epoch:  37 Avg loss:  0.22760789 ; acc:  0.9262445 ; epoch time:  0.31751441955566406\n",
      "Epoch:  38 Avg loss:  0.22218469 ; acc:  0.9323691 ; epoch time:  0.2924368381500244\n",
      "Epoch:  39 Avg loss:  0.22209291 ; acc:  0.93666935 ; epoch time:  0.30686140060424805\n",
      "Exception ignored in: <function _releaseLock at 0x7f7cc5c37560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-04ee7702ea48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/nightknight//git/hierarchcal-gnn-interpretations/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset, test_dataset, max_epoch, lr, batch_size, save_model)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtotal_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;31m#print(data.batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset.subgraph = True\n",
    "dataset.remap = True\n",
    "train(gcn_model, dataset, max_epoch=3000, lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_model = torch.load('./checkpoint/grid_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:  0 Avg loss:  0.41243014 ; acc:  0.77822906 ; epoch time:  0.029079437255859375\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(0.77822906, dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "dataset.subgraph = False\n",
    "dataset.remap = False\n",
    "eval(gcn_model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "index:  0\n",
      "tensor([1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "index:  1\n",
      "tensor([1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  2\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 0, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "index:  3\n",
      "tensor([1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  4\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[4]\n",
      "index:  5\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "index:  6\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 0, 1, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "index:  7\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "index:  8\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  9\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "index:  10\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "index:  11\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 0, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  12\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "index:  13\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[4, 13]\n",
      "index:  14\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  15\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 0, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  16\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  17\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  18\n",
      "tensor([1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "index:  19\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "index:  20\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 0, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  21\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "index:  22\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[4, 13, 22]\n",
      "index:  23\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  24\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 0, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  25\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  26\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  27\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "       device='cuda:0')\n",
      "tensor(11, device='cuda:0')\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       device='cuda:0')\n",
      "index:  28\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1],\n",
      "       device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0],\n",
      "       device='cuda:0')\n",
      "[4, 13, 22, 28]\n",
      "index:  29\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(11, device='cuda:0')\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "index:  30\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(10, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "index:  31\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "[4, 13, 22, 28, 31]\n",
      "index:  32\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(10, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 0, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "index:  33\n",
      "tensor([1, 1, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 1, 1, 0, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "index:  34\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(10, device='cuda:0')\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "index:  35\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "index:  36\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       device='cuda:0')\n",
      "index:  37\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "index:  38\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "index:  39\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "index:  40\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "[4, 13, 22, 28, 31, 40]\n",
      "index:  41\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  42\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "index:  43\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  44\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  45\n",
      "tensor([1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "index:  46\n",
      "tensor([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "index:  47\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "index:  48\n",
      "tensor([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "index:  49\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "[4, 13, 22, 28, 31, 40, 49]\n",
      "index:  50\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  51\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "index:  52\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  53\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  54\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "index:  55\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "index:  56\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 0, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  57\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "index:  58\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([0, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "[4, 13, 22, 28, 31, 40, 49, 58]\n",
      "index:  59\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  60\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 0, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  61\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  62\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "index:  63\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "index:  64\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "index:  65\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "index:  66\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "index:  67\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "[4, 13, 22, 28, 31, 40, 49, 58, 67]\n",
      "index:  68\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "index:  69\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "index:  70\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 1, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "index:  71\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "index:  72\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1],\n",
      "       device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0],\n",
      "       device='cuda:0')\n",
      "index:  73\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-89181fe3097c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#print(preds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/nightknight//git/hierarchcal-gnn-interpretations/utils.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(dataset, idx, batch_size, shuffle)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    185\u001b[0m         dataset at the specified indices.\"\"\"\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-83345713d9b1>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0msub_adj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msub_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msub_edge_label_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_adj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_adj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-83345713d9b1>\u001b[0m in \u001b[0;36mallnodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mallnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mallnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mallnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-83345713d9b1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mallnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mallnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mallnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset.setting = 3\n",
    "correct = 0\n",
    "dataset.subgraph = True\n",
    "dataset.remap = True\n",
    "#load_model = torch.load('./checkpoint/gcn_mix').to('cuda')\n",
    "load_model = gcn_model\n",
    "load_model.eval()\n",
    "in_correct = []\n",
    "for idx in range(dataset.len()):\n",
    "    print('index: ', idx)\n",
    "    data = get_data(dataset, idx).to('cuda')\n",
    "    pred = load_model.forward(data)\n",
    "    #print(preds)\n",
    "    label = data.y.to('cuda')\n",
    "\n",
    "    _, indices = torch.max(pred, 1)\n",
    "    #print(pred)\n",
    "    print(label)\n",
    "    print(torch.sum(label))\n",
    "    print(indices)\n",
    "    #print(torch.argmax(load_model(data)[0]))\n",
    "    if (indices[0] == 1.0):\n",
    "        correct += 1\n",
    "    else:\n",
    "        in_correct.append(idx)\n",
    "        print(in_correct)\n",
    "print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "index:  0\n",
      "target node:  0\n",
      "epoch time:  0.10573625564575195\n",
      "{0, 2, 4, 6, 11, 12, 13, 14}\n",
      "acc:  0.625\n",
      "auc:  0.7142857142857143\n",
      "mean acc:  0.625\n",
      "mean auc:  0.7142857142857143\n",
      "\n",
      "index:  1\n",
      "target node:  0\n",
      "epoch time:  0.07853150367736816\n",
      "{0, 2, 4, 6, 7, 8, 9, 10, 11}\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.962962962962963\n",
      "mean acc:  0.7569444444444444\n",
      "mean auc:  0.8386243386243386\n",
      "\n",
      "index:  2\n",
      "target node:  0\n",
      "epoch time:  0.06259751319885254\n",
      "{0, 2, 3, 4, 5, 6, 7, 8}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8379629629629629\n",
      "mean auc:  0.892416225749559\n",
      "\n",
      "index:  3\n",
      "target node:  0\n",
      "epoch time:  0.07952666282653809\n",
      "{0, 1, 4, 6, 7, 8, 9, 10, 11}\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.962962962962963\n",
      "mean acc:  0.8506944444444444\n",
      "mean auc:  0.91005291005291\n",
      "\n",
      "index:  5\n",
      "target node:  0\n",
      "epoch time:  0.06253337860107422\n",
      "foo\n",
      "\n",
      "index:  6\n",
      "target node:  0\n",
      "epoch time:  0.06470274925231934\n",
      "{0, 2, 3, 4, 5, 6, 7, 8}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8805555555555555\n",
      "mean auc:  0.928042328042328\n",
      "\n",
      "index:  7\n",
      "target node:  0\n",
      "epoch time:  0.06767058372497559\n",
      "foo\n",
      "\n",
      "index:  8\n",
      "target node:  0\n",
      "epoch time:  0.05823540687561035\n",
      "foo\n",
      "\n",
      "index:  9\n",
      "target node:  0\n",
      "epoch time:  0.14387798309326172\n",
      "{0, 5, 6, 7, 8, 10, 12, 13}\n",
      "acc:  0.375\n",
      "auc:  0.3375\n",
      "mean acc:  0.7962962962962963\n",
      "mean auc:  0.8296186067019401\n",
      "\n",
      "index:  10\n",
      "target node:  0\n",
      "epoch time:  0.09702467918395996\n",
      "{0, 3, 4, 5, 6, 7, 9, 11, 12}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8253968253968254\n",
      "mean auc:  0.8539588057445201\n",
      "\n",
      "index:  11\n",
      "target node:  0\n",
      "epoch time:  0.07428741455078125\n",
      "{0, 2, 3, 4, 5, 6, 7, 8}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8472222222222222\n",
      "mean auc:  0.8722139550264549\n",
      "\n",
      "index:  12\n",
      "target node:  0\n",
      "epoch time:  0.13274407386779785\n",
      "{0, 3, 4, 5, 6, 7, 9, 11, 12}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8641975308641975\n",
      "mean auc:  0.88641240446796\n",
      "\n",
      "index:  14\n",
      "target node:  0\n",
      "epoch time:  0.08634448051452637\n",
      "foo\n",
      "\n",
      "index:  15\n",
      "target node:  0\n",
      "epoch time:  0.09740829467773438\n",
      "{0, 2, 3, 4, 5, 6, 7, 8}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8777777777777779\n",
      "mean auc:  0.897771164021164\n",
      "\n",
      "index:  16\n",
      "target node:  0\n",
      "epoch time:  0.08850955963134766\n",
      "foo\n",
      "\n",
      "index:  17\n",
      "target node:  0\n",
      "epoch time:  0.09089422225952148\n",
      "foo\n",
      "\n",
      "index:  18\n",
      "target node:  0\n",
      "epoch time:  0.1421349048614502\n",
      "{0, 3, 6, 7, 9, 11, 16, 17}\n",
      "acc:  0.375\n",
      "auc:  0.3375\n",
      "mean acc:  0.8320707070707072\n",
      "mean auc:  0.8468374218374218\n",
      "\n",
      "index:  19\n",
      "target node:  0\n",
      "epoch time:  0.11371064186096191\n",
      "{0, 3, 4, 5, 6, 7, 8, 9, 10}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8460648148148149\n",
      "mean auc:  0.8596009700176367\n",
      "\n",
      "index:  20\n",
      "target node:  0\n",
      "epoch time:  0.08571887016296387\n",
      "{0, 2, 3, 4, 5, 6, 7, 8}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.857905982905983\n",
      "mean auc:  0.8704008954008954\n",
      "\n",
      "index:  21\n",
      "target node:  0\n",
      "epoch time:  0.11805534362792969\n",
      "{0, 3, 4, 5, 6, 7, 8, 9, 10}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8680555555555556\n",
      "mean auc:  0.8796579743008314\n",
      "\n",
      "index:  23\n",
      "target node:  0\n",
      "epoch time:  0.10926055908203125\n",
      "foo\n",
      "\n",
      "index:  24\n",
      "target node:  0\n",
      "epoch time:  0.10348010063171387\n",
      "{0, 2, 3, 4, 5, 6, 7, 8}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8768518518518519\n",
      "mean auc:  0.8876807760141093\n",
      "\n",
      "index:  25\n",
      "target node:  0\n",
      "epoch time:  0.09775543212890625\n",
      "foo\n",
      "\n",
      "index:  26\n",
      "target node:  0\n",
      "epoch time:  0.09352898597717285\n",
      "foo\n",
      "\n",
      "index:  27\n",
      "target node:  0\n",
      "epoch time:  0.1759786605834961\n",
      "{0, 5, 6, 7, 8, 9, 10, 11, 18, 19, 20}\n",
      "acc:  0.2727272727272727\n",
      "auc:  0.21818181818181814\n",
      "mean acc:  0.8390940656565656\n",
      "mean auc:  0.8458370911495912\n",
      "\n",
      "index:  29\n",
      "target node:  0\n",
      "epoch time:  0.13001680374145508\n",
      "{0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8485591206179441\n",
      "mean auc:  0.8549054975525564\n",
      "\n",
      "index:  30\n",
      "target node:  0\n",
      "epoch time:  0.12794923782348633\n",
      "{0, 1, 2, 3, 9, 10, 11, 12, 13}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8569725028058361\n",
      "mean auc:  0.8629663032440811\n",
      "\n",
      "index:  32\n",
      "target node:  0\n",
      "epoch time:  0.10917282104492188\n",
      "{0, 1, 2, 3, 5, 6, 7, 8, 9}\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.8888888888888888\n",
      "mean acc:  0.8586523125996809\n",
      "mean auc:  0.8643306498569657\n",
      "\n",
      "index:  33\n",
      "target node:  0\n",
      "epoch time:  0.10675716400146484\n",
      "{0, 1, 2, 4, 5, 6, 7, 8}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8657196969696969\n",
      "mean auc:  0.8711141173641174\n",
      "\n",
      "index:  34\n",
      "target node:  0\n",
      "epoch time:  0.11472582817077637\n",
      "{0, 1, 2, 4, 5, 6, 7, 8, 9}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8721139971139971\n",
      "mean auc:  0.8772515403467784\n",
      "\n",
      "index:  35\n",
      "target node:  0\n",
      "epoch time:  0.10528564453125\n",
      "foo\n",
      "\n",
      "index:  36\n",
      "target node:  0\n",
      "epoch time:  0.1786816120147705\n",
      "{0, 5, 6, 7, 8, 9, 10, 11}\n",
      "acc:  0.375\n",
      "auc:  0.375\n",
      "mean acc:  0.849517906336088\n",
      "mean auc:  0.8544219248764704\n",
      "\n",
      "index:  37\n",
      "target node:  0\n",
      "epoch time:  0.1294236183166504\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 9}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.856060606060606\n",
      "mean auc:  0.8607514064035804\n",
      "\n",
      "index:  38\n",
      "target node:  0\n",
      "epoch time:  0.1184999942779541\n",
      "{0, 1, 2, 3, 4, 5, 6, 7}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8620580808080809\n",
      "mean auc:  0.8665534311367645\n",
      "\n",
      "index:  39\n",
      "target node:  0\n",
      "epoch time:  0.14788484573364258\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 9}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8675757575757577\n",
      "mean auc:  0.8718912938912939\n",
      "\n",
      "index:  41\n",
      "target node:  0\n",
      "epoch time:  0.11571812629699707\n",
      "foo\n",
      "\n",
      "index:  42\n",
      "target node:  0\n",
      "epoch time:  0.11409592628479004\n",
      "{0, 1, 2, 3, 4, 5, 6, 7}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8726689976689977\n",
      "mean auc:  0.8768185518185518\n",
      "\n",
      "index:  43\n",
      "target node:  0\n",
      "epoch time:  0.11788630485534668\n",
      "foo\n",
      "\n",
      "index:  44\n",
      "target node:  0\n",
      "epoch time:  0.10838913917541504\n",
      "foo\n",
      "\n",
      "index:  45\n",
      "target node:  0\n",
      "epoch time:  0.17931461334228516\n",
      "{0, 2, 3, 5, 6, 7, 9, 11}\n",
      "acc:  0.375\n",
      "auc:  0.3375\n",
      "mean acc:  0.8542368125701459\n",
      "mean auc:  0.8568437906400869\n",
      "\n",
      "index:  46\n",
      "target node:  0\n",
      "epoch time:  0.1519608497619629\n",
      "{0, 1, 3, 4, 5, 6, 7, 8, 9}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8594426406926408\n",
      "mean auc:  0.8619565124029409\n",
      "\n",
      "index:  47\n",
      "target node:  0\n",
      "epoch time:  0.12923431396484375\n",
      "{0, 1, 2, 3, 4, 5, 6, 7}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.864289446185998\n",
      "mean auc:  0.8667166326649085\n",
      "\n",
      "index:  48\n",
      "target node:  0\n",
      "epoch time:  0.15230631828308105\n",
      "{0, 1, 2, 4, 5, 6, 7, 8, 9}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8688131313131314\n",
      "mean auc:  0.8711594115760782\n",
      "\n",
      "index:  50\n",
      "target node:  0\n",
      "epoch time:  0.1470012664794922\n",
      "foo\n",
      "\n",
      "index:  51\n",
      "target node:  0\n",
      "epoch time:  0.14262866973876953\n",
      "{0, 1, 2, 3, 4, 5, 6, 7}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8730449657869014\n",
      "mean auc:  0.8753155595897532\n",
      "\n",
      "index:  52\n",
      "target node:  0\n",
      "epoch time:  0.1253519058227539\n",
      "foo\n",
      "\n",
      "index:  53\n",
      "target node:  0\n",
      "epoch time:  0.12470269203186035\n",
      "foo\n",
      "\n",
      "index:  54\n",
      "target node:  0\n",
      "epoch time:  0.18376827239990234\n",
      "{0, 6, 11, 13, 14, 15, 16, 17}\n",
      "acc:  0.375\n",
      "auc:  0.3375\n",
      "mean acc:  0.8574810606060607\n",
      "mean auc:  0.8585088233525734\n",
      "\n",
      "index:  55\n",
      "target node:  0\n",
      "epoch time:  0.16640615463256836\n",
      "{0, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8617998163452709\n",
      "mean auc:  0.8627964347661318\n",
      "\n",
      "index:  56\n",
      "target node:  0\n",
      "epoch time:  0.1491868495941162\n",
      "{0, 2, 3, 4, 5, 6, 7, 8}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8658645276292336\n",
      "mean auc:  0.8668318337435985\n",
      "\n",
      "index:  57\n",
      "target node:  0\n",
      "epoch time:  0.16852450370788574\n",
      "{0, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8696969696969697\n",
      "mean auc:  0.8706366384937814\n",
      "\n",
      "index:  59\n",
      "target node:  0\n",
      "epoch time:  0.1576235294342041\n",
      "foo\n",
      "\n",
      "index:  60\n",
      "target node:  0\n",
      "epoch time:  0.15249967575073242\n",
      "{0, 2, 3, 4, 5, 6, 7, 8}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8733164983164984\n",
      "mean auc:  0.8742300652022874\n",
      "\n",
      "index:  61\n",
      "target node:  0\n",
      "epoch time:  0.13837003707885742\n",
      "foo\n",
      "\n",
      "index:  62\n",
      "target node:  0\n",
      "epoch time:  0.14406728744506836\n",
      "foo\n",
      "\n",
      "index:  63\n",
      "target node:  0\n",
      "epoch time:  0.1991429328918457\n",
      "{0, 1, 2, 3, 4, 5, 6, 17}\n",
      "acc:  0.375\n",
      "auc:  0.3375\n",
      "mean acc:  0.8598484848484849\n",
      "mean auc:  0.8597238472238472\n",
      "\n",
      "index:  64\n",
      "target node:  0\n",
      "epoch time:  0.1763167381286621\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 12}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.86353668261563\n",
      "mean auc:  0.8634153249284829\n",
      "\n",
      "index:  65\n",
      "target node:  0\n",
      "epoch time:  0.15359044075012207\n",
      "{0, 1, 2, 3, 4, 5, 7, 8}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.867035742035742\n",
      "mean auc:  0.8669174960841628\n",
      "\n",
      "index:  66\n",
      "target node:  0\n",
      "epoch time:  0.16386675834655762\n",
      "{0, 1, 2, 3, 4, 5, 6, 11, 12}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8703598484848485\n",
      "mean auc:  0.8702445586820587\n",
      "\n",
      "index:  68\n",
      "target node:  0\n",
      "epoch time:  0.1548478603363037\n",
      "foo\n",
      "\n",
      "index:  69\n",
      "target node:  0\n",
      "epoch time:  0.1473252773284912\n",
      "{0, 1, 2, 3, 4, 5, 7, 8}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8735218033998522\n",
      "mean auc:  0.873409325543472\n",
      "\n",
      "index:  70\n",
      "target node:  0\n",
      "epoch time:  0.15628719329833984\n",
      "foo\n",
      "\n",
      "index:  71\n",
      "target node:  0\n",
      "epoch time:  0.23227405548095703\n",
      "foo\n",
      "\n",
      "index:  72\n",
      "target node:  0\n",
      "epoch time:  0.34644198417663574\n",
      "{0, 9, 10, 11, 12, 13, 14, 15}\n",
      "acc:  0.5\n",
      "auc:  0.46590909090909094\n",
      "mean acc:  0.8646284271284271\n",
      "mean auc:  0.8637069390045582\n",
      "\n",
      "index:  73\n",
      "target node:  0\n",
      "epoch time:  0.2920706272125244\n",
      "{0, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14}\n",
      "acc:  0.9166666666666666\n",
      "auc:  0.9583333333333334\n",
      "mean acc:  0.8658386187455954\n",
      "mean auc:  0.8659075528261577\n",
      "\n",
      "index:  74\n",
      "target node:  0\n",
      "epoch time:  0.19366025924682617\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8688877410468319\n",
      "mean auc:  0.868955108443745\n",
      "\n",
      "index:  75\n",
      "target node:  0\n",
      "epoch time:  0.1897122859954834\n",
      "{0, 3, 4, 5, 6, 7, 8, 9, 10}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8718013468013467\n",
      "mean auc:  0.8718672171449952\n",
      "\n",
      "index:  76\n",
      "target node:  0\n",
      "epoch time:  0.18584561347961426\n",
      "{0, 1, 2, 3, 4, 5, 6, 8, 10}\n",
      "acc:  0.7777777777777778\n",
      "auc:  0.0\n",
      "target node:  0\n",
      "epoch time:  0.16654109954833984\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"231.84pt\" version=\"1.1\" viewBox=\"0 0 345.480125 231.84\" width=\"345.480125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-19T20:34:05.833435</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 231.84 \nL 345.480125 231.84 \nL 345.480125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 139.029345 125.191606 \nQ 139.388819 108.560822 139.748292 91.930037 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 152.867769 139.14461 \nQ 169.241364 138.931127 185.61496 138.717643 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 124.601005 138.531868 \nQ 108.252 137.609052 91.902994 136.686236 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 138.418139 153.469893 \nQ 138.067202 169.707125 137.716266 185.944356 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 218.707022 60.5514 \nQ 227.919856 52.286898 237.132689 44.022396 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 205.630604 89.766251 \nQ 205.599556 104.154759 205.568508 118.543267 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 188.149257 72.164628 \nQ 174.164698 72.098176 160.180139 72.031725 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 120.197738 71.165057 \nQ 106.221207 70.625353 92.244676 70.085648 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 139.748262 91.93145 \nQ 139.388807 108.561391 139.029351 125.191332 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 160.177777 72.031714 \nQ 174.164535 72.098176 188.151293 72.164637 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 92.246709 70.085727 \nQ 106.221044 70.625347 120.195379 71.164966 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 74.021209 86.913328 \nQ 73.430534 101.289707 72.839859 115.666086 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 62.219356 57.159232 \nQ 53.372251 48.503276 44.525145 39.847319 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 185.616292 138.717626 \nQ 169.240829 138.931134 152.865366 139.144642 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 204.740315 158.356768 \nQ 204.208924 171.823057 203.677533 185.289346 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 205.568499 118.547307 \nQ 205.599552 104.156447 205.630605 89.765586 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 72.839693 115.670123 \nQ 73.430465 101.291393 74.021236 86.912663 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 91.901664 136.686161 \nQ 108.252534 137.609082 124.603404 138.532003 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 71.947055 155.47819 \nQ 71.896119 168.954893 71.845184 182.431597 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 203.677469 185.290957 \nQ 204.208912 171.82335 204.740355 158.355743 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 184.70006 204.163948 \nQ 170.903783 204.631646 157.107506 205.099344 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 44.526089 39.848243 \nQ 53.373319 48.504321 62.220549 57.160399 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 71.845178 182.433209 \nQ 71.896118 168.955186 71.947059 155.477164 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 89.989353 202.11089 \nQ 103.752481 203.175997 117.515609 204.241105 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 237.131706 44.023278 \nQ 227.918743 52.287896 218.70578 60.552514 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 137.716256 185.944824 \nQ 138.06723 169.70583 138.418205 153.466836 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_28\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 157.10801 205.099327 \nQ 170.902768 204.63168 184.697527 204.164034 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_29\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 117.515107 204.241066 \nQ 103.753493 203.176076 89.99188 202.111086 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 138.723766 153.471159 \nC 142.474304 153.471159 146.071735 151.981055 148.723766 149.329024 \nC 151.375797 146.676993 152.865902 143.079562 152.865902 139.329024 \nC 152.865902 135.578486 151.375797 131.981055 148.723766 129.329024 \nC 146.071735 126.676993 142.474304 125.186888 138.723766 125.186888 \nC 134.973228 125.186888 131.375797 126.676993 128.723766 129.329024 \nC 126.071735 131.981055 124.58163 135.578486 124.58163 139.329024 \nC 124.58163 143.079562 126.071735 146.676993 128.723766 149.329024 \nC 131.375797 151.981055 134.973228 153.471159 138.723766 153.471159 \nz\n\" style=\"fill:#fff5eb;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 205.668405 89.763859 \nC 210.313699 89.763859 214.769358 87.918265 218.054077 84.633546 \nC 221.338795 81.348828 223.18439 76.893168 223.18439 72.247875 \nC 223.18439 67.602581 221.338795 63.146922 218.054077 59.862203 \nC 214.769358 56.577485 210.313699 54.73189 205.668405 54.73189 \nC 201.023112 54.73189 196.567452 56.577485 193.282734 59.862203 \nC 189.998015 63.146922 188.152421 67.602581 188.152421 72.247875 \nC 188.152421 76.893168 189.998015 81.348828 193.282734 84.633546 \nC 196.567452 87.918265 201.023112 89.763859 205.668405 89.763859 \nz\n\" style=\"fill:#fa8331;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 140.180448 91.936691 \nC 145.48451 91.936691 150.572045 89.829365 154.322583 86.078827 \nC 158.073121 82.328288 160.180448 77.240753 160.180448 71.936691 \nC 160.180448 66.632629 158.073121 61.545094 154.322583 57.794555 \nC 150.572045 54.044017 145.48451 51.936691 140.180448 51.936691 \nC 134.876386 51.936691 129.78885 54.044017 126.038312 57.794555 \nC 122.287774 61.545094 120.180448 66.632629 120.180448 71.936691 \nC 120.180448 77.240753 122.287774 82.328288 126.038312 86.078827 \nC 129.78885 89.829365 134.876386 91.936691 140.180448 91.936691 \nz\n\" style=\"fill:#7f2704;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 74.740371 86.926618 \nC 79.385907 86.926618 83.841799 85.080927 87.126689 81.796037 \nC 90.411579 78.511147 92.25727 74.055255 92.25727 69.409719 \nC 92.25727 64.764183 90.411579 60.30829 87.126689 57.0234 \nC 83.841799 53.73851 79.385907 51.892819 74.740371 51.892819 \nC 70.094834 51.892819 65.638942 53.73851 62.354052 57.0234 \nC 59.069162 60.30829 57.223471 64.764183 57.223471 69.409719 \nC 57.223471 74.055255 59.069162 78.511147 62.354052 81.796037 \nC 65.638942 85.080927 70.094834 86.926618 74.740371 86.926618 \nz\n\" style=\"fill:#fa8331;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 205.525535 158.370146 \nC 210.806287 158.370146 215.871463 156.272081 219.605518 152.538026 \nC 223.339573 148.803971 225.437638 143.738795 225.437638 138.458044 \nC 225.437638 133.177292 223.339573 128.112116 219.605518 124.378061 \nC 215.871463 120.644006 210.806287 118.545941 205.525535 118.545941 \nC 200.244784 118.545941 195.179608 120.644006 191.445553 124.378061 \nC 187.711498 128.112116 185.613433 133.177292 185.613433 138.458044 \nC 185.613433 143.738795 187.711498 148.803971 191.445553 152.538026 \nC 195.179608 156.272081 200.244784 158.370146 205.525535 158.370146 \nz\n\" style=\"fill:#842904;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 72.022321 155.476467 \nC 77.303149 155.476467 82.368398 153.378372 86.102508 149.644262 \nC 89.836617 145.910153 91.934712 140.844903 91.934712 135.564075 \nC 91.934712 130.283248 89.836617 125.217998 86.102508 121.483889 \nC 82.368398 117.749779 77.303149 115.651684 72.022321 115.651684 \nC 66.741493 115.651684 61.676243 117.749779 57.942134 121.483889 \nC 54.208025 125.217998 52.109929 130.283248 52.109929 135.564075 \nC 52.109929 140.844903 54.208025 145.910153 57.942134 149.644262 \nC 61.676243 153.378372 66.741493 155.476467 72.022321 155.476467 \nz\n\" style=\"fill:#842904;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 202.957148 221.81287 \nC 207.801837 221.81287 212.448751 219.888055 215.874463 216.462343 \nC 219.300175 213.036631 221.224991 208.389716 221.224991 203.545027 \nC 221.224991 198.700339 219.300175 194.053424 215.874463 190.627712 \nC 212.448751 187.202 207.801837 185.277185 202.957148 185.277185 \nC 198.11246 185.277185 193.465545 187.202 190.039833 190.627712 \nC 186.614121 194.053424 184.689306 198.700339 184.689306 203.545027 \nC 184.689306 208.389716 186.614121 213.036631 190.039833 216.462343 \nC 193.465545 219.888055 198.11246 221.81287 202.957148 221.81287 \nz\n\" style=\"fill:#e85d0c;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 30.442314 45.770681 \nC 35.667324 45.770681 40.679035 43.694762 44.373676 40.000122 \nC 48.068316 36.305482 50.144234 31.293771 50.144234 26.06876 \nC 50.144234 20.84375 48.068316 15.832039 44.373676 12.137399 \nC 40.679035 8.442759 35.667324 6.36684 30.442314 6.36684 \nC 25.217304 6.36684 20.205593 8.442759 16.510953 12.137399 \nC 12.816312 15.832039 10.740394 20.84375 10.740394 26.06876 \nC 10.740394 31.293771 12.816312 36.305482 16.510953 40.000122 \nC 20.205593 43.694762 25.217304 45.770681 30.442314 45.770681 \nz\n\" style=\"fill:#912e04;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 71.776133 218.969183 \nC 76.620806 218.969183 81.267706 217.044373 84.693407 213.618672 \nC 88.119109 210.192971 90.043918 205.546071 90.043918 200.701397 \nC 90.043918 195.856724 88.119109 191.209824 84.693407 187.784122 \nC 81.267706 184.358421 76.620806 182.433612 71.776133 182.433612 \nC 66.931459 182.433612 62.284559 184.358421 58.858858 187.784122 \nC 55.433156 191.209824 53.508347 195.856724 53.508347 200.701397 \nC 53.508347 205.546071 55.433156 210.192971 58.858858 213.618672 \nC 62.284559 217.044373 66.931459 218.969183 71.776133 218.969183 \nz\n\" style=\"fill:#e85d0c;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 251.797686 50.568723 \nC 257.022656 50.568723 262.034329 48.492821 265.728941 44.798209 \nC 269.423553 41.103596 271.499456 36.091924 271.499456 30.866953 \nC 271.499456 25.641983 269.423553 20.63031 265.728941 16.935698 \nC 262.034329 13.241086 257.022656 11.165183 251.797686 11.165183 \nC 246.572715 11.165183 241.561043 13.241086 237.866431 16.935698 \nC 234.171819 20.63031 232.095916 25.641983 232.095916 30.866953 \nC 232.095916 36.091924 234.171819 41.103596 237.866431 44.798209 \nC 241.561043 48.492821 246.572715 50.568723 251.797686 50.568723 \nz\n\" style=\"fill:#912e04;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p85469fe759)\" d=\"M 137.287747 225.602304 \nC 142.547006 225.602304 147.591569 223.512778 151.310427 219.79392 \nC 155.029285 216.075062 157.118811 211.030499 157.118811 205.77124 \nC 157.118811 200.51198 155.029285 195.467418 151.310427 191.748559 \nC 147.591569 188.029701 142.547006 185.940175 137.287747 185.940175 \nC 132.028487 185.940175 126.983925 188.029701 123.265066 191.748559 \nC 119.546208 195.467418 117.456682 200.51198 117.456682 205.77124 \nC 117.456682 211.030499 119.546208 216.075062 123.265066 219.79392 \nC 126.983925 223.512778 132.028487 225.602304 137.287747 225.602304 \nz\n\" style=\"fill:#892b04;stroke:#0000ff;\"/>\n   </g>\n   <g id=\"text_1\">\n    <g clip-path=\"url(#p85469fe759)\">\n     <!-- 0 -->\n     <g transform=\"translate(134.906266 142.640274)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-48\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_2\">\n    <g clip-path=\"url(#p85469fe759)\">\n     <!-- 1 -->\n     <g transform=\"translate(201.850905 75.559125)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-49\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_3\">\n    <g clip-path=\"url(#p85469fe759)\">\n     <!-- 2 -->\n     <g transform=\"translate(136.362948 75.247941)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-50\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_4\">\n    <g clip-path=\"url(#p85469fe759)\">\n     <!-- 3 -->\n     <g transform=\"translate(70.922871 72.720969)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-51\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_5\">\n    <g clip-path=\"url(#p85469fe759)\">\n     <!-- 4 -->\n     <g transform=\"translate(201.708035 141.769294)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-52\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_6\">\n    <g clip-path=\"url(#p85469fe759)\">\n     <!-- 5 -->\n     <g transform=\"translate(68.204821 138.875325)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-53\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_7\">\n    <g clip-path=\"url(#p85469fe759)\">\n     <!-- 6 -->\n     <g transform=\"translate(199.139648 206.856277)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-54\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_8\">\n    <g clip-path=\"url(#p85469fe759)\">\n     <!-- 7 -->\n     <g transform=\"translate(26.624814 29.38001)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-55\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_9\">\n    <g clip-path=\"url(#p85469fe759)\">\n     <!-- 8 -->\n     <g transform=\"translate(67.958633 204.012647)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-56\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_10\">\n    <g clip-path=\"url(#p85469fe759)\">\n     <!-- 9 -->\n     <g transform=\"translate(247.980186 34.178203)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-57\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_11\">\n    <g clip-path=\"url(#p85469fe759)\">\n     <!-- 10 -->\n     <g transform=\"translate(129.652747 209.08249)scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_30\">\n    <path clip-path=\"url(#p0cfe4f724f)\" d=\"M 291.78 224.64 \nL 291.78 223.790625 \nL 291.78 8.049375 \nL 291.78 7.2 \nL 302.652 7.2 \nL 302.652 8.049375 \nL 302.652 223.790625 \nL 302.652 224.64 \nz\n\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;stroke-width:0.01;\"/>\n   </g>\n   <image height=\"218\" id=\"image0a47a2ac96\" transform=\"scale(1 -1)translate(0 -218)\" width=\"11\" x=\"292\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAAsAAADaCAYAAABwzrisAAABKUlEQVR4nO2aMQ7DMAwDlcL//2jnbrbVuZsuAAOqcGeCoEiZToJe+XlnFH8jclexMSLKxDEiCZgxl7FdB9QxAzcSyHiVkdHUjZ5xN5QhTFAHNhkQMS8Vc+g0A3CyAU/cd5k94mYyNnFDWLmyRlq65fdoUcSM4j5u/IAburGnhYzjxjPMrOs8NAvj9njsMWFmbpgMeOK+y0yqgHzfEGrWyUh20aN3K4vdSNnDSRI34GtpPzegDI+TQtzQhaJLEPkMVEgbSSbDxA0IJjJk/YxkwLj/3A3YSCrmLbytyljqc504xiLWAWwM4BzUrGOe+xIxm7iBElxsRYkMmWYkAw0Il58skocb02NFEbPOOqa5oXXsDHokyJgJeMkObMe4TRpJt0jsagMy0N91vp7vphoTEwrKAAAAAElFTkSuQmCC\" y=\"-6\"/>\n   <g id=\"matplotlib.axis_1\"/>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 3.5 0 \n\" id=\"m81f0438710\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#m81f0438710\" y=\"203.818503\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.290 -->\n      <g transform=\"translate(309.652 207.617721)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#m81f0438710\" y=\"178.395484\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.292 -->\n      <g transform=\"translate(309.652 182.194703)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#m81f0438710\" y=\"152.972466\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.294 -->\n      <g transform=\"translate(309.652 156.771685)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#m81f0438710\" y=\"127.549448\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.296 -->\n      <g transform=\"translate(309.652 131.348667)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#m81f0438710\" y=\"102.12643\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.298 -->\n      <g transform=\"translate(309.652 105.925649)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#m81f0438710\" y=\"76.703412\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 0.300 -->\n      <g transform=\"translate(309.652 80.502631)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#m81f0438710\" y=\"51.280394\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 0.302 -->\n      <g transform=\"translate(309.652 55.079613)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#m81f0438710\" y=\"25.857376\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 0.304 -->\n      <g transform=\"translate(309.652 29.656595)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_31\">\n    <path d=\"M 291.78 224.64 \nL 291.78 223.790625 \nL 291.78 8.049375 \nL 291.78 7.2 \nL 302.652 7.2 \nL 302.652 8.049375 \nL 302.652 223.790625 \nL 302.652 224.64 \nz\n\" style=\"fill:none;stroke:#000000;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p85469fe759\">\n   <rect height=\"217.44\" width=\"267.84\" x=\"7.2\" y=\"7.2\"/>\n  </clipPath>\n  <clipPath id=\"p0cfe4f724f\">\n   <rect height=\"217.44\" width=\"10.872\" x=\"291.78\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mean acc:  0.8697573561703996\n",
      "mean auc:  0.8529135819896692\n",
      "\n",
      "index:  77\n",
      "target node:  0\n",
      "epoch time:  0.18578767776489258\n",
      "foo\n",
      "\n",
      "index:  78\n",
      "target node:  0\n",
      "epoch time:  0.16635441780090332\n",
      "{0, 1, 2, 3, 4, 5, 6, 7}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8725284762518805\n",
      "mean auc:  0.856043080245208\n",
      "\n",
      "index:  79\n",
      "target node:  0\n",
      "epoch time:  0.16893935203552246\n",
      "foo\n",
      "\n",
      "index:  80\n",
      "target node:  0\n",
      "epoch time:  0.1692187786102295\n",
      "{0, 1, 2, 3, 4, 5, 6, 8}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8751841329966331\n",
      "mean auc:  0.8590421827400995\n",
      "\n",
      "index:  81\n",
      "target node:  0\n",
      "epoch time:  0.22234010696411133\n",
      "{0, 1, 5, 6, 7, 8, 10, 12}\n",
      "acc:  0.375\n",
      "auc:  0.3375\n",
      "mean acc:  0.8649762935477222\n",
      "mean auc:  0.8483984647249954\n",
      "\n",
      "index:  82\n",
      "target node:  0\n",
      "epoch time:  0.20157790184020996\n",
      "{0, 1, 4, 5, 6, 7, 8, 10, 11}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8676767676767677\n",
      "mean auc:  0.8514304954304954\n",
      "\n",
      "index:  83\n",
      "target node:  0\n",
      "epoch time:  0.18559718132019043\n",
      "{0, 1, 2, 3, 4, 5, 7, 8}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8702713408595762\n",
      "mean auc:  0.8543436229710739\n",
      "\n",
      "index:  84\n",
      "target node:  0\n",
      "epoch time:  0.20221638679504395\n",
      "{0, 1, 4, 5, 6, 7, 8, 10, 11}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8727661227661229\n",
      "mean auc:  0.8571447071447071\n",
      "\n",
      "index:  85\n",
      "target node:  0\n",
      "epoch time:  0.18564677238464355\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 9}\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.0\n",
      "target node:  0\n",
      "epoch time:  0.1933581829071045\n",
      "Exception ignored in: <function _ConnectionBase.__del__ at 0x7fd1a53164d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/connection.py\", line 132, in __del__\n",
      "    self._close()\n",
      "  File \"/home/nightknight/anaconda3/envs/graph/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"234.687148pt\" version=\"1.1\" viewBox=\"0 0 345.480125 234.687148\" width=\"345.480125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-19T20:34:08.277795</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 234.687148 \nL 345.480125 234.687148 \nL 345.480125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 116.703814 125.394257 \nQ 115.969132 110.033511 115.23445 94.672765 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 131.478603 138.451651 \nQ 158.170277 136.432378 184.861951 134.413105 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 103.253242 140.205407 \nQ 76.768193 141.493692 50.283145 142.781977 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 118.753226 153.596836 \nQ 120.228965 168.719155 121.704704 183.841475 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 104.517987 203.468241 \nQ 80.466619 204.312116 56.41525 205.155992 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 121.705279 183.847373 \nQ 120.229197 168.721533 118.753114 153.595693 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 142.51549 201.005489 \nQ 166.989908 198.688738 191.464326 196.371986 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 181.76715 71.528506 \nQ 157.532592 73.020888 133.298033 74.51327 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 200.492716 87.883081 \nQ 201.45592 100.95308 202.419123 114.023079 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 212.564285 59.18195 \nQ 224.538566 49.075596 236.512847 38.969242 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 133.300798 74.513099 \nQ 157.531379 73.020963 181.761961 71.528826 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 95.354482 76.926288 \nQ 71.145144 78.514644 46.935805 80.103001 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 115.23423 94.668164 \nQ 115.968929 110.029276 116.703628 125.390388 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 46.930829 80.103327 \nQ 71.144845 78.514664 95.358861 76.926001 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 30.658825 97.712424 \nQ 30.835369 111.18887 31.011913 124.665315 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 202.419198 114.024093 \nQ 201.456066 100.955067 200.492935 87.886041 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 184.857947 134.413407 \nQ 158.167573 136.432582 131.4772 138.451757 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 205.072833 151.944301 \nQ 205.946806 165.133339 206.820779 178.322378 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 33.582205 162.613573 \nQ 35.162265 175.485273 36.742325 188.356974 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 31.011861 124.661345 \nQ 30.83532 111.18515 30.658779 97.708955 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 50.286269 142.781825 \nQ 76.770917 141.49356 103.255564 140.205294 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 206.820994 178.325622 \nQ 205.946984 165.13602 205.072973 151.946419 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 191.460495 196.372349 \nQ 166.988512 198.68887 142.51653 201.005391 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 236.515822 38.966731 \nQ 224.539571 49.074748 212.563319 59.182765 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 36.742378 188.357407 \nQ 35.162205 175.484782 33.582031 162.612156 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 56.412926 205.156073 \nQ 80.466237 204.31213 104.519547 203.468187 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 117.379345 153.660421 \nC 121.129883 153.660421 124.727314 152.170317 127.379345 149.518286 \nC 130.031376 146.866255 131.52148 143.268824 131.52148 139.518286 \nC 131.52148 135.767747 130.031376 132.170317 127.379345 129.518286 \nC 124.727314 126.866255 121.129883 125.37615 117.379345 125.37615 \nC 113.628807 125.37615 110.031376 126.866255 107.379345 129.518286 \nC 104.727314 132.170317 103.237209 135.767747 103.237209 139.518286 \nC 103.237209 143.268824 104.727314 146.866255 107.379345 149.518286 \nC 110.031376 152.170317 113.628807 153.660421 117.379345 153.660421 \nz\n\" style=\"fill:#fff5eb;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 123.554836 221.846545 \nC 128.605957 221.846545 133.450878 219.839713 137.02256 216.268031 \nC 140.594242 212.696349 142.601074 207.851429 142.601074 202.800307 \nC 142.601074 197.749186 140.594242 192.904266 137.02256 189.332584 \nC 133.450878 185.760901 128.605957 183.75407 123.554836 183.75407 \nC 118.503715 183.75407 113.658794 185.760901 110.087112 189.332584 \nC 106.51543 192.904266 104.508598 197.749186 104.508598 202.800307 \nC 104.508598 207.851429 106.51543 212.696349 110.087112 216.268031 \nC 113.658794 219.839713 118.503715 221.846545 123.554836 221.846545 \nz\n\" style=\"fill:#be3f02;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 199.208302 87.930805 \nC 203.843081 87.930805 208.288655 86.089388 211.565938 82.812104 \nC 214.843222 79.534821 216.684639 75.089246 216.684639 70.454468 \nC 216.684639 65.819689 214.843222 61.374114 211.565938 58.096831 \nC 208.288655 54.819547 203.843081 52.97813 199.208302 52.97813 \nC 194.573523 52.97813 190.127949 54.819547 186.850665 58.096831 \nC 183.573381 61.374114 181.731964 65.819689 181.731964 70.454468 \nC 181.731964 75.089246 183.573381 79.534821 186.850665 82.812104 \nC 190.127949 86.089388 194.573523 87.930805 199.208302 87.930805 \nz\n\" style=\"fill:#fb8634;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 114.32613 94.691508 \nC 119.367624 94.691508 124.20331 92.688502 127.768184 89.123627 \nC 131.333058 85.558753 133.336065 80.723067 133.336065 75.681573 \nC 133.336065 70.640079 131.333058 65.804394 127.768184 62.239519 \nC 124.20331 58.674645 119.367624 56.671638 114.32613 56.671638 \nC 109.284636 56.671638 104.44895 58.674645 100.884076 62.239519 \nC 97.319202 65.804394 95.316195 70.640079 95.316195 75.681573 \nC 95.316195 80.723067 97.319202 85.558753 100.884076 89.123627 \nC 104.44895 92.688502 109.284636 94.691508 114.32613 94.691508 \nz\n\" style=\"fill:#c14002;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 30.442314 97.711524 \nC 34.825166 97.711524 39.029098 95.970199 42.128242 92.871054 \nC 45.227387 89.77191 46.968712 85.567978 46.968712 81.185126 \nC 46.968712 76.802274 45.227387 72.598342 42.128242 69.499197 \nC 39.029098 66.400053 34.825166 64.658727 30.442314 64.658727 \nC 26.059462 64.658727 21.85553 66.400053 18.756386 69.499197 \nC 15.657241 72.598342 13.915916 76.802274 13.915916 81.185126 \nC 13.915916 85.567978 15.657241 89.77191 18.756386 92.871054 \nC 21.85553 95.970199 26.059462 97.711524 30.442314 97.711524 \nz\n\" style=\"fill:#fdb170;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 203.816108 151.989066 \nC 208.857586 151.989066 213.693258 149.986066 217.258121 146.421202 \nC 220.822985 142.856338 222.825986 138.020667 222.825986 132.979188 \nC 222.825986 127.93771 220.822985 123.102038 217.258121 119.537175 \nC 213.693258 115.972311 208.857586 113.96931 203.816108 113.96931 \nC 198.774629 113.96931 193.938958 115.972311 190.374094 119.537175 \nC 186.809231 123.102038 184.80623 127.93771 184.80623 132.979188 \nC 184.80623 138.020667 186.809231 142.856338 190.374094 146.421202 \nC 193.938958 149.986066 198.774629 151.989066 203.816108 151.989066 \nz\n\" style=\"fill:#c14002;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 31.261365 162.753472 \nC 36.312487 162.753472 41.157407 160.74664 44.729089 157.174958 \nC 48.300771 153.603276 50.307603 148.758355 50.307603 143.707234 \nC 50.307603 138.656113 48.300771 133.811192 44.729089 130.23951 \nC 41.157407 126.667828 36.312487 124.660996 31.261365 124.660996 \nC 26.210244 124.660996 21.365324 126.667828 17.793641 130.23951 \nC 14.221959 133.811192 12.215128 138.656113 12.215128 143.707234 \nC 12.215128 148.758355 14.221959 153.603276 17.793641 157.174958 \nC 21.365324 160.74664 26.210244 162.753472 31.261365 162.753472 \nz\n\" style=\"fill:#be3f02;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 207.913657 211.341355 \nC 212.296527 211.341355 216.500475 209.600022 219.599632 206.500866 \nC 222.698789 203.401709 224.440121 199.19776 224.440121 194.814891 \nC 224.440121 190.432021 222.698789 186.228073 219.599632 183.128916 \nC 216.500475 180.029759 212.296527 178.288426 207.913657 178.288426 \nC 203.530787 178.288426 199.326839 180.029759 196.227682 183.128916 \nC 193.128525 186.228073 191.387193 190.432021 191.387193 194.814891 \nC 191.387193 199.19776 193.128525 203.401709 196.227682 206.500866 \nC 199.326839 209.600022 203.530787 211.341355 207.913657 211.341355 \nz\n\" style=\"fill:#fdb170;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 251.797686 46.06876 \nC 257.101748 46.06876 262.189283 43.961434 265.939822 40.210896 \nC 269.69036 36.460358 271.797686 31.372822 271.797686 26.06876 \nC 271.797686 20.764698 269.69036 15.677163 265.939822 11.926625 \nC 262.189283 8.176086 257.101748 6.06876 251.797686 6.06876 \nC 246.493624 6.06876 241.406089 8.176086 237.65555 11.926625 \nC 233.905012 15.677163 231.797686 20.764698 231.797686 26.06876 \nC 231.797686 31.372822 233.905012 36.460358 237.65555 40.210896 \nC 241.406089 43.961434 246.493624 46.06876 251.797686 46.06876 \nz\n\" style=\"fill:#7f2704;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#p651b9848b7)\" d=\"M 38.880006 223.315551 \nC 43.532812 223.315551 47.995677 221.466971 51.285707 218.176941 \nC 54.575738 214.88691 56.424317 210.424045 56.424317 205.77124 \nC 56.424317 201.118434 54.575738 196.655569 51.285707 193.365538 \nC 47.995677 190.075508 43.532812 188.226929 38.880006 188.226929 \nC 34.227201 188.226929 29.764335 190.075508 26.474305 193.365538 \nC 23.184275 196.655569 21.335695 201.118434 21.335695 205.77124 \nC 21.335695 210.424045 23.184275 214.88691 26.474305 218.176941 \nC 29.764335 221.466971 34.227201 223.315551 38.880006 223.315551 \nz\n\" style=\"fill:#f98230;stroke:#0000ff;\"/>\n   </g>\n   <g id=\"text_1\">\n    <g clip-path=\"url(#p651b9848b7)\">\n     <!-- 0 -->\n     <g transform=\"translate(113.561845 142.829536)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-48\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_2\">\n    <g clip-path=\"url(#p651b9848b7)\">\n     <!-- 1 -->\n     <g transform=\"translate(119.737336 206.111557)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-49\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_3\">\n    <g clip-path=\"url(#p651b9848b7)\">\n     <!-- 2 -->\n     <g transform=\"translate(195.390802 73.765718)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-50\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_4\">\n    <g clip-path=\"url(#p651b9848b7)\">\n     <!-- 3 -->\n     <g transform=\"translate(110.50863 78.992823)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-51\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_5\">\n    <g clip-path=\"url(#p651b9848b7)\">\n     <!-- 4 -->\n     <g transform=\"translate(26.624814 84.496376)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-52\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_6\">\n    <g clip-path=\"url(#p651b9848b7)\">\n     <!-- 5 -->\n     <g transform=\"translate(199.998608 136.290438)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-53\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_7\">\n    <g clip-path=\"url(#p651b9848b7)\">\n     <!-- 6 -->\n     <g transform=\"translate(27.443865 147.018484)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-54\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_8\">\n    <g clip-path=\"url(#p651b9848b7)\">\n     <!-- 7 -->\n     <g transform=\"translate(204.096157 198.126141)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-55\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_9\">\n    <g clip-path=\"url(#p651b9848b7)\">\n     <!-- 8 -->\n     <g transform=\"translate(247.980186 29.38001)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-56\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_10\">\n    <g clip-path=\"url(#p651b9848b7)\">\n     <!-- 9 -->\n     <g transform=\"translate(35.062506 209.08249)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-57\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_28\">\n    <path clip-path=\"url(#pbda2b776cd)\" d=\"M 291.78 224.64 \nL 291.78 223.790625 \nL 291.78 8.049375 \nL 291.78 7.2 \nL 302.652 7.2 \nL 302.652 8.049375 \nL 302.652 223.790625 \nL 302.652 224.64 \nz\n\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;stroke-width:0.01;\"/>\n   </g>\n   <image height=\"217\" id=\"image4b310d3fe3\" transform=\"scale(1 -1)translate(0 -217)\" width=\"11\" x=\"292\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAAsAAADZCAYAAAD2WsoCAAABL0lEQVR4nO2YQQ6DMBADlyr/f2jvvTVZvpBpNZJBcLZWXtsxgaM/767NZ1RvY2tUEXDI5BAa4oJLotGAxmsbiWmEqHFBu6EpIQuyydOigYIkLohoeGqgBTXpyIKkvh67/wCLdntVkPGaQDTWl4C91HlgwhmpIVaBBl5anpnOt1fDq69HjV8nzwtyFpv/grdcsZEyijFlwQzOIWqQtxX8QLDUYDTYgqhkpF9DUA123/BoWNmApnh5tnSG0kVkg5mi9UaTaw+yG2DNYkQ0lngGAQ2os3VSTM5gMtQZgKHd29ick7J/uGss1vxgcshJmWwyAAOZa4DQ1QBYOHn2IU32OJtqkMmEBguSRiMm/CB1Hg1md0ZE0WQkHcuGRsOT7vYOosmo+UM4h9jtNZJpdwKNE6rQphYiH8EMAAAAAElFTkSuQmCC\" y=\"-7\"/>\n   <g id=\"matplotlib.axis_1\"/>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 3.5 0 \n\" id=\"mb4441cac0e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#mb4441cac0e\" y=\"221.608241\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.302 -->\n      <g transform=\"translate(309.652 225.40746)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#mb4441cac0e\" y=\"181.95501\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.303 -->\n      <g transform=\"translate(309.652 185.754228)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#mb4441cac0e\" y=\"142.301778\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.304 -->\n      <g transform=\"translate(309.652 146.100996)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#mb4441cac0e\" y=\"102.648546\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.305 -->\n      <g transform=\"translate(309.652 106.447765)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#mb4441cac0e\" y=\"62.995314\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.306 -->\n      <g transform=\"translate(309.652 66.794533)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#mb4441cac0e\" y=\"23.342082\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.307 -->\n      <g transform=\"translate(309.652 27.141301)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_29\">\n    <path d=\"M 291.78 224.64 \nL 291.78 223.790625 \nL 291.78 8.049375 \nL 291.78 7.2 \nL 302.652 7.2 \nL 302.652 8.049375 \nL 302.652 223.790625 \nL 302.652 224.64 \nz\n\" style=\"fill:none;stroke:#000000;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p651b9848b7\">\n   <rect height=\"217.44\" width=\"267.84\" x=\"7.2\" y=\"7.2\"/>\n  </clipPath>\n  <clipPath id=\"pbda2b776cd\">\n   <rect height=\"217.44\" width=\"10.872\" x=\"291.78\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mean acc:  0.8730703259005146\n",
      "mean auc:  0.8409721655004674\n",
      "\n",
      "index:  86\n",
      "target node:  0\n",
      "epoch time:  0.1869187355041504\n",
      "foo\n",
      "\n",
      "index:  87\n",
      "target node:  0\n",
      "epoch time:  0.19365382194519043\n",
      "{0, 1, 2, 3, 4, 5, 6, 8}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8754208754208754\n",
      "mean auc:  0.8439171253986069\n",
      "\n",
      "index:  88\n",
      "target node:  0\n",
      "epoch time:  0.20117759704589844\n",
      "foo\n",
      "\n",
      "index:  89\n",
      "target node:  0\n",
      "epoch time:  0.2088925838470459\n",
      "foo\n",
      "\n",
      "index:  90\n",
      "target node:  0\n",
      "epoch time:  0.2705538272857666\n",
      "{0, 1, 3, 5, 11, 13, 16, 17}\n",
      "acc:  0.375\n",
      "auc:  0.3375\n",
      "mean acc:  0.8663223140495868\n",
      "mean auc:  0.8347095413004504\n",
      "\n",
      "index:  91\n",
      "target node:  0\n",
      "epoch time:  0.24340009689331055\n",
      "{0, 1, 2, 3, 6, 8, 9, 11, 12}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8687094155844157\n",
      "mean auc:  0.8376611566343709\n",
      "\n",
      "index:  92\n",
      "target node:  0\n",
      "epoch time:  0.19418883323669434\n",
      "{0, 1, 2, 3, 4, 6, 7, 8}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.871012759170654\n",
      "mean auc:  0.8405092065179784\n",
      "\n",
      "index:  93\n",
      "target node:  0\n",
      "epoch time:  0.22034883499145508\n",
      "{0, 1, 2, 3, 6, 8, 9, 11, 12}\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8732366771159876\n",
      "mean auc:  0.8432590477849098\n",
      "\n",
      "index:  94\n",
      "target node:  0\n",
      "epoch time:  0.29607295989990234\n",
      "{0, 1, 2, 3, 4, 5, 6, 8, 9}\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.0\n",
      "target node:  0\n",
      "epoch time:  0.28968191146850586\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"234.676611pt\" version=\"1.1\" viewBox=\"0 0 345.480125 234.676611\" width=\"345.480125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-19T20:34:11.236593</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 234.676611 \nL 345.480125 234.676611 \nL 345.480125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 182.199926 109.058804 \nQ 194.91159 101.158567 207.623255 93.258329 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 157.896793 123.519194 \nQ 144.785735 130.980796 131.674678 138.442398 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 163.528278 104.049731 \nQ 155.508056 89.025948 147.487834 74.002165 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 176.415392 129.220132 \nQ 183.857208 144.39095 191.299023 159.561767 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 231.890966 100.444098 \nQ 238.117283 113.709393 244.343601 126.974687 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 207.624935 93.257285 \nQ 194.912398 101.158065 182.199861 109.058845 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 214.426021 66.622737 \nQ 207.030726 53.539971 199.635431 40.457204 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 244.341851 126.970959 \nQ 238.117311 113.709453 231.892772 100.447946 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 237.080861 152.402272 \nQ 226.372995 159.348249 215.66513 166.294225 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 122.20328 66.965964 \nQ 111.164662 73.545944 100.126044 80.125924 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 147.485454 73.997707 \nQ 155.506194 89.022459 163.526933 104.047211 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 154.922183 47.589778 \nQ 166.091062 41.018801 177.259941 34.447823 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 93.070516 104.637977 \nQ 99.78581 117.777658 106.501103 130.917339 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 68.480885 83.705748 \nQ 58.978208 80.639557 49.47553 77.573366 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 100.130163 80.123469 \nQ 111.167036 73.544529 122.20391 66.965589 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 106.501188 130.917505 \nQ 99.784994 117.776063 93.068801 104.634621 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 123.890068 164.727408 \nQ 130.713225 177.910585 137.536382 191.093761 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 131.6758 138.44176 \nQ 144.78615 130.980561 157.8965 123.519361 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 137.537181 191.095303 \nQ 130.713425 177.910971 123.88967 164.726639 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 159.713514 197.990465 \nQ 171.298577 191.808214 182.88364 185.625964 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 49.473279 77.57264 \nQ 58.977827 80.639434 68.482375 83.706229 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 215.662426 166.295979 \nQ 226.371335 159.349326 237.080243 152.402673 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 182.88128 185.627223 \nQ 171.298041 191.8085 159.714802 197.989777 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 191.297822 159.559319 \nQ 183.856314 144.389128 176.414806 129.218938 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 199.633581 40.453931 \nQ 207.029799 53.538331 214.426018 66.622731 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 177.25483 34.450831 \nQ 166.08713 41.021114 154.919429 47.591398 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;stroke-width:2;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 170.187673 130.666497 \nC 173.938211 130.666497 177.535642 129.176392 180.187673 126.524361 \nC 182.839704 123.87233 184.329809 120.274899 184.329809 116.524361 \nC 184.329809 112.773823 182.839704 109.176392 180.187673 106.524361 \nC 177.535642 103.87233 173.938211 102.382225 170.187673 102.382225 \nC 166.437135 102.382225 162.839704 103.87233 160.187673 106.524361 \nC 157.535642 109.176392 156.045537 112.773823 156.045537 116.524361 \nC 156.045537 120.274899 157.535642 123.87233 160.187673 126.524361 \nC 162.839704 129.176392 166.437135 130.666497 170.187673 130.666497 \nz\n\" style=\"fill:#fff5eb;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 223.799428 102.251271 \nC 228.850581 102.251271 233.695531 100.244427 237.267235 96.672723 \nC 240.83894 93.101018 242.845784 88.256068 242.845784 83.204916 \nC 242.845784 78.153763 240.83894 73.308813 237.267235 69.737109 \nC 233.695531 66.165404 228.850581 64.15856 223.799428 64.15856 \nC 218.748276 64.15856 213.903326 66.165404 210.331621 69.737109 \nC 206.759917 73.308813 204.753073 78.153763 204.753073 83.204916 \nC 204.753073 88.256068 206.759917 93.101018 210.331621 96.672723 \nC 213.903326 100.244427 218.748276 102.251271 223.799428 102.251271 \nz\n\" style=\"fill:#be3f02;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 251.797686 160.400285 \nC 256.450547 160.400285 260.913466 158.551684 264.203535 155.261614 \nC 267.493605 151.971545 269.342206 147.508626 269.342206 142.855765 \nC 269.342206 138.202904 267.493605 133.739985 264.203535 130.449916 \nC 260.913466 127.159846 256.450547 125.311244 251.797686 125.311244 \nC 247.144825 125.311244 242.681906 127.159846 239.391837 130.449916 \nC 236.101767 133.739985 234.253165 138.202904 234.253165 142.855765 \nC 234.253165 147.508626 236.101767 151.971545 239.391837 155.261614 \nC 242.681906 158.551684 247.144825 160.400285 251.797686 160.400285 \nz\n\" style=\"fill:#f98230;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 138.534779 76.240905 \nC 143.576274 76.240905 148.411961 74.237898 151.976836 70.673023 \nC 155.541712 67.108147 157.544719 62.27246 157.544719 57.230965 \nC 157.544719 52.18947 155.541712 47.353783 151.976836 43.788908 \nC 148.411961 40.224033 143.576274 38.221026 138.534779 38.221026 \nC 133.493284 38.221026 128.657597 40.224033 125.092722 43.788908 \nC 121.527847 47.353783 119.52484 52.18947 119.52484 57.230965 \nC 119.52484 62.27246 121.527847 67.108147 125.092722 70.673023 \nC 128.657597 74.237898 133.493284 76.240905 138.534779 76.240905 \nz\n\" style=\"fill:#c14002;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 85.115878 106.549751 \nC 89.750688 106.549751 94.196293 104.708321 97.473599 101.431015 \nC 100.750905 98.153709 102.592335 93.708104 102.592335 89.073294 \nC 102.592335 84.438483 100.750905 79.992879 97.473599 76.715573 \nC 94.196293 73.438267 89.750688 71.596837 85.115878 71.596837 \nC 80.481067 71.596837 76.035463 73.438267 72.758157 76.715573 \nC 69.480851 79.992879 67.639421 84.438483 67.639421 89.073294 \nC 67.639421 93.708104 69.480851 98.153709 72.758157 101.431015 \nC 76.035463 104.708321 80.481067 106.549751 85.115878 106.549751 \nz\n\" style=\"fill:#fb8634;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 115.152476 166.855277 \nC 120.193979 166.855277 125.029673 164.852267 128.594554 161.287386 \nC 132.159434 157.722506 134.162444 152.886811 134.162444 147.845309 \nC 134.162444 142.803806 132.159434 137.968112 128.594554 134.403231 \nC 125.029673 130.838351 120.193979 128.835341 115.152476 128.835341 \nC 110.110974 128.835341 105.275279 130.838351 101.710399 134.403231 \nC 98.145518 137.968112 96.142508 142.803806 96.142508 147.845309 \nC 96.142508 152.886811 98.145518 157.722506 101.710399 161.287386 \nC 105.275279 164.852267 110.110974 166.855277 115.152476 166.855277 \nz\n\" style=\"fill:#c14002;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 145.132939 222.297763 \nC 149.515824 222.297763 153.719788 220.556424 156.818956 217.457257 \nC 159.918124 214.358089 161.659462 210.154125 161.659462 205.77124 \nC 161.659462 201.388354 159.918124 197.184391 156.818956 194.085223 \nC 153.719788 190.986055 149.515824 189.244716 145.132939 189.244716 \nC 140.750053 189.244716 136.54609 190.986055 133.446922 194.085223 \nC 130.347754 197.184391 128.606415 201.388354 128.606415 205.77124 \nC 128.606415 210.154125 130.347754 214.358089 133.446922 217.457257 \nC 136.54609 220.556424 140.750053 222.297763 145.132939 222.297763 \nz\n\" style=\"fill:#fdb170;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 30.442314 91.431995 \nC 35.746376 91.431995 40.833911 89.324669 44.58445 85.574131 \nC 48.334988 81.823593 50.442314 76.736057 50.442314 71.431995 \nC 50.442314 66.127933 48.334988 61.040398 44.58445 57.28986 \nC 40.833911 53.539322 35.746376 51.431995 30.442314 51.431995 \nC 25.138252 51.431995 20.050717 53.539322 16.300178 57.28986 \nC 12.54964 61.040398 10.442314 66.127933 10.442314 71.431995 \nC 10.442314 76.736057 12.54964 81.823593 16.300178 85.574131 \nC 20.050717 89.324669 25.138252 91.431995 30.442314 91.431995 \nz\n\" style=\"fill:#7f2704;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 199.686068 195.705876 \nC 204.73722 195.705876 209.582171 193.699032 213.153875 190.127327 \nC 216.725579 186.555623 218.732423 181.710673 218.732423 176.65952 \nC 218.732423 171.608368 216.725579 166.763418 213.153875 163.191713 \nC 209.582171 159.620009 204.73722 157.613165 199.686068 157.613165 \nC 194.634915 157.613165 189.789965 159.620009 186.218261 163.191713 \nC 182.646557 166.763418 180.639712 171.608368 180.639712 176.65952 \nC 180.639712 181.710673 182.646557 186.555623 186.218261 190.127327 \nC 189.789965 193.699032 194.634915 195.705876 199.686068 195.705876 \nz\n\" style=\"fill:#be3f02;stroke:#0000ff;\"/>\n    <path clip-path=\"url(#pc7a7043d86)\" d=\"M 191.502075 42.595415 \nC 195.884995 42.595415 200.088993 40.854063 203.188185 37.75487 \nC 206.287378 34.655678 208.02873 30.451681 208.02873 26.06876 \nC 208.02873 21.68584 206.287378 17.481843 203.188185 14.38265 \nC 200.088993 11.283458 195.884995 9.542105 191.502075 9.542105 \nC 187.119155 9.542105 182.915158 11.283458 179.815965 14.38265 \nC 176.716773 17.481843 174.97542 21.68584 174.97542 26.06876 \nC 174.97542 30.451681 176.716773 34.655678 179.815965 37.75487 \nC 182.915158 40.854063 187.119155 42.595415 191.502075 42.595415 \nz\n\" style=\"fill:#fdb170;stroke:#0000ff;\"/>\n   </g>\n   <g id=\"text_1\">\n    <g clip-path=\"url(#pc7a7043d86)\">\n     <!-- 0 -->\n     <g transform=\"translate(166.370173 119.835611)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-48\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_2\">\n    <g clip-path=\"url(#pc7a7043d86)\">\n     <!-- 1 -->\n     <g transform=\"translate(219.981928 86.516166)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-49\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_3\">\n    <g clip-path=\"url(#pc7a7043d86)\">\n     <!-- 2 -->\n     <g transform=\"translate(247.980186 146.167015)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-50\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_4\">\n    <g clip-path=\"url(#pc7a7043d86)\">\n     <!-- 3 -->\n     <g transform=\"translate(134.717279 60.542215)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-51\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_5\">\n    <g clip-path=\"url(#pc7a7043d86)\">\n     <!-- 4 -->\n     <g transform=\"translate(81.298378 92.384544)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-52\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_6\">\n    <g clip-path=\"url(#pc7a7043d86)\">\n     <!-- 5 -->\n     <g transform=\"translate(111.334976 151.156559)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-53\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_7\">\n    <g clip-path=\"url(#pc7a7043d86)\">\n     <!-- 6 -->\n     <g transform=\"translate(141.315439 209.08249)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-54\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_8\">\n    <g clip-path=\"url(#pc7a7043d86)\">\n     <!-- 7 -->\n     <g transform=\"translate(26.624814 74.743245)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-55\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_9\">\n    <g clip-path=\"url(#pc7a7043d86)\">\n     <!-- 8 -->\n     <g transform=\"translate(195.868568 179.97077)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-56\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_10\">\n    <g clip-path=\"url(#pc7a7043d86)\">\n     <!-- 9 -->\n     <g transform=\"translate(187.684575 29.38001)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-57\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_28\">\n    <path clip-path=\"url(#p91de5fee18)\" d=\"M 291.78 224.64 \nL 291.78 223.790625 \nL 291.78 8.049375 \nL 291.78 7.2 \nL 302.652 7.2 \nL 302.652 8.049375 \nL 302.652 223.790625 \nL 302.652 224.64 \nz\n\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;stroke-width:0.01;\"/>\n   </g>\n   <image height=\"217\" id=\"image8a6f0688da\" transform=\"scale(1 -1)translate(0 -217)\" width=\"11\" x=\"292\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAAsAAADZCAYAAAD2WsoCAAABLklEQVR4nO2YQQ7CMAwEXZT/P5Q7NxLzhQxopA0qZ8sa79rblqtfz67N36jerq1RRYpDOodgiAMuCaMBxmO7EmOEqHGg3dCUkAFZ52lhoEUSB0QYnhpoQE06MiCJr9vuH4pFu70oyHhMIIz1JsXe1nnFhBmpIUaBVry0fWY6/70aXnzdanzbeR7ILCb/gW+5YiJlBGPKgBnMIWqQpxX8QLDUYBhsQBQy0l9DUA32vuFhWLsBTfH22dIZSddi1mmmeBjktQfZDWrNYEQYS7xBgAF11i5FZAadoc6gGNq9XZtzKfvHXWOx5AedQy5lss6gGMhcAyxdDVALO8++pM4es6kG6Uww2CJpGDHLD7bOw2B2Z6wo6uzZjTC8zuxSMjBCpEPJH8IcYreXSKbdCRgf1u+mFp3dHZ0AAAAASUVORK5CYII=\" y=\"-7\"/>\n   <g id=\"matplotlib.axis_1\"/>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 3.5 0 \n\" id=\"maa114bec6e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#maa114bec6e\" y=\"221.597705\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.302 -->\n      <g transform=\"translate(309.652 225.396924)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#maa114bec6e\" y=\"181.945766\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.303 -->\n      <g transform=\"translate(309.652 185.744985)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#maa114bec6e\" y=\"142.293827\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.304 -->\n      <g transform=\"translate(309.652 146.093046)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#maa114bec6e\" y=\"102.641888\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.305 -->\n      <g transform=\"translate(309.652 106.441107)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#maa114bec6e\" y=\"62.98995\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.306 -->\n      <g transform=\"translate(309.652 66.789168)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.652\" xlink:href=\"#maa114bec6e\" y=\"23.338011\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.307 -->\n      <g transform=\"translate(309.652 27.13723)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_29\">\n    <path d=\"M 291.78 224.64 \nL 291.78 223.790625 \nL 291.78 8.049375 \nL 291.78 7.2 \nL 302.652 7.2 \nL 302.652 8.049375 \nL 302.652 223.790625 \nL 302.652 224.64 \nz\n\" style=\"fill:none;stroke:#000000;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc7a7043d86\">\n   <rect height=\"217.44\" width=\"267.84\" x=\"7.2\" y=\"7.2\"/>\n  </clipPath>\n  <clipPath id=\"p91de5fee18\">\n   <rect height=\"217.44\" width=\"10.872\" x=\"291.78\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mean acc:  0.873501968840952\nmean auc:  0.8289665215512673\n\nindex:  95\ntarget node:  0\nepoch time:  0.195723295211792\nfoo\n\nindex:  96\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-3439c5348b71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#if len(truth_node) > 6:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#    continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mnode_sort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_explain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mnode_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msub_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/nightknight//git/hierarchcal-gnn-interpretations/explain.py\u001b[0m in \u001b[0;36mprint_explain\u001b[0;34m(dataset, model, idx, class_idx, visible, figsize, node_range, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mbegin_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0mclass_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCD_explain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m     \u001b[0;31m#print(class_score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbegin_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/nightknight//git/hierarchcal-gnn-interpretations/explain.py\u001b[0m in \u001b[0;36mCD_explain\u001b[0;34m(model, dataset, idx, mask_node_list, node_range, target_node)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/nightknight//git/hierarchcal-gnn-interpretations/utils.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(dataset, idx, batch_size, shuffle)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0melem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_data_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfollow_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[0;34m(data_list, follow_batch)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_data_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36mcontiguous\u001b[0;34m(self, *keys)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall\u001b[0m \u001b[0mpresent\u001b[0m \u001b[0mattributes\u001b[0m \u001b[0mare\u001b[0m \u001b[0mensured\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         have a contiguous memory layout.\"\"\"\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *keys)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mall\u001b[0m \u001b[0mpresent\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \"\"\"\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__apply__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *keys)\u001b[0m\n\u001b[1;32m    155\u001b[0m         present attributes.\"\"\"\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    141\u001b[0m         r\"\"\"Returns :obj:`True`, if the attribute :obj:`key` is present in the\n\u001b[1;32m    142\u001b[0m         data.\"\"\"\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36mkeys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;34mr\"\"\"Returns all names of graph attributes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'__'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;34mr\"\"\"Returns all names of graph attributes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'__'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "auc_list = []\n",
    "node_num_list = []\n",
    "dataset.subgraph = True\n",
    "dataset.remap = True\n",
    "load_model = gcn_model\n",
    "#load_model = torch.load('./checkpoint/gcn_mix').to('cuda')\n",
    "#load_model.eval()\n",
    "\n",
    "all_node_label = []\n",
    "all_node_color = []\n",
    "for idx in range(dataset.len()):\n",
    "    if idx in in_correct:\n",
    "        continue\n",
    "    print('\\nindex: ', idx)\n",
    "    sub_adj,sub_feature, sub_label,sub_edge_label_matrix = dataset.get_subgraph(idx)\n",
    "    #truth_node = np.where(sub_label[:,1] == True)[0]\n",
    "    truth_node = get_node_set(sub_edge_label_matrix)\n",
    "    #if len(truth_node) > 6:\n",
    "    #    continue\n",
    "    node_sort, node_color = print_explain(dataset, load_model, idx, class_idx = 1, visible = False)\n",
    "\n",
    "    node_label = np.array([0] * sub_label.shape[0])\n",
    "    node_label[list(truth_node)] = 1\n",
    "    pred  = np.array([0] * sub_label.shape[0])\n",
    "    pred[node_sort[:6]] = 1\n",
    "    \n",
    "    edge_label = []\n",
    "    edge_pred = []\n",
    "    for r,c in list(zip(sub_adj.row,sub_adj.col)):\n",
    "        sub_edge_label = sub_edge_label_matrix.todense()\n",
    "        edge_label.append(sub_edge_label[r,c] or sub_edge_label[c,r])\n",
    "        edge_pred.append((node_color[r] + node_color[c])/2)\n",
    "    #print(edge_label)\n",
    "    try:\n",
    "        auc = roc_auc_score(node_label, node_color)\n",
    "    except:\n",
    "        print('foo')\n",
    "        continue\n",
    "        auc = 1.0\n",
    "    #auc = 1.0 if len(label) == 6 else roc_auc_score(edge_label, edge_pred)\n",
    "    #auc = roc_auc_score(label, node_color)\n",
    "    node_num_list.append(len(truth_node))\n",
    "\n",
    "    #print(edge_label)\n",
    "    #print(edge_pred)\n",
    "    print(truth_node)\n",
    "    #print(node_sort)\n",
    "    acc = len([node for node in node_sort[:len(truth_node)] if node in truth_node])/len(truth_node)\n",
    "    acc_list.append(acc)\n",
    "    auc_list.append(auc)\n",
    "    all_node_label.extend(node_label)\n",
    "    all_node_color.extend(node_color)\n",
    "    print('acc: ', acc)\n",
    "    print('auc: ', auc)\n",
    "    if auc == 0.0:\n",
    "        print_explain(dataset, load_model, idx, class_idx = 0, visible = True)\n",
    "    print('mean acc: ', np.mean(acc_list))\n",
    "    print('mean auc: ', np.mean(auc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "np.argmax(sub_label,axis=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gcn_model, './checkpoint/gcn_grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1231])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "data = get_data(dataset, 0).to('cuda')\n",
    "preds = load_model.forward(data)\n",
    "_, indices = torch.max(preds, 1)\n",
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "index:  511\n",
      "0 label:  1\n",
      "node range:  [511, 0, 513, 1, 515, 2, 517, 3, 4, 5, 6, 514, 516, 518, 512]\n",
      "target node:  511\n",
      "epoch time:  0.1514291763305664\n",
      "[0.3567338287830353, 0.3511389195919037, 0.3397960364818573, 0.33758512139320374, 0.3432352840900421, 0.3375582993030548, 0.3397960364818573, 0.33220475912094116, 0.33220475912094116, 0.3321780562400818, 0.33189839124679565, 0.3538082242012024, 0.3374482989311218, 0.33744826912879944, 0.3538082242012024]\n",
      "[ 0 14 11  1  4  6  2  3  5 12 13  8  7  9 10]\n",
      "truth node:  [0, 2, 4, 6, 11, 12, 13, 14]\n",
      "acc:  0.6666666666666666\n",
      "auc:  0.8392857142857143\n",
      "mean acc:  0.6666666666666666\n",
      "mean auc:  0.8392857142857143\n",
      "\n",
      "index:  512\n",
      "0 label:  1\n",
      "node range:  [512, 0, 514, 1, 516, 2, 518, 513, 515, 517, 519, 511]\n",
      "target node:  512\n",
      "epoch time:  0.10879039764404297\n",
      "[0.35748448967933655, 0.33776551485061646, 0.34387099742889404, 0.332610547542572, 0.34707242250442505, 0.332610547542572, 0.3361215889453888, 0.35763439536094666, 0.3543564975261688, 0.3380427062511444, 0.3389563262462616, 0.35329681634902954]\n",
      "[ 7  0  8 11  4  2 10  9  1  6  5  3]\n",
      "truth node:  [0, 2, 4, 6, 7, 8, 9, 10, 11]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.962962962962963\n",
      "mean acc:  0.7777777777777777\n",
      "mean auc:  0.9011243386243386\n",
      "\n",
      "index:  513\n",
      "0 label:  1\n",
      "node range:  [513, 0, 512, 515, 514, 516, 518, 519, 511]\n",
      "target node:  513\n",
      "epoch time:  0.09568428993225098\n",
      "[0.3686867654323578, 0.3290061056613922, 0.3641353249549866, 0.348693311214447, 0.3360249698162079, 0.3655732274055481, 0.3372718393802643, 0.3425397276878357, 0.33873632550239563]\n",
      "[0 5 2 3 7 8 6 4 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8148148148148148\n",
      "mean auc:  0.9340828924162258\n",
      "\n",
      "index:  514\n",
      "0 label:  1\n",
      "node range:  [514, 512, 0, 1, 516, 2, 518, 513, 515, 517, 519, 511]\n",
      "target node:  514\n",
      "epoch time:  0.11936545372009277\n",
      "[0.35748448967933655, 0.34387102723121643, 0.33776551485061646, 0.332610547542572, 0.3361215889453888, 0.332610547542572, 0.34707239270210266, 0.3380427658557892, 0.3543564975261688, 0.35763439536094666, 0.3389563262462616, 0.35329681634902954]\n",
      "[ 9  0  8 11  6  1 10  7  2  4  5  3]\n",
      "truth node:  [0, 1, 4, 6, 7, 8, 9, 10, 11]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.962962962962963\n",
      "mean acc:  0.8333333333333333\n",
      "mean auc:  0.94130291005291\n",
      "\n",
      "index:  515\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  516\n",
      "0 label:  1\n",
      "node range:  [516, 512, 513, 514, 515, 517, 518, 519, 511]\n",
      "target node:  516\n",
      "epoch time:  0.09425020217895508\n",
      "[0.3604322075843811, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554757833480835, 0.33900347352027893, 0.34700849652290344, 0.3583422899246216, 0.3377439081668854]\n",
      "[0 7 2 4 6 1 5 8 3]\n",
      "foo\n",
      "\n",
      "index:  517\n",
      "0 label:  1\n",
      "node range:  [517, 0, 512, 514, 515, 516, 518, 519, 511]\n",
      "target node:  517\n",
      "epoch time:  0.10296964645385742\n",
      "[0.3686867654323578, 0.3290061056613922, 0.3360249698162079, 0.3641353249549866, 0.348693311214447, 0.3372718393802643, 0.3655732274055481, 0.3425397276878357, 0.33873632550239563]\n",
      "[0 6 3 4 7 8 5 2 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8444444444444443\n",
      "mean auc:  0.953042328042328\n",
      "\n",
      "index:  518\n",
      "0 label:  1\n",
      "node range:  [518, 512, 513, 514, 515, 516, 517, 519, 511]\n",
      "target node:  518\n",
      "epoch time:  0.09961175918579102\n",
      "[0.3604322075843811, 0.33623364567756653, 0.33900347352027893, 0.34689080715179443, 0.3554757833480835, 0.34700849652290344, 0.35820525884628296, 0.3583422303199768, 0.3377439081668854]\n",
      "[0 7 6 4 5 3 2 8 1]\n",
      "foo\n",
      "\n",
      "index:  519\n",
      "0 label:  1\n",
      "node range:  [519, 512, 513, 514, 515, 516, 517, 518]\n",
      "target node:  519\n",
      "epoch time:  0.07828736305236816\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963, 0.36502206325531006]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  520\n",
      "0 label:  1\n",
      "node range:  [520, 0, 2, 5, 6, 521, 522, 523, 524, 13, 526, 14, 525, 527, 27, 28, 29, 30]\n",
      "target node:  520\n",
      "epoch time:  0.22415828704833984\n",
      "[0.3550257384777069, 0.3314604163169861, 0.33559200167655945, 0.33146044611930847, 0.34830451011657715, 0.3534209132194519, 0.3397080898284912, 0.3534209132194519, 0.34321895241737366, 0.33559203147888184, 0.3397080898284912, 0.33556848764419556, 0.33731284737586975, 0.33731284737586975, 0.33146047592163086, 0.33146044611930847, 0.33143699169158936, 0.3312041461467743]\n",
      "[ 0  7  5  4  8 10  6 12 13  9  2 11 14 15  3  1 16 17]\n",
      "truth node:  [0, 5, 6, 7, 8, 10, 12, 13]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9375\n",
      "mean acc:  0.8518518518518517\n",
      "mean auc:  0.9504519400352733\n",
      "\n",
      "index:  521\n",
      "0 label:  1\n",
      "node range:  [521, 2, 6, 520, 522, 523, 524, 525, 13, 527, 14, 526, 528]\n",
      "target node:  521\n",
      "epoch time:  0.15140843391418457\n",
      "[0.35759681463241577, 0.3320516049861908, 0.33642852306365967, 0.3528936803340912, 0.3578200340270996, 0.34382888674736023, 0.354500949382782, 0.34713849425315857, 0.3320516049861908, 0.3360597491264343, 0.3320516049861908, 0.338000625371933, 0.33893585205078125]\n",
      "[ 4  0  6  3  7  5 12 11  2  9 10  8  1]\n",
      "truth node:  [0, 3, 4, 5, 6, 7, 9, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8571428571428571\n",
      "mean auc:  0.9535619803476946\n",
      "\n",
      "index:  522\n",
      "0 label:  1\n",
      "node range:  [522, 6, 520, 521, 523, 524, 525, 527, 528]\n",
      "target node:  522\n",
      "epoch time:  0.1066441535949707\n",
      "[0.368984192609787, 0.33907854557037354, 0.34668850898742676, 0.3655906617641449, 0.34467679262161255, 0.3541537821292877, 0.3667139410972595, 0.3456573188304901, 0.34958958625793457]\n",
      "[0 6 3 5 8 2 7 4 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.861111111111111\n",
      "mean auc:  0.9593667328042328\n",
      "\n",
      "index:  523\n",
      "0 label:  1\n",
      "node range:  [523, 2, 6, 520, 521, 522, 524, 525, 13, 527, 14, 526, 528]\n",
      "target node:  523\n",
      "epoch time:  0.15478873252868652\n",
      "[0.35759681463241577, 0.3320516049861908, 0.33642852306365967, 0.3528936803340912, 0.34382888674736023, 0.338000625371933, 0.3545009195804596, 0.3360597491264343, 0.3320516049861908, 0.34713849425315857, 0.3320516049861908, 0.3578200340270996, 0.33893585205078125]\n",
      "[11  0  6  3  9  4 12  5  2  7 10  8  1]\n",
      "truth node:  [0, 3, 4, 5, 6, 7, 9, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8641975308641974\n",
      "mean auc:  0.9607951205173426\n",
      "\n",
      "index:  524\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  525\n",
      "0 label:  1\n",
      "node range:  [525, 520, 521, 522, 523, 524, 526, 527, 528]\n",
      "target node:  525\n",
      "epoch time:  0.09280204772949219\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820525884628296, 0.33623364567756653, 0.3554757833480835, 0.33900347352027893, 0.34700843691825867, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  526\n",
      "0 label:  1\n",
      "node range:  [526, 6, 520, 521, 523, 524, 525, 527, 528]\n",
      "target node:  526\n",
      "epoch time:  0.08117485046386719\n",
      "[0.3689841628074646, 0.3390783965587616, 0.3466884195804596, 0.344676673412323, 0.3655906915664673, 0.35415375232696533, 0.3456572890281677, 0.3667139410972595, 0.34958958625793457]\n",
      "[0 7 4 5 8 2 6 3 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8666666666666666\n",
      "mean auc:  0.9647156084656083\n",
      "\n",
      "index:  527\n",
      "0 label:  1\n",
      "node range:  [527, 520, 521, 522, 523, 524, 525, 526, 528]\n",
      "target node:  527\n",
      "epoch time:  0.09830760955810547\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900347352027893, 0.34689080715179443, 0.3554757833480835, 0.34700843691825867, 0.35820528864860535, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  528\n",
      "0 label:  1\n",
      "node range:  [528, 521, 522, 523, 524, 525, 526, 527]\n",
      "target node:  528\n",
      "epoch time:  0.07715582847595215\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.36502206325531006, 0.3425886631011963, 0.36502206325531006]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  529\n",
      "0 label:  1\n",
      "node range:  [529, 2, 5, 536, 11, 12, 530, 531, 51, 533, 52, 535, 53, 25, 26, 54, 532, 534]\n",
      "target node:  529\n",
      "epoch time:  0.14842700958251953\n",
      "[0.3550257086753845, 0.3314604163169861, 0.33559203147888184, 0.33731284737586975, 0.3314604163169861, 0.34830451011657715, 0.3534209132194519, 0.3397081196308136, 0.3314604163169861, 0.34321895241737366, 0.3314604163169861, 0.3397080898284912, 0.33143699169158936, 0.33559203147888184, 0.33556848764419556, 0.3312041461467743, 0.3534209132194519, 0.33731284737586975]\n",
      "[ 0  6 16  5  9  7 11  3 17 13  2 14 10  4  1  8 12 15]\n",
      "truth node:  [0, 3, 6, 7, 9, 11, 16, 17]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9374999999999999\n",
      "mean acc:  0.8686868686868686\n",
      "mean auc:  0.9622414622414621\n",
      "\n",
      "index:  530\n",
      "0 label:  1\n",
      "node range:  [530, 5, 12, 537, 529, 531, 532, 533, 534, 535, 536, 25, 26]\n",
      "target node:  530\n",
      "epoch time:  0.12297701835632324\n",
      "[0.35759681463241577, 0.3320516049861908, 0.33642852306365967, 0.33893582224845886, 0.3528937101364136, 0.3578200340270996, 0.34382888674736023, 0.3545009195804596, 0.34713849425315857, 0.338000625371933, 0.3360597491264343, 0.3320516049861908, 0.3320516049861908]\n",
      "[ 5  0  7  4  8  6  3  9  2 10 12 11  1]\n",
      "truth node:  [0, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8703703703703703\n",
      "mean auc:  0.9630731922398588\n",
      "\n",
      "index:  531\n",
      "0 label:  1\n",
      "node range:  [531, 12, 529, 530, 532, 533, 534, 536, 537]\n",
      "target node:  531\n",
      "epoch time:  0.09668421745300293\n",
      "[0.368984192609787, 0.3390786349773407, 0.34668850898742676, 0.3655906319618225, 0.3446766436100006, 0.3541537821292877, 0.36671391129493713, 0.3456572890281677, 0.34958964586257935]\n",
      "[0 6 3 5 8 2 7 4 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8717948717948718\n",
      "mean auc:  0.9659137159137158\n",
      "\n",
      "index:  532\n",
      "0 label:  1\n",
      "node range:  [532, 5, 12, 537, 529, 530, 531, 533, 534, 535, 536, 25, 26]\n",
      "target node:  532\n",
      "epoch time:  0.13728880882263184\n",
      "[0.35759681463241577, 0.3320516049861908, 0.33642852306365967, 0.33893582224845886, 0.3528936803340912, 0.34382885694503784, 0.338000625371933, 0.354500949382782, 0.3360597491264343, 0.3578200340270996, 0.34713849425315857, 0.3320516049861908, 0.3320516049861908]\n",
      "[ 9  0  7  4 10  5  3  6  2  8 12 11  1]\n",
      "truth node:  [0, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8730158730158731\n",
      "mean auc:  0.9663643235071805\n",
      "\n",
      "index:  533\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  534\n",
      "0 label:  1\n",
      "node range:  [534, 529, 530, 531, 532, 533, 535, 536, 537]\n",
      "target node:  534\n",
      "epoch time:  0.07661128044128418\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820525884628296, 0.33623364567756653, 0.3554757833480835, 0.33900341391563416, 0.34700849652290344, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  535\n",
      "0 label:  1\n",
      "node range:  [535, 12, 529, 530, 532, 533, 534, 536, 537]\n",
      "target node:  535\n",
      "epoch time:  0.09332680702209473\n",
      "[0.3689841628074646, 0.3390783965587616, 0.346688449382782, 0.3446767032146454, 0.3655906915664673, 0.35415375232696533, 0.3456573188304901, 0.3667139410972595, 0.34958964586257935]\n",
      "[0 7 4 5 8 2 6 3 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8740740740740741\n",
      "mean auc:  0.9686067019400351\n",
      "\n",
      "index:  536\n",
      "0 label:  1\n",
      "node range:  [536, 529, 530, 531, 532, 533, 534, 535, 537]\n",
      "target node:  536\n",
      "epoch time:  0.09082269668579102\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900347352027893, 0.34689080715179443, 0.3554757833480835, 0.34700849652290344, 0.35820528864860535, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  537\n",
      "0 label:  1\n",
      "node range:  [537, 530, 531, 532, 533, 534, 535, 536]\n",
      "target node:  537\n",
      "epoch time:  0.08336472511291504\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.36502206325531006, 0.3425886631011963, 0.36502206325531006]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  538\n",
      "0 label:  1\n",
      "node range:  [538, 3, 8, 17, 18, 539, 540, 541, 542, 543, 544, 545, 37, 38, 75, 76, 77, 78, 982, 985, 986]\n",
      "target node:  538\n",
      "epoch time:  0.1839449405670166\n",
      "[0.3532843589782715, 0.3311134874820709, 0.3353612422943115, 0.3311134874820709, 0.34788671135902405, 0.35028013586997986, 0.33716142177581787, 0.35260871052742004, 0.34151872992515564, 0.3359946608543396, 0.33957579731941223, 0.3366723954677582, 0.3353612422943115, 0.33533695340156555, 0.3311134874820709, 0.3311134874820709, 0.3310893476009369, 0.330849826335907, 0.33112287521362305, 0.3353923261165619, 0.33112287521362305]\n",
      "[ 0  7  5  4  8 10  6 11  9 19 12  2 13 18 20 14 15  3  1 16 17]\n",
      "truth node:  [0, 5, 6, 7, 8, 9, 10, 11, 18, 19, 20]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.951923076923077\n",
      "mean acc:  0.875\n",
      "mean auc:  0.9675639753764753\n",
      "\n",
      "index:  539\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  540\n",
      "0 label:  1\n",
      "node range:  [540, 545, 546, 986, 18, 982, 985, 538, 539, 541, 542, 543]\n",
      "target node:  540\n",
      "epoch time:  0.0977025032043457\n",
      "[0.2882092297077179, 0.2999401390552521, 0.29727569222450256, 0.3033224046230316, 0.3034784197807312, 0.3033226728439331, 0.30019593238830566, 0.3002135753631592, 0.29105687141418457, 0.3008151054382324, 0.29582762718200684, 0.2888217568397522]\n",
      "[ 4  5  3  9  7  6  1  2 10  8 11  0]\n",
      "truth node:  [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.0625\n",
      "mean acc:  0.8758169934640523\n",
      "mean auc:  0.9143249180013885\n",
      "\n",
      "index:  541\n",
      "0 label:  1\n",
      "node range:  [541, 544, 545, 546, 37, 38, 8, 18, 985, 538, 539, 540, 542, 543]\n",
      "target node:  541\n",
      "epoch time:  0.1366405487060547\n",
      "[0.3578110337257385, 0.3581525683403015, 0.3472183644771576, 0.3388849198818207, 0.33184993267059326, 0.33184993267059326, 0.33184993267059326, 0.3362548351287842, 0.333690345287323, 0.35216769576072693, 0.34149160981178284, 0.3369230628013611, 0.3539462983608246, 0.335906058549881]\n",
      "[ 1  0 12  9  2 10  3 11  7 13  8  6  5  4]\n",
      "truth node:  [0, 1, 2, 3, 9, 10, 11, 12, 13]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9777777777777777\n",
      "mean acc:  0.8765432098765432\n",
      "mean auc:  0.9178500768778546\n",
      "\n",
      "index:  542\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  543\n",
      "0 label:  1\n",
      "node range:  [543, 544, 545, 546, 985, 538, 539, 540, 541, 542]\n",
      "target node:  543\n",
      "epoch time:  0.10076475143432617\n",
      "[0.3607839345932007, 0.33895495533943176, 0.34714654088020325, 0.358822226524353, 0.33450984954833984, 0.3366772532463074, 0.34420716762542725, 0.35736367106437683, 0.33606234192848206, 0.35495999455451965]\n",
      "[0 3 7 9 2 6 1 5 8 4]\n",
      "truth node:  [0, 1, 2, 3, 5, 6, 7, 8, 9]\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8830409356725146\n",
      "mean auc:  0.9221737570421781\n",
      "\n",
      "index:  544\n",
      "0 label:  1\n",
      "node range:  [544, 545, 546, 18, 538, 539, 541, 542, 543]\n",
      "target node:  544\n",
      "epoch time:  0.07828521728515625\n",
      "[0.3445783257484436, 0.3445169925689697, 0.3439328372478485, 0.34356990456581116, 0.34382563829421997, 0.34373369812965393, 0.3444713056087494, 0.344078928232193, 0.3438039720058441]\n",
      "[0 1 6 7 2 4 8 5 3]\n",
      "truth node:  [0, 1, 2, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8833333333333334\n",
      "mean auc:  0.9260650691900691\n",
      "\n",
      "index:  545\n",
      "0 label:  1\n",
      "node range:  [545, 544, 546, 985, 538, 539, 540, 541, 542, 543]\n",
      "target node:  545\n",
      "epoch time:  0.1033790111541748\n",
      "[0.360566645860672, 0.35835424065589905, 0.358492374420166, 0.33196625113487244, 0.33733901381492615, 0.33519506454467773, 0.33855053782463074, 0.3469083607196808, 0.355229914188385, 0.3470269441604614]\n",
      "[0 2 1 8 9 7 6 4 5 3]\n",
      "truth node:  [0, 1, 2, 4, 5, 6, 7, 8, 9]\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.888888888888889\n",
      "mean auc:  0.9295857801810182\n",
      "\n",
      "index:  546\n",
      "0 label:  1\n",
      "node range:  [546, 544, 545, 539, 540, 541, 542, 543]\n",
      "target node:  546\n",
      "epoch time:  0.09235310554504395\n",
      "[0.36875396966934204, 0.3425551950931549, 0.3653956353664398, 0.33585065603256226, 0.34242719411849976, 0.3372459411621094, 0.34876713156700134, 0.3652825951576233]\n",
      "[0 2 7 6 1 4 5 3]\n",
      "foo\n",
      "\n",
      "index:  547\n",
      "0 label:  1\n",
      "node range:  [547, 5, 11, 23, 24, 548, 549, 550, 551, 552, 553, 554, 49, 50, 473, 99, 100, 101, 102]\n",
      "target node:  547\n",
      "epoch time:  0.16810131072998047\n",
      "[0.35499098896980286, 0.3314515948295593, 0.33555448055267334, 0.3314515948295593, 0.34795132279396057, 0.3534241020679474, 0.339699387550354, 0.3534241020679474, 0.3432101905345917, 0.3373083472251892, 0.339699387550354, 0.3373083472251892, 0.33455535769462585, 0.3355308771133423, 0.33137455582618713, 0.3310856521129608, 0.3310856521129608, 0.33142808079719543, 0.33119475841522217]\n",
      "[ 0  5  7  4  8 10  6  9 11  2 13 12  3  1 17 14 18 15 16]\n",
      "truth node:  [0, 5, 6, 7, 8, 9, 10, 11]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9431818181818181\n",
      "mean acc:  0.888888888888889\n",
      "mean auc:  0.9302037819083272\n",
      "\n",
      "index:  548\n",
      "0 label:  1\n",
      "node range:  [548, 547, 549, 550, 551, 552, 553, 554, 11, 555, 49, 50, 24]\n",
      "target node:  548\n",
      "epoch time:  0.11013221740722656\n",
      "[0.3576821982860565, 0.35292550921440125, 0.35791194438934326, 0.3438355624675751, 0.3545692265033722, 0.3471759855747223, 0.3379792869091034, 0.3360343277454376, 0.3319839835166931, 0.3389267027378082, 0.3317590057849884, 0.3319839835166931, 0.3363822400569916]\n",
      "[ 2  0  4  1  5  3  9  6 12  7 11  8 10]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 9]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.888888888888889\n",
      "mean auc:  0.932030670617627\n",
      "\n",
      "index:  549\n",
      "0 label:  1\n",
      "node range:  [549, 547, 548, 550, 551, 552, 554, 555, 24]\n",
      "target node:  549\n",
      "epoch time:  0.07795548439025879\n",
      "[0.368984192609787, 0.34668853878974915, 0.3655906617641449, 0.34467679262161255, 0.3541537821292877, 0.36671388149261475, 0.3456573188304901, 0.34958967566490173, 0.33907845616340637]\n",
      "[0 5 2 4 7 1 6 3 8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.888888888888889\n",
      "mean auc:  0.9348627260085594\n",
      "\n",
      "index:  550\n",
      "0 label:  1\n",
      "node range:  [550, 547, 548, 549, 551, 552, 553, 554, 11, 555, 49, 50, 24]\n",
      "target node:  550\n",
      "epoch time:  0.0962672233581543\n",
      "[0.35768216848373413, 0.35292550921440125, 0.3438355624675751, 0.3379793167114258, 0.3545692563056946, 0.3360343277454376, 0.35791194438934326, 0.3471759855747223, 0.3319839835166931, 0.3389267027378082, 0.3317590057849884, 0.3319839835166931, 0.3363822400569916]\n",
      "[ 6  0  4  1  7  2  9  3 12  5 11  8 10]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 9]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.888888888888889\n",
      "mean auc:  0.9363571058571059\n",
      "\n",
      "index:  551\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  552\n",
      "0 label:  1\n",
      "node range:  [552, 547, 548, 549, 550, 551, 553, 554, 555]\n",
      "target node:  552\n",
      "epoch time:  0.08976173400878906\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820525884628296, 0.33623364567756653, 0.3554757833480835, 0.33900347352027893, 0.34700843691825867, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  553\n",
      "0 label:  1\n",
      "node range:  [553, 547, 548, 550, 551, 552, 554, 555, 24]\n",
      "target node:  553\n",
      "epoch time:  0.08412432670593262\n",
      "[0.3689841628074646, 0.3466884195804596, 0.34467679262161255, 0.3655906319618225, 0.3541537821292877, 0.3456572890281677, 0.3667139410972595, 0.34958967566490173, 0.33907854557037354]\n",
      "[0 6 3 4 7 1 5 2 8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8888888888888891\n",
      "mean auc:  0.9388049094779863\n",
      "\n",
      "index:  554\n",
      "0 label:  1\n",
      "node range:  [554, 547, 548, 549, 550, 551, 552, 553, 555]\n",
      "target node:  554\n",
      "epoch time:  0.08593297004699707\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900347352027893, 0.34689080715179443, 0.3554757833480835, 0.34700843691825867, 0.35820528864860535, 0.3583422899246216]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  555\n",
      "0 label:  1\n",
      "node range:  [555, 548, 549, 550, 551, 552, 553, 554]\n",
      "target node:  555\n",
      "epoch time:  0.08399605751037598\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.36502206325531006, 0.3425886631011963, 0.36502206325531006]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  556\n",
      "0 label:  1\n",
      "node range:  [556, 6, 557, 558, 14, 560, 559, 562, 29, 561, 125, 563, 30, 126, 123, 124, 61, 62]\n",
      "target node:  556\n",
      "epoch time:  0.15673327445983887\n",
      "[0.3550932705402374, 0.33114421367645264, 0.3534834086894989, 0.33969905972480774, 0.33552804589271545, 0.3432292640209198, 0.3534834086894989, 0.33969905972480774, 0.33137786388397217, 0.33729061484336853, 0.33137786388397217, 0.33729061484336853, 0.3483012020587921, 0.331144243478775, 0.33140143752098083, 0.33140143752098083, 0.3355517089366913, 0.33552804589271545]\n",
      "[ 0  6  2 12  5  3  7 11  9 16  4 17 14 15 10  8 13  1]\n",
      "truth node:  [0, 2, 3, 5, 6, 7, 9, 11]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9375\n",
      "mean acc:  0.8888888888888891\n",
      "mean auc:  0.9387565794973202\n",
      "\n",
      "index:  557\n",
      "0 label:  1\n",
      "node range:  [557, 556, 14, 559, 558, 561, 560, 563, 562, 564, 62, 61, 30]\n",
      "target node:  557\n",
      "epoch time:  0.12060952186584473\n",
      "[0.35759681463241577, 0.3528936803340912, 0.3320516049861908, 0.34382888674736023, 0.357820063829422, 0.34713849425315857, 0.3545009195804596, 0.3360597491264343, 0.338000625371933, 0.33893582224845886, 0.3320516049861908, 0.3320516049861908, 0.33642852306365967]\n",
      "[ 4  0  6  1  5  3  9  8 12  7 11 10  2]\n",
      "truth node:  [0, 1, 3, 4, 5, 6, 7, 8, 9]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8888888888888891\n",
      "mean auc:  0.9399517810232095\n",
      "\n",
      "index:  558\n",
      "0 label:  1\n",
      "node range:  [558, 556, 557, 559, 560, 561, 563, 564, 30]\n",
      "target node:  558\n",
      "epoch time:  0.08569836616516113\n",
      "[0.368984192609787, 0.346688449382782, 0.3655906319618225, 0.34467679262161255, 0.3541537821292877, 0.36671391129493713, 0.3456572890281677, 0.34958958625793457, 0.3390786051750183]\n",
      "[0 5 2 4 7 1 6 3 8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8888888888888891\n",
      "mean auc:  0.9420224092637886\n",
      "\n",
      "index:  559\n",
      "0 label:  1\n",
      "node range:  [559, 556, 557, 14, 558, 561, 560, 563, 562, 564, 62, 61, 30]\n",
      "target node:  559\n",
      "epoch time:  0.09120368957519531\n",
      "[0.35759681463241577, 0.3528936803340912, 0.34382885694503784, 0.3320516049861908, 0.338000625371933, 0.3360597491264343, 0.3545009195804596, 0.34713849425315857, 0.357820063829422, 0.33893585205078125, 0.3320516049861908, 0.3320516049861908, 0.33642855286598206]\n",
      "[ 8  0  6  1  7  2  9  4 12  5 11 10  3]\n",
      "truth node:  [0, 1, 2, 4, 5, 6, 7, 8, 9]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8888888888888891\n",
      "mean auc:  0.9430290696957363\n",
      "\n",
      "index:  560\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  561\n",
      "0 label:  1\n",
      "node range:  [561, 556, 557, 558, 559, 560, 562, 563, 564]\n",
      "target node:  561\n",
      "epoch time:  0.08321690559387207\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554757833480835, 0.33900347352027893, 0.34700843691825867, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  562\n",
      "0 label:  1\n",
      "node range:  [562, 556, 557, 559, 560, 561, 563, 564, 30]\n",
      "target node:  562\n",
      "epoch time:  0.10449910163879395\n",
      "[0.3689841628074646, 0.346688449382782, 0.3446767032146454, 0.3655907213687897, 0.3541538119316101, 0.3456573784351349, 0.36671388149261475, 0.34958964586257935, 0.33907854557037354]\n",
      "[0 6 3 4 7 1 5 2 8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8888888888888891\n",
      "mean auc:  0.9448668416410351\n",
      "\n",
      "index:  563\n",
      "0 label:  1\n",
      "node range:  [563, 556, 557, 558, 559, 560, 561, 562, 564]\n",
      "target node:  563\n",
      "epoch time:  0.08731675148010254\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900341391563416, 0.34689080715179443, 0.3554757833480835, 0.34700843691825867, 0.35820528864860535, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  564\n",
      "0 label:  1\n",
      "node range:  [564, 557, 558, 559, 560, 561, 562, 563]\n",
      "target node:  564\n",
      "epoch time:  0.08055377006530762\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963, 0.3650219738483429]\n",
      "[0 5 7 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  565\n",
      "0 label:  1\n",
      "node range:  [565, 35, 36, 8, 73, 74, 568, 17, 147, 148, 149, 567, 150, 569, 566, 571, 570, 572]\n",
      "target node:  565\n",
      "epoch time:  0.15943050384521484\n",
      "[0.3550257086753845, 0.3314604163169861, 0.34830451011657715, 0.3314604163169861, 0.33559203147888184, 0.33556848764419556, 0.3534209132194519, 0.33559203147888184, 0.33146044611930847, 0.33146044611930847, 0.33143699169158936, 0.3397081196308136, 0.3312041461467743, 0.34321895241737366, 0.3534209132194519, 0.3397080898284912, 0.33731284737586975, 0.33731284737586975]\n",
      "[ 0 14  6  2 13 11 15 16 17  7  4  5  9  8  3  1 10 12]\n",
      "truth node:  [0, 6, 11, 13, 14, 15, 16, 17]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9374999999999999\n",
      "mean acc:  0.8888888888888888\n",
      "mean auc:  0.9446366278397529\n",
      "\n",
      "index:  566\n",
      "0 label:  1\n",
      "node range:  [566, 36, 73, 74, 17, 565, 567, 568, 569, 570, 571, 572, 573]\n",
      "target node:  566\n",
      "epoch time:  0.11661052703857422\n",
      "[0.35759681463241577, 0.33642852306365967, 0.3320516049861908, 0.3320516347885132, 0.3320516347885132, 0.3528936803340912, 0.357820063829422, 0.34382888674736023, 0.354500949382782, 0.34713852405548096, 0.338000625371933, 0.3360597491264343, 0.33893585205078125]\n",
      "[ 6  0  8  5  9  7 12 10  1 11  4  3  2]\n",
      "truth node:  [0, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8888888888888888\n",
      "mean auc:  0.9454725549422519\n",
      "\n",
      "index:  567\n",
      "0 label:  1\n",
      "node range:  [567, 36, 565, 566, 568, 569, 570, 572, 573]\n",
      "target node:  567\n",
      "epoch time:  0.09141111373901367\n",
      "[0.368984192609787, 0.3390786051750183, 0.34668850898742676, 0.3655906915664673, 0.34467679262161255, 0.3541537821292877, 0.3667139708995819, 0.3456572890281677, 0.34958958625793457]\n",
      "[0 6 3 5 8 2 7 4 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8888888888888888\n",
      "mean auc:  0.9470763033263033\n",
      "\n",
      "index:  568\n",
      "0 label:  1\n",
      "node range:  [568, 36, 73, 74, 17, 565, 566, 567, 569, 570, 571, 572, 573]\n",
      "target node:  568\n",
      "epoch time:  0.10621905326843262\n",
      "[0.35759681463241577, 0.33642852306365967, 0.3320516049861908, 0.3320516049861908, 0.3320516049861908, 0.3528936803340912, 0.34382888674736023, 0.338000625371933, 0.3545009195804596, 0.3360597491264343, 0.357820063829422, 0.34713849425315857, 0.33893582224845886]\n",
      "[10  0  8  5 11  6 12  7  1  9  4  3  2]\n",
      "truth node:  [0, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8888888888888888\n",
      "mean auc:  0.947794758151901\n",
      "\n",
      "index:  569\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  570\n",
      "0 label:  1\n",
      "node range:  [570, 565, 566, 567, 568, 569, 571, 572, 573]\n",
      "target node:  570\n",
      "epoch time:  0.09189462661743164\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554758131504059, 0.33900341391563416, 0.34700849652290344, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  571\n",
      "0 label:  1\n",
      "node range:  [571, 36, 565, 566, 568, 569, 570, 572, 573]\n",
      "target node:  571\n",
      "epoch time:  0.08419060707092285\n",
      "[0.368984192609787, 0.3390786349773407, 0.346688449382782, 0.344676673412323, 0.3655906915664673, 0.3541537821292877, 0.3456572890281677, 0.36671388149261475, 0.34958964586257935]\n",
      "[0 7 4 5 8 2 6 3 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8888888888888888\n",
      "mean auc:  0.9492449037587927\n",
      "\n",
      "index:  572\n",
      "0 label:  1\n",
      "node range:  [572, 565, 566, 567, 568, 569, 570, 571, 573]\n",
      "target node:  572\n",
      "epoch time:  0.09012413024902344\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900341391563416, 0.34689080715179443, 0.3554758131504059, 0.34700849652290344, 0.35820525884628296, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  573\n",
      "0 label:  1\n",
      "node range:  [573, 566, 567, 568, 569, 570, 571, 572]\n",
      "target node:  573\n",
      "epoch time:  0.09874510765075684\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963, 0.3650220036506653]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  574\n",
      "0 label:  1\n",
      "node range:  [574, 576, 577, 578, 579, 580, 581, 9, 41, 42, 171, 172, 173, 174, 20, 85, 86, 575]\n",
      "target node:  574\n",
      "epoch time:  0.16869354248046875\n",
      "[0.3550257086753845, 0.3397080898284912, 0.3534209132194519, 0.34321895241737366, 0.33731284737586975, 0.3397080898284912, 0.33731284737586975, 0.33146047592163086, 0.33146044611930847, 0.34830451011657715, 0.33146047592163086, 0.33146044611930847, 0.33143699169158936, 0.3312041461467743, 0.33559203147888184, 0.33559203147888184, 0.33556848764419556, 0.3534209132194519]\n",
      "[ 0  2 17  9  3  5  1  6  4 14 15 16 10  7 11  8 12 13]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 17]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9374999999999999\n",
      "mean acc:  0.8888888888888888\n",
      "mean auc:  0.9489274739274739\n",
      "\n",
      "index:  575\n",
      "0 label:  1\n",
      "node range:  [575, 576, 577, 578, 579, 580, 581, 582, 42, 20, 85, 86, 574]\n",
      "target node:  575\n",
      "epoch time:  0.1447451114654541\n",
      "[0.3575967848300934, 0.3578200340270996, 0.34382888674736023, 0.3545009195804596, 0.34713849425315857, 0.338000625371933, 0.3360597491264343, 0.33893588185310364, 0.33642852306365967, 0.3320516049861908, 0.3320516049861908, 0.3320516049861908, 0.3528937101364136]\n",
      "[ 1  0  3 12  4  2  7  5  8  6 11 10  9]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8888888888888887\n",
      "mean auc:  0.9495404936194409\n",
      "\n",
      "index:  576\n",
      "0 label:  1\n",
      "node range:  [576, 577, 578, 579, 581, 582, 42, 574, 575]\n",
      "target node:  576\n",
      "epoch time:  0.08075594902038574\n",
      "[0.368984192609787, 0.3446767032146454, 0.3541538119316101, 0.36671388149261475, 0.34565725922584534, 0.34958958625793457, 0.33907845616340637, 0.34668850898742676, 0.3655906319618225]\n",
      "[0 3 8 2 5 7 4 1 6]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8888888888888886\n",
      "mean auc:  0.9508343271163784\n",
      "\n",
      "index:  577\n",
      "0 label:  1\n",
      "node range:  [577, 576, 578, 579, 580, 581, 582, 42, 20, 85, 86, 574, 575]\n",
      "target node:  577\n",
      "epoch time:  0.11651778221130371\n",
      "[0.3575967848300934, 0.338000625371933, 0.354500949382782, 0.3360597789287567, 0.3578200340270996, 0.34713849425315857, 0.33893582224845886, 0.33642852306365967, 0.3320516049861908, 0.3320516049861908, 0.3320516049861908, 0.3528936803340912, 0.34382888674736023]\n",
      "[ 4  0  2 11  5 12  6  1  7  3 10  9  8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.888888888888889\n",
      "mean auc:  0.9513690244940245\n",
      "\n",
      "index:  578\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  579\n",
      "0 label:  1\n",
      "node range:  [579, 576, 577, 578, 580, 581, 582, 574, 575]\n",
      "target node:  579\n",
      "epoch time:  0.08484506607055664\n",
      "[0.3604322075843811, 0.35820528864860535, 0.33623364567756653, 0.3554757833480835, 0.33900347352027893, 0.34700849652290344, 0.3583422899246216, 0.3377439081668854, 0.34689080715179443]\n",
      "[0 6 1 3 5 8 4 7 2]\n",
      "foo\n",
      "\n",
      "index:  580\n",
      "0 label:  1\n",
      "node range:  [580, 577, 578, 579, 581, 582, 42, 574, 575]\n",
      "target node:  580\n",
      "epoch time:  0.0718531608581543\n",
      "[0.3689841628074646, 0.3655906915664673, 0.3541537821292877, 0.34565725922584534, 0.3667139410972595, 0.34958958625793457, 0.33907854557037354, 0.3466884195804596, 0.34467679262161255]\n",
      "[0 4 1 2 5 7 3 8 6]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8888888888888888\n",
      "mean auc:  0.9525551458478287\n",
      "\n",
      "index:  581\n",
      "0 label:  1\n",
      "node range:  [581, 576, 577, 578, 579, 580, 582, 574, 575]\n",
      "target node:  581\n",
      "epoch time:  0.09778642654418945\n",
      "[0.3604322075843811, 0.33900347352027893, 0.34689080715179443, 0.3554757833480835, 0.34700849652290344, 0.35820528864860535, 0.3583422899246216, 0.3377439081668854, 0.33623364567756653]\n",
      "[0 6 5 3 4 2 1 7 8]\n",
      "foo\n",
      "\n",
      "index:  582\n",
      "0 label:  1\n",
      "node range:  [582, 576, 577, 578, 579, 580, 581, 575]\n",
      "target node:  582\n",
      "epoch time:  0.06398844718933105\n",
      "[0.36824873089790344, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963, 0.36502206325531006, 0.3374617099761963]\n",
      "[0 6 4 3 5 1 7 2]\n",
      "foo\n",
      "\n",
      "index:  583\n",
      "0 label:  1\n",
      "node range:  [583, 11, 23, 47, 48, 195, 196, 197, 198, 584, 585, 586, 587, 588, 589, 590, 97, 98, 621]\n",
      "target node:  583\n",
      "epoch time:  0.16065430641174316\n",
      "[0.3551832139492035, 0.33122700452804565, 0.3354451060295105, 0.33122700452804565, 0.34842973947525024, 0.33122700452804565, 0.33122700452804565, 0.33120301365852356, 0.3309648036956787, 0.3527096211910248, 0.33728817105293274, 0.35364750027656555, 0.343137264251709, 0.33637645840644836, 0.33965441584587097, 0.33720117807388306, 0.3354451060295105, 0.33542105555534363, 0.33173811435699463]\n",
      "[ 0 11  9  4 12 14 10 15 13 16  2 17 18  6  5  3  1  7  8]\n",
      "truth node:  [0, 9, 10, 11, 12, 13, 14, 15]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9431818181818181\n",
      "mean acc:  0.8888888888888887\n",
      "mean auc:  0.9523319713795905\n",
      "\n",
      "index:  584\n",
      "0 label:  1\n",
      "node range:  [584, 97, 98, 583, 585, 586, 587, 588, 621, 590, 589, 48, 591, 620, 624, 23]\n",
      "target node:  584\n",
      "epoch time:  0.167952299118042\n",
      "[0.3547421395778656, 0.331582248210907, 0.331582248210907, 0.3524058759212494, 0.35296830534935, 0.3438586890697479, 0.3534151613712311, 0.34393084049224854, 0.337496280670166, 0.3357524573802948, 0.33778226375579834, 0.3361451029777527, 0.337792307138443, 0.3320627510547638, 0.3320627510547638, 0.331582248210907]\n",
      "[ 0  6  4  3  7  5 12 10  8 11  9 14 13 15  2  1]\n",
      "truth node:  [0, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14]\n",
      "acc:  1.0\n",
      "auc:  0.9682539682539683\n",
      "mean acc:  0.8914728682170542\n",
      "mean auc:  0.952702250376669\n",
      "\n",
      "index:  585\n",
      "0 label:  1\n",
      "node range:  [585, 583, 584, 586, 587, 620, 588, 621, 591, 624, 48, 590, 619, 623, 627]\n",
      "target node:  585\n",
      "epoch time:  0.13547992706298828\n",
      "[0.35699304938316345, 0.33737629652023315, 0.3531254827976227, 0.3364797830581665, 0.343158483505249, 0.33745622634887695, 0.3540911078453064, 0.35139280557632446, 0.33974581956863403, 0.3374961018562317, 0.3316386640071869, 0.33732590079307556, 0.3319372236728668, 0.33412429690361023, 0.33240464329719543]\n",
      "[ 0  6  2  7  4  8  9  5  1 11  3 13 14 12 10]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14]\n",
      "acc:  1.0\n",
      "auc:  0.8035714285714285\n",
      "mean acc:  0.8939393939393938\n",
      "mean auc:  0.9493129135174591\n",
      "\n",
      "index:  586\n",
      "0 label:  1\n",
      "node range:  [586, 97, 98, 583, 584, 585, 587, 588, 589, 590, 591, 48, 23]\n",
      "target node:  586\n",
      "epoch time:  0.12388992309570312\n",
      "[0.35801205039024353, 0.3318113088607788, 0.3318113088607788, 0.3530852496623993, 0.3437967300415039, 0.3366754651069641, 0.3547103703022003, 0.3358824551105499, 0.35824623703956604, 0.34729140996932983, 0.3388258218765259, 0.3362959325313568, 0.3318113088607788]\n",
      "[ 8  0  6  3  9  4 10  5 11  7 12  2  1]\n",
      "truth node:  [0, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8938271604938269\n",
      "mean auc:  0.9498220092664538\n",
      "\n",
      "index:  587\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  588\n",
      "0 label:  1\n",
      "node range:  [588, 583, 584, 585, 586, 587, 621, 590, 591, 620, 624, 589]\n",
      "target node:  588\n",
      "epoch time:  0.12621808052062988\n",
      "[0.35790178179740906, 0.3367358148097992, 0.34384506940841675, 0.3535033166408539, 0.33594974875450134, 0.35456836223602295, 0.33766821026802063, 0.34722766280174255, 0.35806071758270264, 0.3323863446712494, 0.3323863446712494, 0.3388510048389435]\n",
      "[ 8  0  5  3  7  2 11  6  1  4 10  9]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "acc:  1.0\n",
      "auc:  0.925925925925926\n",
      "mean acc:  0.896135265700483\n",
      "mean auc:  0.9493025291938335\n",
      "\n",
      "index:  589\n",
      "0 label:  1\n",
      "node range:  [589, 583, 584, 586, 587, 588, 590, 591, 48]\n",
      "target node:  589\n",
      "epoch time:  0.0844883918762207\n",
      "[0.3689841628074646, 0.3466884195804596, 0.3446767032146454, 0.3655906617641449, 0.3541537821292877, 0.34565725922584534, 0.36671391129493713, 0.34958958625793457, 0.33907854557037354]\n",
      "[0 6 3 4 7 1 5 2 8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8959810874704489\n",
      "mean auc:  0.9503811987854541\n",
      "\n",
      "index:  590\n",
      "0 label:  1\n",
      "node range:  [590, 583, 584, 585, 586, 587, 588, 589, 591]\n",
      "target node:  590\n",
      "epoch time:  0.08960390090942383\n",
      "[0.36099377274513245, 0.3376148045063019, 0.33605918288230896, 0.3376148045063019, 0.34707656502723694, 0.35576555132865906, 0.34707656502723694, 0.3587154150009155, 0.3587154150009155]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  591\n",
      "0 label:  1\n",
      "node range:  [591, 584, 585, 586, 587, 588, 589, 621, 590]\n",
      "target node:  591\n",
      "epoch time:  0.10139989852905273\n",
      "[0.3686867654323578, 0.3360249698162079, 0.33873632550239563, 0.3372718393802643, 0.348693311214447, 0.3641353249549866, 0.3425397276878357, 0.3290061056613922, 0.3655732274055481]\n",
      "[0 8 5 4 6 2 3 1 7]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8958333333333334\n",
      "mean auc:  0.9514149238107571\n",
      "\n",
      "index:  592\n",
      "0 label:  1\n",
      "node range:  [592, 599, 12, 109, 110, 593, 594, 595, 596, 53, 598, 54, 597, 26, 219, 220, 221, 222]\n",
      "target node:  592\n",
      "epoch time:  0.1830451488494873\n",
      "[0.3550933301448822, 0.33729061484336853, 0.331144243478775, 0.3355517089366913, 0.33552807569503784, 0.3534834086894989, 0.33969905972480774, 0.3534834086894989, 0.3432292640209198, 0.33137786388397217, 0.33969905972480774, 0.3483012020587921, 0.33729061484336853, 0.33552804589271545, 0.33140143752098083, 0.33140143752098083, 0.33137786388397217, 0.331144243478775]\n",
      "[ 0  5  7 11  8 10  6 12  1  3  4 13 14 15  9 16  2 17]\n",
      "truth node:  [0, 1, 5, 6, 7, 8, 10, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9375\n",
      "mean acc:  0.8956916099773242\n",
      "mean auc:  0.9511309457738029\n",
      "\n",
      "index:  593\n",
      "0 label:  1\n",
      "node range:  [593, 600, 109, 110, 592, 594, 595, 596, 597, 54, 599, 598, 26]\n",
      "target node:  593\n",
      "epoch time:  0.10872030258178711\n",
      "[0.35759681463241577, 0.33893582224845886, 0.3320516049861908, 0.3320516049861908, 0.3528937101364136, 0.357820063829422, 0.34382888674736023, 0.3545009195804596, 0.34713852405548096, 0.33642852306365967, 0.3360597491264343, 0.338000625371933, 0.3320516049861908]\n",
      "[ 5  0  7  4  8  6  1 11  9 10 12  3  2]\n",
      "truth node:  [0, 1, 4, 5, 6, 7, 8, 10, 11]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8955555555555554\n",
      "mean auc:  0.9515527713027713\n",
      "\n",
      "index:  594\n",
      "0 label:  1\n",
      "node range:  [594, 592, 593, 595, 596, 597, 54, 599, 600]\n",
      "target node:  594\n",
      "epoch time:  0.11588811874389648\n",
      "[0.3689841628074646, 0.34668850898742676, 0.3655907213687897, 0.34467679262161255, 0.3541537821292877, 0.36671391129493713, 0.33907854557037354, 0.3456572890281677, 0.34958958625793457]\n",
      "[0 5 2 4 8 1 7 3 6]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.895424836601307\n",
      "mean auc:  0.9525027169635013\n",
      "\n",
      "index:  595\n",
      "0 label:  1\n",
      "node range:  [595, 600, 109, 110, 592, 593, 594, 596, 597, 54, 599, 598, 26]\n",
      "target node:  595\n",
      "epoch time:  0.13979291915893555\n",
      "[0.3575967848300934, 0.33893588185310364, 0.3320516049861908, 0.3320516049861908, 0.3528937101364136, 0.34382888674736023, 0.338000625371933, 0.3545009195804596, 0.3360597789287567, 0.33642852306365967, 0.34713849425315857, 0.357820063829422, 0.3320516049861908]\n",
      "[11  0  7  4 10  5  1  6  9  8 12  3  2]\n",
      "truth node:  [0, 1, 4, 5, 6, 7, 8, 10, 11]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.895299145299145\n",
      "mean auc:  0.9528819382184767\n",
      "\n",
      "index:  596\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  597\n",
      "0 label:  1\n",
      "node range:  [597, 592, 593, 594, 595, 596, 598, 599, 600]\n",
      "target node:  597\n",
      "epoch time:  0.0914003849029541\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554758131504059, 0.33900341391563416, 0.34700849652290344, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  598\n",
      "0 label:  1\n",
      "node range:  [598, 599, 592, 593, 595, 596, 597, 54, 600]\n",
      "target node:  598\n",
      "epoch time:  0.07111358642578125\n",
      "[0.3689841330051422, 0.36671391129493713, 0.34668856859207153, 0.344676673412323, 0.3655906915664673, 0.3541537821292877, 0.34565725922584534, 0.3390786349773407, 0.3495897054672241]\n",
      "[0 1 4 5 8 2 6 3 7]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8951781970649892\n",
      "mean auc:  0.9537709582520902\n",
      "\n",
      "index:  599\n",
      "0 label:  1\n",
      "node range:  [599, 592, 593, 594, 595, 596, 597, 598, 600]\n",
      "target node:  599\n",
      "epoch time:  0.08034944534301758\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900341391563416, 0.34689080715179443, 0.3554758131504059, 0.34700843691825867, 0.35820525884628296, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  600\n",
      "0 label:  1\n",
      "node range:  [600, 593, 594, 595, 596, 597, 598, 599]\n",
      "target node:  600\n",
      "epoch time:  0.07475757598876953\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963, 0.3650220036506653]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  601\n",
      "0 label:  1\n",
      "node range:  [601, 608, 121, 605, 59, 604, 14, 243, 244, 245, 246, 602, 122, 603, 60, 29, 606, 607]\n",
      "target node:  601\n",
      "epoch time:  0.1542956829071045\n",
      "[0.3550257384777069, 0.33731284737586975, 0.33559203147888184, 0.34321895241737366, 0.33146044611930847, 0.3534209132194519, 0.33146047592163086, 0.33146044611930847, 0.33146044611930847, 0.33143699169158936, 0.3312041461467743, 0.3534209132194519, 0.33556848764419556, 0.3397080898284912, 0.3483044505119324, 0.33559203147888184, 0.33731284737586975, 0.3397080898284912]\n",
      "[ 0 11  5 14  3 17 13 16  1 15  2 12  6  7  4  8  9 10]\n",
      "truth node:  [0, 1, 3, 5, 11, 13, 16, 17]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9374999999999999\n",
      "mean acc:  0.8950617283950614\n",
      "mean auc:  0.9534696442103849\n",
      "\n",
      "index:  602\n",
      "0 label:  1\n",
      "node range:  [602, 608, 609, 605, 122, 60, 601, 121, 603, 604, 29, 606, 607]\n",
      "target node:  602\n",
      "epoch time:  0.10736560821533203\n",
      "[0.3575967848300934, 0.3360597491264343, 0.33893582224845886, 0.3545009195804596, 0.3320516049861908, 0.33642852306365967, 0.3528937101364136, 0.33205166459083557, 0.3578200340270996, 0.34382888674736023, 0.3320516049861908, 0.34713852405548096, 0.338000625371933]\n",
      "[ 8  0  3  6 11  9  2 12  5  1  7 10  4]\n",
      "truth node:  [0, 1, 2, 3, 6, 8, 9, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8949494949494945\n",
      "mean auc:  0.9538106001742365\n",
      "\n",
      "index:  603\n",
      "0 label:  1\n",
      "node range:  [603, 608, 609, 601, 602, 60, 605, 606, 604]\n",
      "target node:  603\n",
      "epoch time:  0.08072781562805176\n",
      "[0.3689841628074646, 0.3456574082374573, 0.34958964586257935, 0.34668856859207153, 0.3655906319618225, 0.33907845616340637, 0.3541537821292877, 0.36671391129493713, 0.3446767032146454]\n",
      "[0 7 4 6 2 3 1 8 5]\n",
      "truth node:  [0, 1, 2, 3, 4, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8948412698412699\n",
      "mean auc:  0.9546354108854109\n",
      "\n",
      "index:  604\n",
      "0 label:  1\n",
      "node range:  [604, 608, 609, 605, 122, 60, 601, 121, 602, 603, 29, 606, 607]\n",
      "target node:  604\n",
      "epoch time:  0.1369180679321289\n",
      "[0.3575967848300934, 0.34713852405548096, 0.33893585205078125, 0.3545009195804596, 0.3320516049861908, 0.33642852306365967, 0.3528937101364136, 0.3320516049861908, 0.34382888674736023, 0.338000625371933, 0.3320516049861908, 0.3360597491264343, 0.357820063829422]\n",
      "[12  0  3  6  1  8  2  9  5 11 10  7  4]\n",
      "truth node:  [0, 1, 2, 3, 6, 8, 9, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8947368421052632\n",
      "mean auc:  0.9549439514351795\n",
      "\n",
      "index:  605\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  606\n",
      "0 label:  1\n",
      "node range:  [606, 608, 609, 601, 602, 603, 604, 605, 607]\n",
      "target node:  606\n",
      "epoch time:  0.1431112289428711\n",
      "[0.3604322075843811, 0.34700849652290344, 0.3583422899246216, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554757833480835, 0.33900341391563416]\n",
      "[0 2 5 7 1 4 8 3 6]\n",
      "foo\n",
      "\n",
      "index:  607\n",
      "0 label:  1\n",
      "node range:  [607, 608, 609, 604, 601, 602, 60, 605, 606]\n",
      "target node:  607\n",
      "epoch time:  0.13704562187194824\n",
      "[0.368984192609787, 0.36671391129493713, 0.34958961606025696, 0.3655906915664673, 0.3466886281967163, 0.34467679262161255, 0.3390786945819855, 0.35415375232696533, 0.3456572890281677]\n",
      "[0 1 3 7 2 4 8 5 6]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8946360153256705\n",
      "mean auc:  0.955720779858711\n",
      "\n",
      "index:  608\n",
      "0 label:  1\n",
      "node range:  [608, 609, 601, 602, 603, 604, 605, 606, 607]\n",
      "target node:  608\n",
      "epoch time:  0.14557218551635742\n",
      "[0.3604322075843811, 0.3583422303199768, 0.3377439081668854, 0.33623364567756653, 0.33900341391563416, 0.34689080715179443, 0.3554758131504059, 0.34700849652290344, 0.35820525884628296]\n",
      "[0 1 8 6 7 5 4 2 3]\n",
      "foo\n",
      "\n",
      "index:  609\n",
      "0 label:  1\n",
      "node range:  [609, 608, 602, 603, 604, 605, 606, 607]\n",
      "target node:  609\n",
      "epoch time:  0.12594032287597656\n",
      "[0.36824873089790344, 0.3650220036506653, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963]\n",
      "[0 6 1 5 7 3 4 2]\n",
      "foo\n",
      "\n",
      "index:  610\n",
      "0 label:  1\n",
      "node range:  [610, 32, 65, 66, 612, 133, 614, 134, 616, 611, 613, 267, 268, 269, 270, 15, 615, 617]\n",
      "target node:  610\n",
      "epoch time:  0.3071472644805908\n",
      "[0.35404062271118164, 0.3360944390296936, 0.3322283923625946, 0.34821876883506775, 0.339794397354126, 0.33623456954956055, 0.34303733706474304, 0.3361961245536804, 0.33979442715644836, 0.35251274704933167, 0.35251274704933167, 0.3333037197589874, 0.3333037197589874, 0.3332495391368866, 0.3326731324195862, 0.3322283923625946, 0.33758148550987244, 0.33758148550987244]\n",
      "[ 0 10  9  3  6  8  4 16 17  5  7  1 11 12 13 14 15  2]\n",
      "truth node:  [0, 4, 6, 8, 9, 10, 16, 17]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9375\n",
      "mean acc:  0.8945386064030131\n",
      "mean auc:  0.9554119530814447\n",
      "\n",
      "index:  611\n",
      "0 label:  1\n",
      "node range:  [611, 32, 66, 610, 613, 133, 615, 134, 617, 612, 614, 616, 618]\n",
      "target node:  611\n",
      "epoch time:  0.12173318862915039\n",
      "[0.3575967848300934, 0.3320516049861908, 0.33642852306365967, 0.3528936803340912, 0.34382888674736023, 0.3320516049861908, 0.34713849425315857, 0.3320516049861908, 0.3360597491264343, 0.3578200340270996, 0.3545009195804596, 0.338000625371933, 0.33893582224845886]\n",
      "[ 9  0 10  3  6  4 12 11  2  8  7  5  1]\n",
      "truth node:  [0, 3, 4, 6, 8, 9, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8944444444444443\n",
      "mean auc:  0.9556921242337909\n",
      "\n",
      "index:  612\n",
      "0 label:  1\n",
      "node range:  [612, 66, 610, 611, 614, 613, 615, 617, 618]\n",
      "target node:  612\n",
      "epoch time:  0.07900404930114746\n",
      "[0.3689841628074646, 0.3390783965587616, 0.3466884195804596, 0.3655906319618225, 0.3541537821292877, 0.3446767032146454, 0.36671391129493713, 0.34565725922584534, 0.3495897054672241]\n",
      "[0 6 3 4 8 2 7 5 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8943533697632057\n",
      "mean auc:  0.9564184828529091\n",
      "\n",
      "index:  613\n",
      "0 label:  1\n",
      "node range:  [613, 32, 66, 611, 610, 133, 615, 134, 617, 612, 614, 616, 618]\n",
      "target node:  613\n",
      "epoch time:  0.1293942928314209\n",
      "[0.3575967848300934, 0.3320516049861908, 0.33642852306365967, 0.34382888674736023, 0.3528936803340912, 0.3320516049861908, 0.3360597491264343, 0.3320516049861908, 0.34713849425315857, 0.338000625371933, 0.3545009195804596, 0.3578200340270996, 0.33893582224845886]\n",
      "[11  0 10  4  8  3 12  9  2  6  7  5  1]\n",
      "truth node:  [0, 3, 4, 6, 8, 9, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8942652329749101\n",
      "mean auc:  0.9566733818749948\n",
      "\n",
      "index:  614\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  615\n",
      "0 label:  1\n",
      "node range:  [615, 610, 611, 612, 613, 614, 616, 617, 618]\n",
      "target node:  615\n",
      "epoch time:  0.08003497123718262\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554757833480835, 0.33900347352027893, 0.34700843691825867, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  616\n",
      "0 label:  1\n",
      "node range:  [616, 66, 610, 611, 613, 614, 615, 617, 618]\n",
      "target node:  616\n",
      "epoch time:  0.10120224952697754\n",
      "[0.3689841628074646, 0.33907854557037354, 0.3466884195804596, 0.34467679262161255, 0.3655906319618225, 0.3541537821292877, 0.34565725922584534, 0.36671391129493713, 0.34958961606025696]\n",
      "[0 7 4 5 8 2 6 3 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8941798941798939\n",
      "mean auc:  0.9573611059722171\n",
      "\n",
      "index:  617\n",
      "0 label:  1\n",
      "node range:  [617, 610, 611, 612, 613, 614, 615, 616, 618]\n",
      "target node:  617\n",
      "epoch time:  0.0859229564666748\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900347352027893, 0.34689080715179443, 0.3554757833480835, 0.34700843691825867, 0.35820528864860535, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  618\n",
      "0 label:  1\n",
      "node range:  [618, 611, 612, 613, 614, 615, 616, 617]\n",
      "target node:  618\n",
      "epoch time:  0.09322667121887207\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.36502206325531006, 0.3425886631011963, 0.3650219738483429]\n",
      "[0 5 7 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  619\n",
      "0 label:  1\n",
      "node range:  [619, 145, 146, 17, 35, 291, 292, 293, 294, 946, 71, 72, 585, 620, 621, 622, 623, 624, 625, 626]\n",
      "target node:  619\n",
      "epoch time:  0.1538398265838623\n",
      "[0.3543853759765625, 0.33598238229751587, 0.33489087224006653, 0.3318594694137573, 0.3358367085456848, 0.332974910736084, 0.332974910736084, 0.3323081135749817, 0.3318227231502533, 0.33133620023727417, 0.3318595290184021, 0.34802985191345215, 0.3322924077510834, 0.35205966234207153, 0.337510883808136, 0.3529422879219055, 0.34301018714904785, 0.3366589844226837, 0.33973759412765503, 0.33743563294410706]\n",
      "[ 0 15 13 11 16 18 14 19 17  1  4  2  6  5  7 12 10  3  8  9]\n",
      "truth node:  [0, 13, 14, 15, 16, 17, 18, 19]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9479166666666667\n",
      "mean acc:  0.8940972222222223\n",
      "mean auc:  0.9572135366080678\n",
      "\n",
      "index:  620\n",
      "0 label:  1\n",
      "node range:  [620, 35, 72, 585, 584, 619, 621, 622, 623, 624, 145, 626, 146, 625, 588, 627]\n",
      "target node:  620\n",
      "epoch time:  0.14931917190551758\n",
      "[0.3548058867454529, 0.33150792121887207, 0.3360927999019623, 0.33747586607933044, 0.3320123851299286, 0.352428674697876, 0.3530280292034149, 0.34386131167411804, 0.35347214341163635, 0.3439459502696991, 0.33150795102119446, 0.3357221186161041, 0.3312731385231018, 0.33775603771209717, 0.3320123851299286, 0.33777305483818054]\n",
      "[ 0  8  6  5  9  7 15 13  3  2 11 14  4 10  1 12]\n",
      "truth node:  [0, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15]\n",
      "acc:  1.0\n",
      "auc:  0.9682539682539683\n",
      "mean acc:  0.8957264957264959\n",
      "mean auc:  0.9573833894026201\n",
      "\n",
      "index:  621\n",
      "0 label:  1\n",
      "node range:  [621, 583, 584, 585, 72, 619, 588, 587, 623, 591, 620, 624, 627, 622, 626]\n",
      "target node:  621\n",
      "epoch time:  0.13971662521362305\n",
      "[0.35699301958084106, 0.3319372236728668, 0.33745622634887695, 0.35139280557632446, 0.3316386938095093, 0.33737632632255554, 0.3374961018562317, 0.33412429690361023, 0.343158483505249, 0.33240464329719543, 0.35312551259994507, 0.354091078042984, 0.33974581956863403, 0.3364797830581665, 0.33732590079307556]\n",
      "[ 0 11 10  3  8 12  6  2  5 14 13  7  9  1  4]\n",
      "truth node:  [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "acc:  1.0\n",
      "auc:  0.8035714285714285\n",
      "mean acc:  0.8973063973063974\n",
      "mean auc:  0.9550529051476021\n",
      "\n",
      "index:  622\n",
      "0 label:  1\n",
      "node range:  [622, 35, 72, 619, 620, 621, 623, 624, 145, 626, 146, 625, 627]\n",
      "target node:  622\n",
      "epoch time:  0.1314067840576172\n",
      "[0.3580971658229828, 0.33174026012420654, 0.3362465500831604, 0.3531147539615631, 0.3438010811805725, 0.33664602041244507, 0.354777455329895, 0.3358544707298279, 0.33174026012420654, 0.34732785820961, 0.3315103054046631, 0.35833805799484253, 0.33881446719169617]\n",
      "[11  0  6  3  9  4 12  5  2  7  8  1 10]\n",
      "truth node:  [0, 3, 4, 5, 6, 7, 9, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8971807628524047\n",
      "mean auc:  0.9553091636114024\n",
      "\n",
      "index:  623\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  624\n",
      "0 label:  1\n",
      "node range:  [624, 584, 585, 619, 620, 588, 622, 621, 623, 626, 627, 625]\n",
      "target node:  624\n",
      "epoch time:  0.09764957427978516\n",
      "[0.35790178179740906, 0.332386314868927, 0.33766821026802063, 0.3367358446121216, 0.34384506940841675, 0.332386314868927, 0.33594974875450134, 0.3535033166408539, 0.35456836223602295, 0.34722766280174255, 0.35806071758270264, 0.33885103464126587]\n",
      "[10  0  8  7  9  4 11  2  3  6  5  1]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "acc:  1.0\n",
      "auc:  0.925925925925926\n",
      "mean acc:  0.8986928104575164\n",
      "mean auc:  0.9548770571748513\n",
      "\n",
      "index:  625\n",
      "0 label:  1\n",
      "node range:  [625, 72, 619, 620, 622, 623, 624, 626, 627]\n",
      "target node:  625\n",
      "epoch time:  0.09194087982177734\n",
      "[0.3689841330051422, 0.33907854557037354, 0.346688449382782, 0.34467682242393494, 0.3655906319618225, 0.3541537821292877, 0.3456572890281677, 0.36671391129493713, 0.34958967566490173]\n",
      "[0 7 4 5 8 2 6 3 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8985507246376812\n",
      "mean auc:  0.9555310128679694\n",
      "\n",
      "index:  626\n",
      "0 label:  1\n",
      "node range:  [626, 619, 620, 621, 622, 623, 624, 625, 627]\n",
      "target node:  626\n",
      "epoch time:  0.0904688835144043\n",
      "[0.36099377274513245, 0.3376148045063019, 0.33605918288230896, 0.3376147747039795, 0.34707656502723694, 0.35576555132865906, 0.34707656502723694, 0.3587154150009155, 0.3587154150009155]\n",
      "[0 8 7 5 6 4 1 3 2]\n",
      "foo\n",
      "\n",
      "index:  627\n",
      "0 label:  1\n",
      "node range:  [627, 585, 620, 621, 622, 623, 624, 625, 626]\n",
      "target node:  627\n",
      "epoch time:  0.0891265869140625\n",
      "[0.3686867654323578, 0.3290061056613922, 0.3360249698162079, 0.33873632550239563, 0.3372718393802643, 0.348693311214447, 0.3641353249549866, 0.34253978729248047, 0.3655732274055481]\n",
      "[0 8 6 5 7 3 4 2 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8984126984126983\n",
      "mean auc:  0.9561662841127126\n",
      "\n",
      "index:  628\n",
      "0 label:  1\n",
      "node range:  [628, 318, 38, 317, 635, 77, 78, 18, 629, 630, 631, 632, 633, 634, 315, 316, 157, 158]\n",
      "target node:  628\n",
      "epoch time:  0.15021300315856934\n",
      "[0.35434940457344055, 0.33246031403541565, 0.3359457850456238, 0.33305057883262634, 0.33658623695373535, 0.33198219537734985, 0.34836265444755554, 0.3317555785179138, 0.3527432978153229, 0.33975955843925476, 0.3526709973812103, 0.3430406451225281, 0.3374471664428711, 0.33967694640159607, 0.3331061005592346, 0.3331061005592346, 0.3361121118068695, 0.336072713136673]\n",
      "[ 0  8 10  6 11  9 13 12  4 16 17  2 15 14  3  1  5  7]\n",
      "truth node:  [0, 4, 8, 9, 10, 11, 12, 13]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9375\n",
      "mean acc:  0.8982785602503911\n",
      "mean auc:  0.9559033787026745\n",
      "\n",
      "index:  629\n",
      "0 label:  1\n",
      "node range:  [629, 38, 1158, 78, 628, 630, 631, 632, 633, 634, 635, 636, 157, 158]\n",
      "target node:  629\n",
      "epoch time:  0.12918663024902344\n",
      "[0.35772132873535156, 0.3319576382637024, 0.3316226899623871, 0.33637696504592896, 0.35300570726394653, 0.3579825758934021, 0.34381356835365295, 0.3542308807373047, 0.3471589982509613, 0.3374961018562317, 0.3349556028842926, 0.3384416997432709, 0.3319576382637024, 0.3319576680660248]\n",
      "[ 5  0  7  4  8  6 11  9  3 10 13 12  1  2]\n",
      "truth node:  [0, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9777777777777777\n",
      "mean acc:  0.8981481481481483\n",
      "mean auc:  0.9562071898009398\n",
      "\n",
      "index:  630\n",
      "0 label:  1\n",
      "node range:  [630, 78, 628, 629, 631, 632, 633, 635, 636]\n",
      "target node:  630\n",
      "epoch time:  0.1125340461730957\n",
      "[0.33852827548980713, 0.34054169058799744, 0.3400314152240753, 0.3387172222137451, 0.3401409685611725, 0.3395296633243561, 0.338630348443985, 0.34013640880584717, 0.33982107043266296]\n",
      "[1 4 7 2 8 5 3 6 0]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.0\n",
      "mean acc:  0.8980213089802132\n",
      "mean auc:  0.9431084611735296\n",
      "\n",
      "index:  631\n",
      "0 label:  1\n",
      "node range:  [631, 38, 1158, 78, 628, 629, 630, 632, 633, 634, 635, 636, 157, 158]\n",
      "target node:  631\n",
      "epoch time:  0.10989570617675781\n",
      "[0.3578932285308838, 0.33175128698349, 0.33426377177238464, 0.3362634778022766, 0.3532405197620392, 0.34386202692985535, 0.3378881812095642, 0.3539130687713623, 0.3358418643474579, 0.35690808296203613, 0.34431028366088867, 0.3376365303993225, 0.33175128698349, 0.33175128698349]\n",
      "[ 0  9  7  4 10  5  6 11  3  8  2 13 12  1]\n",
      "truth node:  [0, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9777777777777777\n",
      "mean acc:  0.8978978978978979\n",
      "mean auc:  0.9435769654519653\n",
      "\n",
      "index:  632\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  633\n",
      "0 label:  1\n",
      "node range:  [633, 1158, 628, 629, 630, 631, 632, 634, 635, 636]\n",
      "target node:  633\n",
      "epoch time:  0.08680033683776855\n",
      "[0.36086151003837585, 0.3345410227775574, 0.3376438319683075, 0.347051739692688, 0.35875391960144043, 0.3360403776168823, 0.35498160123825073, 0.3377639949321747, 0.3442925810813904, 0.35752350091934204]\n",
      "[0 4 9 6 3 8 7 2 5 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8992592592592592\n",
      "mean auc:  0.9443292725792725\n",
      "\n",
      "index:  634\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  635\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  636\n",
      "0 label:  1\n",
      "node range:  [636, 1155, 1157, 1158, 629, 630, 631, 632, 633, 634, 635]\n",
      "target node:  636\n",
      "epoch time:  0.10483765602111816\n",
      "[0.35739511251449585, 0.34750109910964966, 0.3475010395050049, 0.34955617785453796, 0.3498341143131256, 0.35141444206237793, 0.3495659828186035, 0.3523752987384796, 0.3572012186050415, 0.35035035014152527, 0.3561290204524994]\n",
      "[ 0  8 10  7  5  9  4  6  3  1  2]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.9005847953216374\n",
      "mean auc:  0.9450617821505979\n",
      "\n",
      "index:  637\n",
      "0 label:  1\n",
      "node range:  [637, 640, 641, 642, 643, 644, 41, 169, 170, 83, 20, 84, 339, 340, 341, 342, 638, 639]\n",
      "target node:  637\n",
      "epoch time:  0.17180132865905762\n",
      "[0.35404062271118164, 0.35251274704933167, 0.34303733706474304, 0.33758148550987244, 0.33979442715644836, 0.33758148550987244, 0.336094468832016, 0.33623456954956055, 0.3361961245536804, 0.3322283923625946, 0.3322283923625946, 0.34821876883506775, 0.3333037197589874, 0.3333037197589874, 0.3332495391368866, 0.3326731324195862, 0.35251274704933167, 0.339794397354126]\n",
      "[ 0  1 16 11  2  4 17  5  3  7  8  6 12 13 14 15 10  9]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 16, 17]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9375\n",
      "mean acc:  0.9004329004329004\n",
      "mean auc:  0.944963577187603\n",
      "\n",
      "index:  638\n",
      "0 label:  1\n",
      "node range:  [638, 640, 641, 642, 643, 644, 645, 41, 169, 170, 84, 637, 639]\n",
      "target node:  638\n",
      "epoch time:  0.11886286735534668\n",
      "[0.3575967848300934, 0.34382888674736023, 0.3545009195804596, 0.34713852405548096, 0.338000625371933, 0.3360597491264343, 0.33893588185310364, 0.33205166459083557, 0.33205166459083557, 0.33205166459083557, 0.33642852306365967, 0.3528937101364136, 0.357820063829422]\n",
      "[12  0  2 11  3  1  6  4 10  5  9  8  7]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.9002849002849002\n",
      "mean auc:  0.9453130469957393\n",
      "\n",
      "index:  639\n",
      "0 label:  1\n",
      "node range:  [639, 640, 641, 642, 644, 645, 84, 637, 638]\n",
      "target node:  639\n",
      "epoch time:  0.07405424118041992\n",
      "[0.368984192609787, 0.3446768820285797, 0.3541537821292877, 0.36671391129493713, 0.34565725922584534, 0.34958958625793457, 0.33907845616340637, 0.3466883897781372, 0.3655906319618225]\n",
      "[0 3 8 2 5 7 4 1 6]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.9001406469760899\n",
      "mean auc:  0.9460052869071857\n",
      "\n",
      "index:  640\n",
      "0 label:  1\n",
      "node range:  [640, 641, 642, 643, 644, 645, 41, 169, 170, 84, 637, 638, 639]\n",
      "target node:  640\n",
      "epoch time:  0.12919878959655762\n",
      "[0.3575967848300934, 0.3545009195804596, 0.3360597491264343, 0.3578200340270996, 0.34713849425315857, 0.33893582224845886, 0.33205166459083557, 0.33205166459083557, 0.33205169439315796, 0.33642852306365967, 0.3528937101364136, 0.34382885694503784, 0.338000625371933]\n",
      "[ 3  0  1 10  4 11  5 12  9  2  8  7  6]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.9000000000000001\n",
      "mean auc:  0.9463329985986235\n",
      "\n",
      "index:  641\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  642\n",
      "0 label:  1\n",
      "node range:  [642, 640, 641, 643, 644, 645, 637, 638, 639]\n",
      "target node:  642\n",
      "epoch time:  0.0870361328125\n",
      "[0.3604322075843811, 0.33623364567756653, 0.3554757833480835, 0.33900347352027893, 0.34700843691825867, 0.3583422899246216, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535]\n",
      "[0 5 8 2 4 7 3 6 1]\n",
      "foo\n",
      "\n",
      "index:  643\n",
      "0 label:  1\n",
      "node range:  [643, 640, 641, 642, 644, 645, 84, 637, 638]\n",
      "target node:  643\n",
      "epoch time:  0.10196876525878906\n",
      "[0.3689841628074646, 0.3655906319618225, 0.3541537821292877, 0.3456572890281677, 0.36671391129493713, 0.34958958625793457, 0.33907854557037354, 0.34668853878974915, 0.34467679262161255]\n",
      "[0 4 1 2 5 7 3 8 6]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8998628257887519\n",
      "mean auc:  0.94699555417148\n",
      "\n",
      "index:  644\n",
      "0 label:  1\n",
      "node range:  [644, 640, 641, 642, 643, 645, 637, 638, 639]\n",
      "target node:  644\n",
      "epoch time:  0.08634591102600098\n",
      "[0.3604322075843811, 0.34689080715179443, 0.3554757833480835, 0.34700843691825867, 0.35820528864860535, 0.3583422899246216, 0.3377439081668854, 0.33623364567756653, 0.33900341391563416]\n",
      "[0 5 4 2 3 1 8 6 7]\n",
      "foo\n",
      "\n",
      "index:  645\n",
      "0 label:  1\n",
      "node range:  [645, 640, 641, 642, 643, 644, 638, 639]\n",
      "target node:  645\n",
      "epoch time:  0.0936279296875\n",
      "[0.36824873089790344, 0.3374617099761963, 0.34873244166374207, 0.36502206325531006, 0.3425886631011963, 0.3650219738483429, 0.3374617099761963, 0.3425886631011963]\n",
      "[0 3 5 2 7 4 6 1]\n",
      "foo\n",
      "\n",
      "index:  646\n",
      "0 label:  1\n",
      "node range:  [646, 647, 648, 649, 650, 363, 652, 44, 364, 365, 366, 651, 653, 181, 182, 21, 89, 90]\n",
      "target node:  646\n",
      "epoch time:  0.17884182929992676\n",
      "[0.35411056876182556, 0.3525771498680115, 0.33979082107543945, 0.3525771498680115, 0.3430519998073578, 0.33325815200805664, 0.33979079127311707, 0.33604082465171814, 0.33325815200805664, 0.3332037329673767, 0.3326251208782196, 0.33756542205810547, 0.3375653922557831, 0.33620381355285645, 0.336165189743042, 0.3321565091609955, 0.33193439245224, 0.34822550415992737]\n",
      "[ 0  3  1 17  4  2  6 11 12 13 14  7  5  8  9 10 15 16]\n",
      "truth node:  [0, 1, 2, 3, 4, 6, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9375\n",
      "mean acc:  0.899728997289973\n",
      "mean auc:  0.9468797547303643\n",
      "\n",
      "index:  647\n",
      "0 label:  1\n",
      "node range:  [647, 646, 648, 649, 650, 651, 44, 653, 652, 654, 181, 182, 90]\n",
      "target node:  647\n",
      "epoch time:  0.11241483688354492\n",
      "[0.3575967848300934, 0.3528936803340912, 0.357820063829422, 0.34382885694503784, 0.3545009195804596, 0.34713852405548096, 0.3320516049861908, 0.3360597491264343, 0.338000625371933, 0.33893588185310364, 0.3320516049861908, 0.3320516049861908, 0.33642852306365967]\n",
      "[ 2  0  4  1  5  3  9  8 12  7 11 10  6]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 7, 8, 9]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8995983935742973\n",
      "mean auc:  0.9471850856640013\n",
      "\n",
      "index:  648\n",
      "0 label:  1\n",
      "node range:  [648, 646, 647, 649, 650, 651, 653, 654, 90]\n",
      "target node:  648\n",
      "epoch time:  0.09015965461730957\n",
      "[0.3689841628074646, 0.3466884195804596, 0.3655906319618225, 0.3446767032146454, 0.3541537821292877, 0.36671391129493713, 0.3456573784351349, 0.34958961606025696, 0.3390785753726959]\n",
      "[0 5 2 4 7 1 6 3 8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8994708994708995\n",
      "mean auc:  0.9478138346441918\n",
      "\n",
      "index:  649\n",
      "0 label:  1\n",
      "node range:  [649, 646, 647, 648, 650, 651, 44, 653, 652, 654, 181, 182, 90]\n",
      "target node:  649\n",
      "epoch time:  0.12021303176879883\n",
      "[0.3575967848300934, 0.3528937101364136, 0.34382885694503784, 0.338000625371933, 0.3545009195804596, 0.3360597491264343, 0.3320516049861908, 0.34713849425315857, 0.3578200340270996, 0.33893582224845886, 0.3320516049861908, 0.3320516049861908, 0.33642852306365967]\n",
      "[ 8  0  4  1  7  2  9  3 12  5 11 10  6]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 7, 8, 9]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8993464052287582\n",
      "mean auc:  0.9481009921451098\n",
      "\n",
      "index:  650\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  651\n",
      "0 label:  1\n",
      "node range:  [651, 646, 647, 648, 649, 650, 652, 653, 654]\n",
      "target node:  651\n",
      "epoch time:  0.09403729438781738\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554757833480835, 0.33900341391563416, 0.34700843691825867, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  652\n",
      "0 label:  1\n",
      "node range:  [652, 646, 647, 649, 650, 651, 653, 654, 90]\n",
      "target node:  652\n",
      "epoch time:  0.09373164176940918\n",
      "[0.3689841628074646, 0.3466884195804596, 0.34467679262161255, 0.3655906319618225, 0.3541537821292877, 0.34565725922584534, 0.3667139410972595, 0.34958961606025696, 0.33907854557037354]\n",
      "[0 6 3 4 7 1 5 2 8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8992248062015503\n",
      "mean auc:  0.9487044689806318\n",
      "\n",
      "index:  653\n",
      "0 label:  1\n",
      "node range:  [653, 646, 647, 648, 649, 650, 651, 652, 654]\n",
      "target node:  653\n",
      "epoch time:  0.0847926139831543\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900341391563416, 0.34689080715179443, 0.3554757833480835, 0.34700849652290344, 0.35820528864860535, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  654\n",
      "0 label:  1\n",
      "node range:  [654, 647, 648, 649, 650, 651, 652, 653]\n",
      "target node:  654\n",
      "epoch time:  0.08157134056091309\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963, 0.3650220036506653]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  655\n",
      "0 label:  1\n",
      "node range:  [655, 96, 193, 194, 387, 388, 389, 390, 47, 657, 656, 659, 658, 661, 660, 23, 662, 95]\n",
      "target node:  655\n",
      "epoch time:  0.15446972846984863\n",
      "[0.35404062271118164, 0.34821876883506775, 0.33623456954956055, 0.3361961245536804, 0.3333037495613098, 0.3333037495613098, 0.3332495391368866, 0.3326731324195862, 0.336094468832016, 0.339794397354126, 0.35251274704933167, 0.34303733706474304, 0.35251277685165405, 0.339794397354126, 0.33758148550987244, 0.3322283625602722, 0.33758148550987244, 0.3322283625602722]\n",
      "[ 0 12 10  1 11 13  9 14 16  2  3  8  5  4  6  7 15 17]\n",
      "truth node:  [0, 9, 10, 11, 12, 13, 14, 16]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9375\n",
      "mean acc:  0.8991060025542783\n",
      "mean auc:  0.9485756819808544\n",
      "\n",
      "index:  656\n",
      "0 label:  1\n",
      "node range:  [656, 96, 193, 194, 663, 47, 655, 658, 657, 660, 659, 662, 661]\n",
      "target node:  656\n",
      "epoch time:  0.11989068984985352\n",
      "[0.35759681463241577, 0.33642852306365967, 0.3320516049861908, 0.3320516049861908, 0.33893585205078125, 0.3320516049861908, 0.3528936803340912, 0.34382885694503784, 0.3578200340270996, 0.34713852405548096, 0.3545009195804596, 0.3360597491264343, 0.338000625371933]\n",
      "[ 8  0 10  6  9  7  4 12  1 11  5  3  2]\n",
      "truth node:  [0, 4, 6, 7, 8, 9, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8989898989898992\n",
      "mean auc:  0.9488443926654153\n",
      "\n",
      "index:  657\n",
      "0 label:  1\n",
      "node range:  [657, 96, 655, 656, 658, 659, 660, 662, 663]\n",
      "target node:  657\n",
      "epoch time:  0.08611607551574707\n",
      "[0.368984192609787, 0.3390786647796631, 0.34668850898742676, 0.3655907213687897, 0.34467679262161255, 0.3541537821292877, 0.36671391129493713, 0.3456572890281677, 0.34958964586257935]\n",
      "[0 6 3 5 8 2 7 4 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8988764044943822\n",
      "mean auc:  0.9494191747702984\n",
      "\n",
      "index:  658\n",
      "0 label:  1\n",
      "node range:  [658, 96, 193, 194, 663, 47, 656, 655, 657, 660, 659, 662, 661]\n",
      "target node:  658\n",
      "epoch time:  0.1178140640258789\n",
      "[0.3575967848300934, 0.33642852306365967, 0.3320516049861908, 0.33205169439315796, 0.33893585205078125, 0.3320516049861908, 0.34382888674736023, 0.3528936803340912, 0.338000625371933, 0.3360597491264343, 0.3545009195804596, 0.34713849425315857, 0.3578200340270996]\n",
      "[12  0 10  7 11  6  4  8  1  9  3  5  2]\n",
      "truth node:  [0, 4, 6, 7, 8, 9, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8987654320987656\n",
      "mean auc:  0.9496725419642087\n",
      "\n",
      "index:  659\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  660\n",
      "0 label:  1\n",
      "node range:  [660, 655, 656, 657, 658, 659, 661, 662, 663]\n",
      "target node:  660\n",
      "epoch time:  0.086883544921875\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820525884628296, 0.33623364567756653, 0.3554758131504059, 0.33900347352027893, 0.34700843691825867, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  661\n",
      "0 label:  1\n",
      "node range:  [661, 96, 655, 656, 658, 659, 660, 662, 663]\n",
      "target node:  661\n",
      "epoch time:  0.0932612419128418\n",
      "[0.368984192609787, 0.33907845616340637, 0.346688449382782, 0.3446767032146454, 0.3655906915664673, 0.3541537821292877, 0.34565725922584534, 0.36671391129493713, 0.34958958625793457]\n",
      "[0 7 4 5 8 2 6 3 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8986568986568988\n",
      "mean auc:  0.9502255909536129\n",
      "\n",
      "index:  662\n",
      "0 label:  1\n",
      "node range:  [662, 655, 656, 657, 658, 659, 660, 661, 663]\n",
      "target node:  662\n",
      "epoch time:  0.07822751998901367\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900341391563416, 0.34689080715179443, 0.3554758131504059, 0.34700843691825867, 0.35820528864860535, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  663\n",
      "0 label:  1\n",
      "node range:  [663, 656, 657, 658, 659, 660, 661, 662]\n",
      "target node:  663\n",
      "epoch time:  0.08281564712524414\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963, 0.3650220036506653]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  664\n",
      "0 label:  1\n",
      "node range:  [664, 414, 101, 102, 669, 205, 206, 667, 50, 665, 412, 24, 666, 411, 668, 413, 670, 671]\n",
      "target node:  664\n",
      "epoch time:  0.15965604782104492\n",
      "[0.35421377420425415, 0.33218204975128174, 0.332082599401474, 0.3482421934604645, 0.3375414311885834, 0.33615824580192566, 0.3360939621925354, 0.35267212986946106, 0.3359941840171814, 0.35267212986946106, 0.3331906199455261, 0.331859290599823, 0.3397851288318634, 0.3331906199455261, 0.3430732786655426, 0.33310002088546753, 0.3397851288318634, 0.3375414311885834]\n",
      "[ 0  9  7  3 14 12 16  4 17  5  6  8 10 13 15  1  2 11]\n",
      "truth node:  [0, 4, 7, 9, 12, 14, 16, 17]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9375\n",
      "mean acc:  0.8985507246376813\n",
      "mean auc:  0.9500872693128128\n",
      "\n",
      "index:  665\n",
      "0 label:  1\n",
      "node range:  [665, 672, 102, 205, 206, 50, 664, 666, 667, 668, 669, 670, 671]\n",
      "target node:  665\n",
      "epoch time:  0.11763739585876465\n",
      "[0.3580445945262909, 0.3374800682067871, 0.33629828691482544, 0.33178970217704773, 0.33178970217704773, 0.33178970217704773, 0.3532199263572693, 0.35814836621284485, 0.343899667263031, 0.35473453998565674, 0.34718790650367737, 0.33785396814346313, 0.33586546778678894]\n",
      "[ 7  0  9  6 10  8 11  1  2 12  5  4  3]\n",
      "truth node:  [0, 1, 6, 7, 8, 9, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8984468339307049\n",
      "mean auc:  0.9503252795591506\n",
      "\n",
      "index:  666\n",
      "0 label:  1\n",
      "node range:  [666, 672, 102, 1134, 664, 665, 667, 668, 669, 671]\n",
      "target node:  666\n",
      "epoch time:  0.09459924697875977\n",
      "[0.31863221526145935, 0.32577332854270935, 0.3282998502254486, 0.32819971442222595, 0.32576707005500793, 0.3200035095214844, 0.32664814591407776, 0.3233642578125, 0.320009708404541, 0.32664385437965393]\n",
      "[2 3 6 9 1 4 7 8 5 0]\n",
      "truth node:  [0, 1, 4, 5, 6, 7, 8, 9]\n",
      "acc:  0.7777777777777778\n",
      "auc:  0.0\n",
      "mean acc:  0.8971631205673758\n",
      "mean auc:  0.9402154361595851\n",
      "\n",
      "index:  667\n",
      "0 label:  1\n",
      "node range:  [667, 672, 102, 205, 206, 50, 664, 665, 666, 668, 669, 670, 671]\n",
      "target node:  667\n",
      "epoch time:  0.10106277465820312\n",
      "[0.3580446243286133, 0.3374800682067871, 0.33629828691482544, 0.33178970217704773, 0.33178967237472534, 0.33178967237472534, 0.3532199263572693, 0.3438996970653534, 0.3378539979457855, 0.35473453998565674, 0.33586546778678894, 0.35814836621284485, 0.34718790650367737]\n",
      "[11  0  9  6 12  7  8  1  2 10  3  5  4]\n",
      "truth node:  [0, 1, 6, 7, 8, 9, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8970760233918128\n",
      "mean auc:  0.9405523496970867\n",
      "\n",
      "index:  668\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  669\n",
      "0 label:  1\n",
      "node range:  [669, 672, 1133, 1134, 1137, 664, 665, 666, 667, 668, 670, 671]\n",
      "target node:  669\n",
      "epoch time:  0.11288118362426758\n",
      "[0.3579344153404236, 0.3536403179168701, 0.3323687016963959, 0.33767926692962646, 0.3323687016963959, 0.33752185106277466, 0.3471257984638214, 0.3579642176628113, 0.3359334170818329, 0.3545924723148346, 0.3379017412662506, 0.34394732117652893]\n",
      "[ 7  0  9  1  6 11 10  3  5  8  4  2]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "acc:  1.0\n",
      "auc:  0.925925925925926\n",
      "mean acc:  0.8981481481481484\n",
      "mean auc:  0.9403999911161369\n",
      "\n",
      "index:  670\n",
      "0 label:  1\n",
      "node range:  [670, 672, 102, 1134, 664, 665, 667, 668, 669, 671]\n",
      "target node:  670\n",
      "epoch time:  0.07770109176635742\n",
      "[0.3186321258544922, 0.32577353715896606, 0.3283001482486725, 0.32819992303848267, 0.32576707005500793, 0.32664844393730164, 0.3200036883354187, 0.3233642578125, 0.3266439735889435, 0.3200097978115082]\n",
      "[2 3 5 8 1 4 7 9 6 0]\n",
      "truth node:  [0, 1, 4, 5, 6, 7, 8, 9]\n",
      "acc:  0.7777777777777778\n",
      "auc:  0.0\n",
      "mean acc:  0.8969072164948455\n",
      "mean auc:  0.9307051458468985\n",
      "\n",
      "index:  671\n",
      "0 label:  1\n",
      "node range:  [671, 672, 1133, 1134, 1137, 664, 665, 666, 667, 668, 669, 670]\n",
      "target node:  671\n",
      "epoch time:  0.12886691093444824\n",
      "[0.3579344153404236, 0.3536403179168701, 0.3323687016963959, 0.33767929673194885, 0.3323687016963959, 0.33752191066741943, 0.3359334170818329, 0.337901771068573, 0.3471257984638214, 0.3545924723148346, 0.34394732117652893, 0.3579642176628113]\n",
      "[11  0  9  1  8 10  7  3  5  6  4  2]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "acc:  1.0\n",
      "auc:  0.925925925925926\n",
      "mean acc:  0.8979591836734695\n",
      "mean auc:  0.9306563782966844\n",
      "\n",
      "index:  672\n",
      "0 label:  1\n",
      "node range:  [672, 1132, 1133, 1134, 1136, 1137, 1140, 665, 666, 667, 668, 669, 670, 671]\n",
      "target node:  672\n",
      "epoch time:  0.1283707618713379\n",
      "[0.3566896915435791, 0.33220967650413513, 0.3375762104988098, 0.35113224387168884, 0.3343321979045868, 0.3376149535179138, 0.33266329765319824, 0.33745965361595154, 0.33979982137680054, 0.33745965361595154, 0.3432280421257019, 0.3537701964378357, 0.33979982137680054, 0.3537701964378357]\n",
      "[ 0 13 11  3 10 12  8  5  2  9  7  4  6  1]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "acc:  1.0\n",
      "auc:  0.8125\n",
      "mean acc:  0.8989898989898991\n",
      "mean auc:  0.9294628795260108\n",
      "\n",
      "index:  673\n",
      "0 label:  1\n",
      "node range:  [673, 674, 675, 26, 677, 676, 679, 678, 680, 107, 108, 435, 436, 53, 437, 438, 217, 218]\n",
      "target node:  673\n",
      "epoch time:  0.14869189262390137\n",
      "[0.35404062271118164, 0.35251274704933167, 0.33979442715644836, 0.3322283923625946, 0.34303733706474304, 0.35251274704933167, 0.33979442715644836, 0.33758148550987244, 0.33758148550987244, 0.3322283923625946, 0.34821876883506775, 0.3333037197589874, 0.3333037197589874, 0.336094468832016, 0.3332495391368866, 0.3326731324195862, 0.33623456954956055, 0.3361961245536804]\n",
      "[ 0  1  5 10  4  2  6  7  8 16 17 13 11 12 14 15  9  3]\n",
      "truth node:  [0, 1, 2, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9375\n",
      "mean acc:  0.898888888888889\n",
      "mean auc:  0.9295432507307507\n",
      "\n",
      "index:  674\n",
      "0 label:  1\n",
      "node range:  [674, 673, 675, 676, 677, 678, 679, 680, 681, 108, 53, 217, 218]\n",
      "target node:  674\n",
      "epoch time:  0.13187932968139648\n",
      "[0.3575967848300934, 0.3528936803340912, 0.3578200340270996, 0.34382885694503784, 0.3545009195804596, 0.34713849425315857, 0.338000625371933, 0.3360597789287567, 0.33893582224845886, 0.33642852306365967, 0.3320516049861908, 0.3320516049861908, 0.3320516049861908]\n",
      "[ 2  0  4  1  5  3  8  6  9  7 12 11 10]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8987898789878989\n",
      "mean auc:  0.9299658148049237\n",
      "\n",
      "index:  675\n",
      "0 label:  1\n",
      "node range:  [675, 673, 674, 676, 677, 678, 680, 681, 108]\n",
      "target node:  675\n",
      "epoch time:  0.0855245590209961\n",
      "[0.3689841628074646, 0.3466884195804596, 0.3655906617641449, 0.344676673412323, 0.35415375232696533, 0.36671391129493713, 0.3456572890281677, 0.34958958625793457, 0.3390783965587616]\n",
      "[0 5 2 4 7 1 6 3 8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8986928104575164\n",
      "mean auc:  0.930652424463699\n",
      "\n",
      "index:  676\n",
      "0 label:  1\n",
      "node range:  [676, 673, 674, 675, 677, 678, 679, 680, 681, 108, 53, 217, 218]\n",
      "target node:  676\n",
      "epoch time:  0.1081547737121582\n",
      "[0.3575967848300934, 0.3528937101364136, 0.34382888674736023, 0.338000625371933, 0.354500949382782, 0.3360597491264343, 0.3578200340270996, 0.34713849425315857, 0.33893582224845886, 0.33642852306365967, 0.3320516049861908, 0.3320516049861908, 0.3320516049861908]\n",
      "[ 6  0  4  1  7  2  8  3  9  5 12 11 10]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8985976267529666\n",
      "mean auc:  0.9310560147331993\n",
      "\n",
      "index:  677\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  678\n",
      "0 label:  1\n",
      "node range:  [678, 673, 674, 675, 676, 677, 679, 680, 681]\n",
      "target node:  678\n",
      "epoch time:  0.10066580772399902\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554757833480835, 0.33900347352027893, 0.34700849652290344, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  679\n",
      "0 label:  1\n",
      "node range:  [679, 673, 674, 676, 677, 678, 680, 681, 108]\n",
      "target node:  679\n",
      "epoch time:  0.08372974395751953\n",
      "[0.3689841628074646, 0.3466884195804596, 0.34467679262161255, 0.3655906319618225, 0.3541537821292877, 0.34565725922584534, 0.3667139410972595, 0.34958958625793457, 0.33907854557037354]\n",
      "[0 6 3 4 7 1 5 2 8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8985042735042736\n",
      "mean auc:  0.9317189376684568\n",
      "\n",
      "index:  680\n",
      "0 label:  1\n",
      "node range:  [680, 673, 674, 675, 676, 677, 678, 679, 681]\n",
      "target node:  680\n",
      "epoch time:  0.10034060478210449\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900341391563416, 0.34689080715179443, 0.3554757833480835, 0.34700849652290344, 0.35820528864860535, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  681\n",
      "0 label:  1\n",
      "node range:  [681, 674, 675, 676, 677, 678, 679, 680]\n",
      "target node:  681\n",
      "epoch time:  0.08205270767211914\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963, 0.3650220036506653]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  682\n",
      "0 label:  1\n",
      "node range:  [682, 229, 230, 459, 684, 460, 686, 461, 688, 113, 114, 462, 683, 685, 687, 689, 56, 27]\n",
      "target node:  682\n",
      "epoch time:  0.14368844032287598\n",
      "[0.354214072227478, 0.33612003922462463, 0.33612003922462463, 0.3325546383857727, 0.33978548645973206, 0.3331364691257477, 0.3430735766887665, 0.3331364691257477, 0.33978548645973206, 0.33210551738739014, 0.3482510447502136, 0.3325546383857727, 0.3526723086833954, 0.3526723086833954, 0.337541788816452, 0.337541788816452, 0.3360172510147095, 0.33210551738739014]\n",
      "[ 0 13 12 10  6  4  8 14 15  2  1 16  7  5 11  3  9 17]\n",
      "truth node:  [0, 4, 6, 8, 12, 13, 14, 15]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9374999999999999\n",
      "mean acc:  0.8984126984126986\n",
      "mean auc:  0.9317739954049478\n",
      "\n",
      "index:  683\n",
      "0 label:  1\n",
      "node range:  [683, 229, 230, 682, 684, 685, 686, 687, 688, 689, 114, 690, 56]\n",
      "target node:  683\n",
      "epoch time:  0.12359356880187988\n",
      "[0.3575967848300934, 0.3320516049861908, 0.3320516049861908, 0.3528936803340912, 0.357820063829422, 0.34382885694503784, 0.3545009195804596, 0.34713855385780334, 0.338000625371933, 0.3360597491264343, 0.33642852306365967, 0.33893582224845886, 0.3320516049861908]\n",
      "[ 4  0  6  3  7  5 11  8 10  9 12  2  1]\n",
      "truth node:  [0, 3, 4, 5, 6, 7, 8, 9, 11]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8983228511530399\n",
      "mean auc:  0.9321555824503938\n",
      "\n",
      "index:  684\n",
      "0 label:  1\n",
      "node range:  [684, 682, 683, 685, 686, 687, 689, 690, 114]\n",
      "target node:  684\n",
      "epoch time:  0.08631706237792969\n",
      "[0.368984192609787, 0.3466885983943939, 0.3655906915664673, 0.34467679262161255, 0.3541537821292877, 0.36671391129493713, 0.3456572890281677, 0.34958958625793457, 0.3390786647796631]\n",
      "[0 5 2 4 7 1 6 3 8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8982346832814123\n",
      "mean auc:  0.9327896424274928\n",
      "\n",
      "index:  685\n",
      "0 label:  1\n",
      "node range:  [685, 229, 230, 682, 683, 684, 686, 687, 688, 689, 114, 690, 56]\n",
      "target node:  685\n",
      "epoch time:  0.11426830291748047\n",
      "[0.3575967848300934, 0.3320516049861908, 0.3320516049861908, 0.3528937101364136, 0.34382888674736023, 0.338000625371933, 0.354500949382782, 0.3360597491264343, 0.3578200340270996, 0.34713849425315857, 0.33642852306365967, 0.33893588185310364, 0.3320516049861908]\n",
      "[ 8  0  6  3  9  4 11  5 10  7 12  2  1]\n",
      "truth node:  [0, 3, 4, 5, 6, 7, 8, 9, 11]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8981481481481481\n",
      "mean auc:  0.9331547589070738\n",
      "\n",
      "index:  686\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  687\n",
      "0 label:  1\n",
      "node range:  [687, 682, 683, 684, 685, 686, 688, 689, 690]\n",
      "target node:  687\n",
      "epoch time:  0.07337117195129395\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820525884628296, 0.33623364567756653, 0.3554757833480835, 0.33900341391563416, 0.34700843691825867, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  688\n",
      "0 label:  1\n",
      "node range:  [688, 682, 683, 685, 686, 687, 689, 690, 114]\n",
      "target node:  688\n",
      "epoch time:  0.09937834739685059\n",
      "[0.3689841628074646, 0.3466884195804596, 0.344676673412323, 0.3655906915664673, 0.3541537821292877, 0.3456572890281677, 0.36671391129493713, 0.34958958625793457, 0.33907854557037354]\n",
      "[0 6 3 4 7 1 5 2 8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8980632008154944\n",
      "mean auc:  0.9337680179996695\n",
      "\n",
      "index:  689\n",
      "0 label:  1\n",
      "node range:  [689, 682, 683, 684, 685, 686, 687, 688, 690]\n",
      "target node:  689\n",
      "epoch time:  0.08147621154785156\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900347352027893, 0.34689080715179443, 0.3554758131504059, 0.34700843691825867, 0.35820528864860535, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  690\n",
      "0 label:  1\n",
      "node range:  [690, 683, 684, 685, 686, 687, 688, 689]\n",
      "target node:  690\n",
      "epoch time:  0.10164952278137207\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963, 0.3650220036506653]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  691\n",
      "0 label:  1\n",
      "node range:  [691, 483, 484, 485, 486, 696, 241, 242, 119, 693, 692, 695, 120, 697, 694, 59, 29, 698]\n",
      "target node:  691\n",
      "epoch time:  0.17253494262695312\n",
      "[0.35386621952056885, 0.3334121108055115, 0.3334121108055115, 0.3334121108055115, 0.3334121108055115, 0.3376184105873108, 0.3363064229488373, 0.3363064229488373, 0.3323472738265991, 0.33980095386505127, 0.35235220193862915, 0.3429991900920868, 0.3481826186180115, 0.3398009240627289, 0.35235220193862915, 0.33616793155670166, 0.3323472738265991, 0.3376184105873108]\n",
      "[ 0 14 10 12 11  9 13  5 17  7  6 15  4  3  2  1 16  8]\n",
      "truth node:  [0, 5, 9, 10, 11, 13, 14, 17]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9374999999999999\n",
      "mean acc:  0.8979797979797979\n",
      "mean auc:  0.9338019451087634\n",
      "\n",
      "index:  692\n",
      "0 label:  1\n",
      "node range:  [692, 241, 242, 691, 693, 694, 695, 696, 697, 698, 59, 120, 699]\n",
      "target node:  692\n",
      "epoch time:  0.12321877479553223\n",
      "[0.3575967848300934, 0.3320516049861908, 0.3320516049861908, 0.3528936803340912, 0.3578200340270996, 0.34382888674736023, 0.354500949382782, 0.34713849425315857, 0.338000625371933, 0.3360597491264343, 0.3320516049861908, 0.33642852306365967, 0.33893585205078125]\n",
      "[ 4  0  6  3  7  5 12  8 11  9 10  2  1]\n",
      "truth node:  [0, 3, 4, 5, 6, 7, 8, 9, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8978978978978979\n",
      "mean auc:  0.9341480737314072\n",
      "\n",
      "index:  693\n",
      "0 label:  1\n",
      "node range:  [693, 696, 691, 692, 694, 695, 120, 698, 699]\n",
      "target node:  693\n",
      "epoch time:  0.08348441123962402\n",
      "[0.368984192609787, 0.36671391129493713, 0.346688449382782, 0.3655906915664673, 0.3446766436100006, 0.35415375232696533, 0.3390783965587616, 0.34565725922584534, 0.34958964586257935]\n",
      "[0 1 3 5 8 2 7 4 6]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8978174603174605\n",
      "mean auc:  0.9347360373588052\n",
      "\n",
      "index:  694\n",
      "0 label:  1\n",
      "node range:  [694, 241, 242, 691, 692, 693, 695, 696, 697, 698, 59, 120, 699]\n",
      "target node:  694\n",
      "epoch time:  0.13719892501831055\n",
      "[0.35759681463241577, 0.3320516049861908, 0.3320516049861908, 0.3528936803340912, 0.34382888674736023, 0.338000625371933, 0.3545009195804596, 0.3360597491264343, 0.357820063829422, 0.34713849425315857, 0.3320516049861908, 0.33642852306365967, 0.33893585205078125]\n",
      "[ 8  0  6  3  9  4 12  5 11  7 10  2  1]\n",
      "truth node:  [0, 3, 4, 5, 6, 7, 8, 9, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8977384464110129\n",
      "mean auc:  0.935067773508039\n",
      "\n",
      "index:  695\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  696\n",
      "0 label:  1\n",
      "node range:  [696, 691, 692, 693, 694, 695, 697, 698, 699]\n",
      "target node:  696\n",
      "epoch time:  0.08128714561462402\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554757833480835, 0.33900347352027893, 0.34700849652290344, 0.3583422899246216]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  697\n",
      "0 label:  1\n",
      "node range:  [697, 696, 691, 692, 694, 695, 120, 698, 699]\n",
      "target node:  697\n",
      "epoch time:  0.10400748252868652\n",
      "[0.3689841330051422, 0.3456572890281677, 0.3466886878013611, 0.34467679262161255, 0.3655906915664673, 0.35415375232696533, 0.33907872438430786, 0.36671391129493713, 0.34958967566490173]\n",
      "[0 7 4 5 8 2 1 3 6]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8976608187134504\n",
      "mean auc:  0.935637354442179\n",
      "\n",
      "index:  698\n",
      "0 label:  1\n",
      "node range:  [698, 691, 692, 693, 694, 695, 696, 697, 699]\n",
      "target node:  698\n",
      "epoch time:  0.08216619491577148\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900341391563416, 0.34689080715179443, 0.3554757833480835, 0.34700849652290344, 0.35820528864860535, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  699\n",
      "0 label:  1\n",
      "node range:  [699, 692, 693, 694, 695, 696, 697, 698]\n",
      "target node:  699\n",
      "epoch time:  0.1044917106628418\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963, 0.3650220036506653]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  700\n",
      "0 label:  1\n",
      "node range:  [700, 704, 509, 706, 705, 707, 510, 701, 702, 508, 30, 125, 254, 126, 507, 253, 62, 703]\n",
      "target node:  700\n",
      "epoch time:  0.1689164638519287\n",
      "[0.3539365530014038, 0.34301459789276123, 0.333368182182312, 0.3397982716560364, 0.33760344982147217, 0.33760344982147217, 0.333368182182312, 0.3524170219898224, 0.3397982716560364, 0.333368182182312, 0.3320571780204773, 0.33227723836898804, 0.33627718687057495, 0.3481909930706024, 0.333368182182312, 0.33627718687057495, 0.33611607551574707, 0.3524169921875]\n",
      "[ 0  7 17 13  1  3  8  5  4 12 15 16 14  9  6  2 11 10]\n",
      "truth node:  [0, 1, 3, 4, 5, 7, 8, 17]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9374999999999999\n",
      "mean acc:  0.8975845410628019\n",
      "mean auc:  0.9356535513600731\n",
      "\n",
      "index:  701\n",
      "0 label:  1\n",
      "node range:  [701, 704, 705, 706, 707, 708, 702, 254, 62, 253, 700, 126, 703]\n",
      "target node:  701\n",
      "epoch time:  0.12665009498596191\n",
      "[0.3575967848300934, 0.354500949382782, 0.34713849425315857, 0.338000625371933, 0.3360597491264343, 0.33893582224845886, 0.357820063829422, 0.3320516049861908, 0.3320516049861908, 0.3320516049861908, 0.3528936803340912, 0.33642852306365967, 0.34382888674736023]\n",
      "[ 6  0  1 10  2 12  5  3 11  4  9  8  7]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 10, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8975095785440613\n",
      "mean auc:  0.9359687985226779\n",
      "\n",
      "index:  702\n",
      "0 label:  1\n",
      "node range:  [702, 704, 705, 707, 708, 700, 701, 126, 703]\n",
      "target node:  702\n",
      "epoch time:  0.08619046211242676\n",
      "[0.3689842224121094, 0.35415375232696533, 0.36671391129493713, 0.34565725922584534, 0.3495895564556122, 0.346688449382782, 0.3655906617641449, 0.33907845616340637, 0.3446767032146454]\n",
      "[0 2 6 1 4 5 3 8 7]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8974358974358975\n",
      "mean auc:  0.9365160737489798\n",
      "\n",
      "index:  703\n",
      "0 label:  1\n",
      "node range:  [703, 704, 705, 706, 707, 708, 702, 254, 62, 253, 700, 701, 126]\n",
      "target node:  703\n",
      "epoch time:  0.131561279296875\n",
      "[0.3575967848300934, 0.354500949382782, 0.3360597491264343, 0.357820063829422, 0.34713849425315857, 0.33893582224845886, 0.3380005955696106, 0.3320516049861908, 0.3320516049861908, 0.3320516049861908, 0.3528936803340912, 0.34382888674736023, 0.33642852306365967]\n",
      "[ 3  0  1 10  4 11  5  6 12  2  9  8  7]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 10, 11]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8973634651600753\n",
      "mean auc:  0.9368186682275667\n",
      "\n",
      "index:  704\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  705\n",
      "0 label:  1\n",
      "node range:  [705, 704, 706, 707, 708, 700, 701, 702, 703]\n",
      "target node:  705\n",
      "epoch time:  0.09324216842651367\n",
      "[0.3604322075843811, 0.3554757833480835, 0.33900347352027893, 0.34700843691825867, 0.3583422303199768, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653]\n",
      "[0 4 7 1 3 6 2 5 8]\n",
      "foo\n",
      "\n",
      "index:  706\n",
      "0 label:  1\n",
      "node range:  [706, 704, 705, 707, 708, 700, 701, 126, 703]\n",
      "target node:  706\n",
      "epoch time:  0.083465576171875\n",
      "[0.3689841628074646, 0.3541537821292877, 0.3456572890281677, 0.3667139410972595, 0.34958958625793457, 0.3466884195804596, 0.34467676281929016, 0.33907854557037354, 0.3655906319618225]\n",
      "[0 3 8 1 4 5 2 6 7]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8972922502334266\n",
      "mean auc:  0.9373496037886796\n",
      "\n",
      "index:  707\n",
      "0 label:  1\n",
      "node range:  [707, 704, 705, 706, 708, 700, 701, 702, 703]\n",
      "target node:  707\n",
      "epoch time:  0.08099532127380371\n",
      "[0.3604322075843811, 0.3554757833480835, 0.34700849652290344, 0.35820528864860535, 0.3583422303199768, 0.3377439081668854, 0.33623364567756653, 0.33900347352027893, 0.34689080715179443]\n",
      "[0 4 3 1 2 8 7 5 6]\n",
      "foo\n",
      "\n",
      "index:  708\n",
      "0 label:  1\n",
      "node range:  [708, 704, 705, 706, 707, 701, 702, 703]\n",
      "target node:  708\n",
      "epoch time:  0.0742189884185791\n",
      "[0.36824873089790344, 0.34873244166374207, 0.36502206325531006, 0.3425886631011963, 0.36502206325531006, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963]\n",
      "[0 4 2 1 6 3 7 5]\n",
      "foo\n",
      "\n",
      "index:  709\n",
      "0 label:  1\n",
      "node range:  [709, 32, 65, 131, 132, 710, 711, 712, 713, 265, 715, 266, 714, 716]\n",
      "target node:  709\n",
      "epoch time:  0.13953948020935059\n",
      "[0.3542739748954773, 0.33388760685920715, 0.3376534879207611, 0.33388760685920715, 0.3516838550567627, 0.35262051224708557, 0.34088727831840515, 0.35262054204940796, 0.3438946604728699, 0.34242191910743713, 0.34088727831840515, 0.34242191910743713, 0.33880576491355896, 0.33880579471588135]\n",
      "[ 0  7  5  4  8 11  9 10  6 13 12  2  3  1]\n",
      "truth node:  [0, 5, 6, 7, 8, 10, 12, 13]\n",
      "acc:  0.6666666666666666\n",
      "auc:  0.7291666666666667\n",
      "mean acc:  0.8953703703703706\n",
      "mean auc:  0.9356147459793293\n",
      "\n",
      "index:  710\n",
      "0 label:  1\n",
      "node range:  [710, 65, 132, 709, 711, 712, 265, 714, 266, 716, 713, 715, 717]\n",
      "target node:  710\n",
      "epoch time:  0.1046905517578125\n",
      "[0.35692042112350464, 0.3325350284576416, 0.3367471694946289, 0.3526022136211395, 0.35709646344184875, 0.3437579572200775, 0.3334386944770813, 0.34683677554130554, 0.3334386944770813, 0.3362421989440918, 0.35395681858062744, 0.3381475806236267, 0.33899274468421936]\n",
      "[ 4  0 10  3  7  5 12 11  2  9  8  6  1]\n",
      "truth node:  [0, 3, 4, 5, 7, 9, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8953168044077137\n",
      "mean auc:  0.9359172871053036\n",
      "\n",
      "index:  711\n",
      "0 label:  1\n",
      "node range:  [711, 132, 709, 710, 712, 713, 714, 716, 717]\n",
      "target node:  711\n",
      "epoch time:  0.08321976661682129\n",
      "[0.368984192609787, 0.33907854557037354, 0.346688449382782, 0.3655906319618225, 0.3446766436100006, 0.35415375232696533, 0.3667139410972595, 0.3456572890281677, 0.3495895564556122]\n",
      "[0 6 3 5 8 2 7 4 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8952641165755921\n",
      "mean auc:  0.9364425552437847\n",
      "\n",
      "index:  712\n",
      "0 label:  1\n",
      "node range:  [712, 65, 132, 709, 710, 711, 265, 714, 266, 716, 713, 715, 717]\n",
      "target node:  712\n",
      "epoch time:  0.11041092872619629\n",
      "[0.35692042112350464, 0.3325350284576416, 0.3367471694946289, 0.3526022136211395, 0.3437579572200775, 0.3381475806236267, 0.3334386944770813, 0.3362421989440918, 0.3334386944770813, 0.34683677554130554, 0.35395681858062744, 0.35709646344184875, 0.33899274468421936]\n",
      "[11  0 10  3  9  4 12  5  2  7  8  6  1]\n",
      "truth node:  [0, 3, 4, 5, 7, 9, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.895212285456188\n",
      "mean auc:  0.9367334468452355\n",
      "\n",
      "index:  713\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  714\n",
      "0 label:  1\n",
      "node range:  [714, 709, 710, 711, 712, 713, 715, 716, 717]\n",
      "target node:  714\n",
      "epoch time:  0.10213041305541992\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554757833480835, 0.33900341391563416, 0.34700843691825867, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  715\n",
      "0 label:  1\n",
      "node range:  [715, 132, 709, 710, 712, 713, 714, 716, 717]\n",
      "target node:  715\n",
      "epoch time:  0.09496259689331055\n",
      "[0.3689841628074646, 0.339078426361084, 0.34668850898742676, 0.34467676281929016, 0.3655906319618225, 0.3541537821292877, 0.3456572890281677, 0.36671391129493713, 0.34958958625793457]\n",
      "[0 7 4 5 8 2 6 3 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8951612903225807\n",
      "mean auc:  0.9372436609835804\n",
      "\n",
      "index:  716\n",
      "0 label:  1\n",
      "node range:  [716, 709, 710, 711, 712, 713, 714, 715, 717]\n",
      "target node:  716\n",
      "epoch time:  0.07438921928405762\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900347352027893, 0.34689080715179443, 0.3554757833480835, 0.34700843691825867, 0.35820528864860535, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  717\n",
      "0 label:  1\n",
      "node range:  [717, 710, 711, 712, 713, 714, 715, 716]\n",
      "target node:  717\n",
      "epoch time:  0.0718083381652832\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963, 0.3650220036506653]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  718\n",
      "0 label:  1\n",
      "node range:  [718, 33, 68, 137, 138, 719, 720, 432, 722, 721, 724, 277, 278, 723, 725]\n",
      "target node:  718\n",
      "epoch time:  0.1568155288696289\n",
      "[0.3543066084384918, 0.332186758518219, 0.33620885014533997, 0.332186758518219, 0.3503047823905945, 0.3525986969470978, 0.339827299118042, 0.33277860283851624, 0.3430999517440796, 0.3525986969470978, 0.339827299118042, 0.3413316309452057, 0.33784720301628113, 0.3375733196735382, 0.3375733196735382]\n",
      "[ 0  9  5  4  8 11 10  6 12 14 13  2  7  3  1]\n",
      "truth node:  [0, 5, 6, 8, 9, 10, 13, 14]\n",
      "acc:  0.6666666666666666\n",
      "auc:  0.8035714285714286\n",
      "mean acc:  0.8933333333333335\n",
      "mean auc:  0.9361742831242832\n",
      "\n",
      "index:  719\n",
      "0 label:  1\n",
      "node range:  [719, 68, 138, 718, 720, 721, 722, 723, 724, 725, 277, 278, 726]\n",
      "target node:  719\n",
      "epoch time:  0.12094235420227051\n",
      "[0.35713353753089905, 0.3323921263217926, 0.33665531873703003, 0.35270094871520996, 0.35732370615005493, 0.3437836766242981, 0.3541288673877716, 0.3469328284263611, 0.33810535073280334, 0.33618834614753723, 0.33329224586486816, 0.33272820711135864, 0.3389778137207031]\n",
      "[ 4  0  6  3  7  5 12  8  2  9 10 11  1]\n",
      "truth node:  [0, 3, 4, 5, 6, 7, 8, 9, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8932980599647268\n",
      "mean auc:  0.9364603778790288\n",
      "\n",
      "index:  720\n",
      "0 label:  1\n",
      "node range:  [720, 138, 718, 719, 721, 722, 723, 725, 726]\n",
      "target node:  720\n",
      "epoch time:  0.08268165588378906\n",
      "[0.3689841628074646, 0.33907854557037354, 0.34668853878974915, 0.3655906319618225, 0.34467676281929016, 0.3541537821292877, 0.36671391129493713, 0.34565725922584534, 0.34958964586257935]\n",
      "[0 6 3 5 8 2 7 4 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8932633420822398\n",
      "mean auc:  0.9369606898642333\n",
      "\n",
      "index:  721\n",
      "0 label:  1\n",
      "node range:  [721, 68, 138, 718, 719, 720, 722, 723, 724, 725, 277, 278, 726]\n",
      "target node:  721\n",
      "epoch time:  0.1364138126373291\n",
      "[0.35713353753089905, 0.3323921263217926, 0.33665531873703003, 0.35270094871520996, 0.3437836468219757, 0.33810535073280334, 0.3541288673877716, 0.33618834614753723, 0.35732370615005493, 0.3469328284263611, 0.33329224586486816, 0.33272820711135864, 0.3389778137207031]\n",
      "[ 8  0  6  3  9  4 12  5  2  7 10 11  1]\n",
      "truth node:  [0, 3, 4, 5, 6, 7, 8, 9, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.893229166666667\n",
      "mean auc:  0.9372361705857799\n",
      "\n",
      "index:  722\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  723\n",
      "0 label:  1\n",
      "node range:  [723, 718, 719, 720, 721, 722, 724, 725, 726]\n",
      "target node:  723\n",
      "epoch time:  0.07964754104614258\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554757833480835, 0.33900347352027893, 0.34700849652290344, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  724\n",
      "0 label:  1\n",
      "node range:  [724, 138, 718, 719, 721, 722, 723, 725, 726]\n",
      "target node:  724\n",
      "epoch time:  0.08815741539001465\n",
      "[0.368984192609787, 0.33907854557037354, 0.34668853878974915, 0.34467676281929016, 0.3655906617641449, 0.3541537821292877, 0.34565725922584534, 0.3667139410972595, 0.34958967566490173]\n",
      "[0 7 4 5 8 2 6 3 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8931955211024979\n",
      "mean auc:  0.9377227118990685\n",
      "\n",
      "index:  725\n",
      "0 label:  1\n",
      "node range:  [725, 718, 719, 720, 721, 722, 723, 724, 726]\n",
      "target node:  725\n",
      "epoch time:  0.08989524841308594\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900347352027893, 0.34689080715179443, 0.3554757833480835, 0.34700849652290344, 0.35820528864860535, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  726\n",
      "0 label:  1\n",
      "node range:  [726, 719, 720, 721, 722, 723, 724, 725]\n",
      "target node:  726\n",
      "epoch time:  0.09604954719543457\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963, 0.3650220036506653]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  727\n",
      "0 label:  1\n",
      "node range:  [727, 289, 290, 35, 71, 143, 144, 728, 729, 730, 731, 732, 733, 734]\n",
      "target node:  727\n",
      "epoch time:  0.11553478240966797\n",
      "[0.3542739748954773, 0.34242191910743713, 0.34242191910743713, 0.33388757705688477, 0.3376534581184387, 0.33388757705688477, 0.3516838848590851, 0.35262051224708557, 0.3408872187137604, 0.35262054204940796, 0.3438946306705475, 0.33880579471588135, 0.340887188911438, 0.33880579471588135]\n",
      "[ 0  9  7  6 10  2  1  8 12 13 11  4  5  3]\n",
      "truth node:  [0, 7, 8, 9, 10, 11, 12, 13]\n",
      "acc:  0.6666666666666666\n",
      "auc:  0.7291666666666667\n",
      "mean acc:  0.8914529914529914\n",
      "mean auc:  0.9361184346280501\n",
      "\n",
      "index:  728\n",
      "0 label:  1\n",
      "node range:  [728, 289, 290, 71, 144, 727, 729, 730, 731, 732, 733, 734, 735]\n",
      "target node:  728\n",
      "epoch time:  0.13509273529052734\n",
      "[0.35692042112350464, 0.3334386944770813, 0.3334386944770813, 0.3325350284576416, 0.3367471694946289, 0.3526022434234619, 0.35709646344184875, 0.3437579572200775, 0.35395681858062744, 0.34683677554130554, 0.3381475806236267, 0.3362421989440918, 0.33899274468421936]\n",
      "[ 6  0  8  5  9  7 12 10  4 11  2  1  3]\n",
      "truth node:  [0, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8914334181509753\n",
      "mean auc:  0.9363940360600667\n",
      "\n",
      "index:  729\n",
      "0 label:  1\n",
      "node range:  [729, 144, 727, 728, 730, 731, 732, 734, 735]\n",
      "target node:  729\n",
      "epoch time:  0.09273481369018555\n",
      "[0.3689841628074646, 0.3390783965587616, 0.346688449382782, 0.3655906617641449, 0.34467676281929016, 0.3541537821292877, 0.36671391129493713, 0.34565725922584534, 0.34958958625793457]\n",
      "[0 6 3 5 8 2 7 4 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8914141414141413\n",
      "mean auc:  0.9368758994232479\n",
      "\n",
      "index:  730\n",
      "0 label:  1\n",
      "node range:  [730, 289, 290, 71, 144, 727, 728, 729, 731, 732, 733, 734, 735]\n",
      "target node:  730\n",
      "epoch time:  0.13744258880615234\n",
      "[0.35692042112350464, 0.3334386944770813, 0.3334386944770813, 0.3325350284576416, 0.3367471694946289, 0.3526022434234619, 0.3437579572200775, 0.3381475806236267, 0.35395681858062744, 0.3362421989440918, 0.35709646344184875, 0.34683677554130554, 0.33899274468421936]\n",
      "[10  0  8  5 11  6 12  7  4  9  2  1  3]\n",
      "truth node:  [0, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8913951545530492\n",
      "mean auc:  0.937141661248804\n",
      "\n",
      "index:  731\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  732\n",
      "0 label:  1\n",
      "node range:  [732, 727, 728, 729, 730, 731, 733, 734, 735]\n",
      "target node:  732\n",
      "epoch time:  0.08289694786071777\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554757833480835, 0.33900347352027893, 0.34700843691825867, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  733\n",
      "0 label:  1\n",
      "node range:  [733, 144, 727, 728, 730, 731, 732, 734, 735]\n",
      "target node:  733\n",
      "epoch time:  0.08842611312866211\n",
      "[0.3689841628074646, 0.33907845616340637, 0.3466884195804596, 0.3446768820285797, 0.3655907213687897, 0.3541537821292877, 0.34565725922584534, 0.3667139410972595, 0.34958961606025696]\n",
      "[0 7 4 5 8 2 6 3 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8913764510779435\n",
      "mean auc:  0.937610753329037\n",
      "\n",
      "index:  734\n",
      "0 label:  1\n",
      "node range:  [734, 727, 728, 729, 730, 731, 732, 733, 735]\n",
      "target node:  734\n",
      "epoch time:  0.0844266414642334\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900341391563416, 0.34689080715179443, 0.3554758131504059, 0.34700843691825867, 0.35820528864860535, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  735\n",
      "0 label:  1\n",
      "node range:  [735, 728, 729, 730, 731, 732, 733, 734]\n",
      "target node:  735\n",
      "epoch time:  0.08843779563903809\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963, 0.36502206325531006]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  736\n",
      "0 label:  1\n",
      "node range:  [736, 737, 738, 739, 740, 36, 742, 741, 743, 74, 301, 302, 149, 150]\n",
      "target node:  736\n",
      "epoch time:  0.11934947967529297\n",
      "[0.3539577126502991, 0.35221996903419495, 0.3398563861846924, 0.35221999883651733, 0.34302595257759094, 0.33224010467529297, 0.3398563861846924, 0.3376641273498535, 0.3376641273498535, 0.33641624450683594, 0.34144827723503113, 0.34144827723503113, 0.33245494961738586, 0.3511790633201599]\n",
      "[ 0  3  1 13  4 11 10  6  2  8  7  9 12  5]\n",
      "truth node:  [0, 1, 2, 3, 4, 6, 7, 8]\n",
      "acc:  0.6666666666666666\n",
      "auc:  0.7291666666666667\n",
      "mean acc:  0.8897119341563785\n",
      "mean auc:  0.9360667230574639\n",
      "\n",
      "index:  737\n",
      "0 label:  1\n",
      "node range:  [737, 736, 738, 739, 740, 741, 742, 743, 744, 74, 301, 302, 150]\n",
      "target node:  737\n",
      "epoch time:  0.11644721031188965\n",
      "[0.35692042112350464, 0.3526022434234619, 0.35709646344184875, 0.3437579572200775, 0.35395681858062744, 0.34683674573898315, 0.3381475806236267, 0.3362421989440918, 0.33899274468421936, 0.3325350284576416, 0.3334386944770813, 0.3334386944770813, 0.3367471694946289]\n",
      "[ 2  0  4  1  5  3  8  6 12  7 11 10  9]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8897058823529411\n",
      "mean auc:  0.9363325723160282\n",
      "\n",
      "index:  738\n",
      "0 label:  1\n",
      "node range:  [738, 736, 737, 739, 740, 741, 743, 744, 150]\n",
      "target node:  738\n",
      "epoch time:  0.08738899230957031\n",
      "[0.3689841628074646, 0.34668850898742676, 0.3655906319618225, 0.3446766436100006, 0.35415375232696533, 0.36671391129493713, 0.34565725922584534, 0.3495895564556122, 0.33907845616340637]\n",
      "[0 5 2 4 7 1 6 3 8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8896999188969993\n",
      "mean auc:  0.9367972980655462\n",
      "\n",
      "index:  739\n",
      "0 label:  1\n",
      "node range:  [739, 736, 737, 738, 740, 741, 742, 743, 744, 74, 301, 302, 150]\n",
      "target node:  739\n",
      "epoch time:  0.12700819969177246\n",
      "[0.35692042112350464, 0.3526022136211395, 0.3437579572200775, 0.3381475806236267, 0.35395681858062744, 0.3362421989440918, 0.35709646344184875, 0.34683677554130554, 0.33899274468421936, 0.3325350284576416, 0.3334386944770813, 0.3334386944770813, 0.3367471694946289]\n",
      "[ 6  0  4  1  7  2  8  3 12  5 11 10  9]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.889694041867955\n",
      "mean auc:  0.9370540004145077\n",
      "\n",
      "index:  740\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  741\n",
      "0 label:  1\n",
      "node range:  [741, 736, 737, 738, 739, 740, 742, 743, 744]\n",
      "target node:  741\n",
      "epoch time:  0.0959935188293457\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554757833480835, 0.33900347352027893, 0.34700849652290344, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  742\n",
      "0 label:  1\n",
      "node range:  [742, 736, 737, 739, 740, 741, 743, 744, 150]\n",
      "target node:  742\n",
      "epoch time:  0.0825047492980957\n",
      "[0.3689841628074646, 0.346688449382782, 0.3446767032146454, 0.3655907213687897, 0.3541537821292877, 0.34565725922584534, 0.36671388149261475, 0.3495897054672241, 0.3390783369541168]\n",
      "[0 6 3 4 7 1 5 2 8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8896882494004796\n",
      "mean auc:  0.9375068493323889\n",
      "\n",
      "index:  743\n",
      "0 label:  1\n",
      "node range:  [743, 736, 737, 738, 739, 740, 741, 742, 744]\n",
      "target node:  743\n",
      "epoch time:  0.09031891822814941\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900347352027893, 0.34689080715179443, 0.3554757833480835, 0.34700849652290344, 0.35820528864860535, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  744\n",
      "0 label:  1\n",
      "node range:  [744, 737, 738, 739, 740, 741, 742, 743]\n",
      "target node:  744\n",
      "epoch time:  0.06729793548583984\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.36502206325531006, 0.3425886631011963, 0.36502206325531006]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  745\n",
      "0 label:  1\n",
      "node range:  [745, 38, 746, 747, 748, 77, 749, 751, 750, 752, 313, 314, 155, 156]\n",
      "target node:  745\n",
      "epoch time:  0.12333250045776367\n",
      "[0.35413286089897156, 0.332364022731781, 0.3523269295692444, 0.33983781933784485, 0.35225731134414673, 0.33638739585876465, 0.3430093824863434, 0.3397582173347473, 0.3375731408596039, 0.3367474377155304, 0.34147992730140686, 0.34147992730140686, 0.332364022731781, 0.3513668477535248]\n",
      "[ 0  2  4 13  6 11 10  3  7  8  9  5 12  1]\n",
      "truth node:  [0, 2, 3, 4, 6, 7, 8, 9]\n",
      "acc:  0.6666666666666666\n",
      "auc:  0.7291666666666667\n",
      "mean acc:  0.8880952380952382\n",
      "mean auc:  0.9360187051704908\n",
      "\n",
      "index:  746\n",
      "0 label:  1\n",
      "node range:  [746, 745, 747, 748, 77, 750, 749, 752, 751, 753, 313, 314, 156, 414]\n",
      "target node:  746\n",
      "epoch time:  0.10362529754638672\n",
      "[0.35704702138900757, 0.35271817445755005, 0.3572591543197632, 0.3437495231628418, 0.3324510455131531, 0.3468622863292694, 0.3537052869796753, 0.33518970012664795, 0.33766981959342957, 0.3385246992111206, 0.3333645761013031, 0.3333645462989807, 0.33670440316200256, 0.33199819922447205]\n",
      "[ 2  0  6  1  5  3  9  8 12  7 10 11  4 13]\n",
      "truth node:  [0, 1, 2, 3, 5, 6, 7, 8, 9]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9777777777777779\n",
      "mean acc:  0.8881008668242711\n",
      "mean auc:  0.9363148688060036\n",
      "\n",
      "index:  747\n",
      "0 label:  1\n",
      "node range:  [747, 745, 746, 748, 749, 750, 752, 753, 156]\n",
      "target node:  747\n",
      "epoch time:  0.0944986343383789\n",
      "[0.3385280668735504, 0.3400314450263977, 0.3387172222137451, 0.3401409089565277, 0.33952996134757996, 0.3386304974555969, 0.3401365876197815, 0.33982083201408386, 0.3405416011810303]\n",
      "[8 3 6 1 7 4 2 5 0]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.0\n",
      "mean acc:  0.8881064162754304\n",
      "mean auc:  0.9297211021242712\n",
      "\n",
      "index:  748\n",
      "0 label:  1\n",
      "node range:  [748, 745, 746, 747, 77, 750, 749, 752, 751, 753, 313, 314, 156, 414]\n",
      "target node:  748\n",
      "epoch time:  0.13276982307434082\n",
      "[0.3572259545326233, 0.3529609143733978, 0.34380894899368286, 0.33805689215660095, 0.33226585388183594, 0.3360486924648285, 0.35341599583625793, 0.3441483974456787, 0.3562452793121338, 0.33776482939720154, 0.33320048451423645, 0.33320045471191406, 0.33660924434661865, 0.33453449606895447]\n",
      "[ 0  8  6  1  7  2  3  9 12  5 13 10 11  4]\n",
      "truth node:  [0, 1, 2, 3, 5, 6, 7, 8, 9]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9777777777777779\n",
      "mean acc:  0.8881118881118881\n",
      "mean auc:  0.9300571627931769\n",
      "\n",
      "index:  749\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  750\n",
      "0 label:  1\n",
      "node range:  [750, 745, 746, 747, 748, 749, 751, 752, 753, 414]\n",
      "target node:  750\n",
      "epoch time:  0.09023213386535645\n",
      "[0.36086151003837585, 0.3376438319683075, 0.347051739692688, 0.35875391960144043, 0.3360403776168823, 0.35498160123825073, 0.3377639949321747, 0.34429261088371277, 0.35752344131469727, 0.3345410227775574]\n",
      "[0 3 8 5 2 7 6 1 4 9]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.8888888888888888\n",
      "mean auc:  0.9305428769404465\n",
      "\n",
      "index:  751\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  752\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  753\n",
      "0 label:  1\n",
      "node range:  [753, 746, 747, 748, 749, 750, 751, 752, 206, 1132, 414]\n",
      "target node:  753\n",
      "epoch time:  0.10574650764465332\n",
      "[0.35739508271217346, 0.3498341143131256, 0.35141444206237793, 0.3495658338069916, 0.3523753583431244, 0.3572012186050415, 0.35035037994384766, 0.3561290502548218, 0.34750109910964966, 0.34750109910964966, 0.34955620765686035]\n",
      "[ 0  5  7  4  2  6  1  3 10  9  8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8888888888888891\n",
      "mean auc:  0.9310218915822365\n",
      "\n",
      "index:  754\n",
      "0 label:  1\n",
      "node range:  [754, 161, 162, 325, 326, 39, 80, 755, 756, 757, 758, 759, 760, 761]\n",
      "target node:  754\n",
      "epoch time:  0.12154912948608398\n",
      "[0.3542739152908325, 0.33388757705688477, 0.3516838848590851, 0.34242191910743713, 0.34242191910743713, 0.3338875472545624, 0.33765342831611633, 0.35262051224708557, 0.34088724851608276, 0.3526204824447632, 0.3438946604728699, 0.33880579471588135, 0.34088727831840515, 0.33880576491355896]\n",
      "[ 0  7  9  2 10  4  3 12  8 11 13  6  1  5]\n",
      "truth node:  [0, 7, 8, 9, 10, 11, 12, 13]\n",
      "acc:  0.6666666666666666\n",
      "auc:  0.7291666666666667\n",
      "mean acc:  0.8873668188736683\n",
      "mean auc:  0.9296393215485681\n",
      "\n",
      "index:  755\n",
      "0 label:  1\n",
      "node range:  [755, 162, 325, 326, 80, 754, 756, 757, 758, 759, 760, 761, 762]\n",
      "target node:  755\n",
      "epoch time:  0.12008881568908691\n",
      "[0.35692042112350464, 0.3367471694946289, 0.3334386944770813, 0.3334386944770813, 0.3325350284576416, 0.3526022136211395, 0.35709643363952637, 0.3437579572200775, 0.35395681858062744, 0.34683677554130554, 0.3381475806236267, 0.3362421989440918, 0.33899274468421936]\n",
      "[ 6  0  8  5  9  7 12 10  1 11  3  2  4]\n",
      "truth node:  [0, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8873771730914589\n",
      "mean auc:  0.9299290011449876\n",
      "\n",
      "index:  756\n",
      "0 label:  1\n",
      "node range:  [756, 162, 754, 755, 757, 758, 759, 761, 762]\n",
      "target node:  756\n",
      "epoch time:  0.09022355079650879\n",
      "[0.3689841330051422, 0.33907854557037354, 0.346688449382782, 0.3655906319618225, 0.3446767032146454, 0.3541537821292877, 0.36671391129493713, 0.34565725922584534, 0.34958961606025696]\n",
      "[0 6 3 5 8 2 7 4 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8873873873873874\n",
      "mean auc:  0.9304024538399539\n",
      "\n",
      "index:  757\n",
      "0 label:  1\n",
      "node range:  [757, 162, 325, 326, 80, 754, 755, 756, 758, 759, 760, 761, 762]\n",
      "target node:  757\n",
      "epoch time:  0.12212538719177246\n",
      "[0.35692042112350464, 0.3367471694946289, 0.3334386944770813, 0.3334386944770813, 0.3325350284576416, 0.3526022434234619, 0.3437579572200775, 0.3381475806236267, 0.35395681858062744, 0.3362421989440918, 0.35709646344184875, 0.34683677554130554, 0.33899274468421936]\n",
      "[10  0  8  5 11  6 12  7  1  9  3  2  4]\n",
      "truth node:  [0, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8873974645786726\n",
      "mean auc:  0.9306831234264121\n",
      "\n",
      "index:  758\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  759\n",
      "0 label:  1\n",
      "node range:  [759, 754, 755, 756, 757, 758, 760, 761, 762]\n",
      "target node:  759\n",
      "epoch time:  0.09132981300354004\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554757833480835, 0.33900347352027893, 0.34700849652290344, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  760\n",
      "0 label:  1\n",
      "node range:  [760, 162, 754, 755, 757, 758, 759, 761, 762]\n",
      "target node:  760\n",
      "epoch time:  0.10180068016052246\n",
      "[0.3689841628074646, 0.339078426361084, 0.34668850898742676, 0.3446768820285797, 0.3655907213687897, 0.3541537821292877, 0.34565725922584534, 0.36671388149261475, 0.34958961606025696]\n",
      "[0 7 4 5 8 2 6 3 1]\n",
      "truth node:  [0, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8874074074074074\n",
      "mean auc:  0.9311452359369027\n",
      "\n",
      "index:  761\n",
      "0 label:  1\n",
      "node range:  [761, 754, 755, 756, 757, 758, 759, 760, 762]\n",
      "target node:  761\n",
      "epoch time:  0.08121442794799805\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900341391563416, 0.34689080715179443, 0.3554757833480835, 0.34700849652290344, 0.35820528864860535, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  762\n",
      "0 label:  1\n",
      "node range:  [762, 755, 756, 757, 758, 759, 760, 761]\n",
      "target node:  762\n",
      "epoch time:  0.08800244331359863\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963, 0.3650220036506653]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  763\n",
      "0 label:  1\n",
      "node range:  [763, 768, 769, 770, 167, 168, 41, 337, 338, 83, 764, 765, 766, 767]\n",
      "target node:  763\n",
      "epoch time:  0.12543344497680664\n",
      "[0.3542739152908325, 0.33880576491355896, 0.3408872187137604, 0.33880576491355896, 0.33388757705688477, 0.3516838848590851, 0.33388757705688477, 0.34242191910743713, 0.3424219489097595, 0.3376534879207611, 0.35262051224708557, 0.3408872187137604, 0.35262051224708557, 0.3438946306705475]\n",
      "[ 0 12 10  5 13  8  7 11  2  3  1  9  6  4]\n",
      "truth node:  [0, 1, 2, 3, 10, 11, 12, 13]\n",
      "acc:  0.6666666666666666\n",
      "auc:  0.7291666666666667\n",
      "mean acc:  0.8859455481972038\n",
      "mean auc:  0.9298076295178944\n",
      "\n",
      "index:  764\n",
      "0 label:  1\n",
      "node range:  [764, 768, 769, 770, 771, 168, 337, 338, 83, 763, 765, 766, 767]\n",
      "target node:  764\n",
      "epoch time:  0.12963604927062988\n",
      "[0.35692042112350464, 0.34683677554130554, 0.3381475806236267, 0.3362421989440918, 0.33899274468421936, 0.3367471694946289, 0.3334386944770813, 0.3334386944770813, 0.3325350284576416, 0.3526022136211395, 0.35709646344184875, 0.3437579572200775, 0.35395681858062744]\n",
      "[10  0 12  9  1 11  4  2  5  3  7  6  8]\n",
      "truth node:  [0, 1, 2, 3, 4, 9, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8859649122807018\n",
      "mean auc:  0.930086672890949\n",
      "\n",
      "index:  765\n",
      "0 label:  1\n",
      "node range:  [765, 768, 770, 771, 168, 763, 764, 766, 767]\n",
      "target node:  765\n",
      "epoch time:  0.0853877067565918\n",
      "[0.3689841628074646, 0.36671391129493713, 0.34565725922584534, 0.34958958625793457, 0.3390783965587616, 0.346688449382782, 0.3655906915664673, 0.3446766436100006, 0.35415375232696533]\n",
      "[0 1 6 8 3 5 2 7 4]\n",
      "truth node:  [0, 1, 2, 3, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8859840232389253\n",
      "mean auc:  0.9305436227413351\n",
      "\n",
      "index:  766\n",
      "0 label:  1\n",
      "node range:  [766, 768, 769, 770, 771, 168, 337, 338, 83, 763, 764, 765, 767]\n",
      "target node:  766\n",
      "epoch time:  0.1331024169921875\n",
      "[0.35692042112350464, 0.3362421989440918, 0.35709646344184875, 0.34683677554130554, 0.33899274468421936, 0.3367471694946289, 0.3334386944770813, 0.3334386944770813, 0.3325350284576416, 0.3526022434234619, 0.3437579572200775, 0.3381475806236267, 0.35395681858062744]\n",
      "[ 2  0 12  9  3 10  4 11  5  1  7  6  8]\n",
      "truth node:  [0, 1, 2, 3, 4, 9, 10, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8860028860028861\n",
      "mean auc:  0.9308142629977045\n",
      "\n",
      "index:  767\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  768\n",
      "0 label:  1\n",
      "node range:  [768, 769, 770, 771, 763, 764, 765, 766, 767]\n",
      "target node:  768\n",
      "epoch time:  0.08150935173034668\n",
      "[0.3604322075843811, 0.33900347352027893, 0.34700849652290344, 0.3583422303199768, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554758131504059]\n",
      "[0 3 6 8 2 5 1 4 7]\n",
      "foo\n",
      "\n",
      "index:  769\n",
      "0 label:  1\n",
      "node range:  [769, 768, 770, 771, 168, 763, 764, 766, 767]\n",
      "target node:  769\n",
      "epoch time:  0.09406042098999023\n",
      "[0.3689841628074646, 0.34565725922584534, 0.36671388149261475, 0.34958958625793457, 0.3390783369541168, 0.346688449382782, 0.3446767032146454, 0.3655907213687897, 0.3541537821292877]\n",
      "[0 2 7 8 3 5 1 6 4]\n",
      "truth node:  [0, 1, 2, 3, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8860215053763442\n",
      "mean auc:  0.9312606225912676\n",
      "\n",
      "index:  770\n",
      "0 label:  1\n",
      "node range:  [770, 768, 769, 771, 763, 764, 765, 766, 767]\n",
      "target node:  770\n",
      "epoch time:  0.08028149604797363\n",
      "[0.3604322075843811, 0.34700843691825867, 0.35820528864860535, 0.3583422303199768, 0.3377439081668854, 0.33623364567756653, 0.33900341391563416, 0.34689080715179443, 0.3554757833480835]\n",
      "[0 3 2 8 1 7 6 4 5]\n",
      "foo\n",
      "\n",
      "index:  771\n",
      "0 label:  1\n",
      "node range:  [771, 768, 769, 770, 764, 765, 766, 767]\n",
      "target node:  771\n",
      "epoch time:  0.0730428695678711\n",
      "[0.36824873089790344, 0.36502206325531006, 0.3425886631011963, 0.36502206325531006, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207]\n",
      "[0 3 1 7 5 2 6 4]\n",
      "foo\n",
      "\n",
      "index:  772\n",
      "0 label:  1\n",
      "node range:  [772, 773, 774, 775, 776, 777, 778, 42, 779, 173, 174, 86, 349, 350]\n",
      "target node:  772\n",
      "epoch time:  0.13774871826171875\n",
      "[0.3539577126502991, 0.35221999883651733, 0.3398563861846924, 0.35221996903419495, 0.34302595257759094, 0.3376641571521759, 0.3398563861846924, 0.33224010467529297, 0.3376641273498535, 0.33245494961738586, 0.3511790633201599, 0.33641624450683594, 0.34144827723503113, 0.34144827723503113]\n",
      "[ 0  1  3 10  4 13 12  6  2  5  8 11  9  7]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "acc:  0.6666666666666666\n",
      "auc:  0.7291666666666667\n",
      "mean acc:  0.8846153846153846\n",
      "mean auc:  0.9299651485148279\n",
      "\n",
      "index:  773\n",
      "0 label:  1\n",
      "node range:  [773, 772, 774, 775, 776, 777, 778, 779, 780, 174, 86, 349, 350]\n",
      "target node:  773\n",
      "epoch time:  0.12514090538024902\n",
      "[0.35692042112350464, 0.3526022434234619, 0.35709646344184875, 0.3437579572200775, 0.35395681858062744, 0.34683677554130554, 0.3381475806236267, 0.3362421989440918, 0.33899274468421936, 0.3367471694946289, 0.3325350284576416, 0.3334386944770813, 0.3334386944770813]\n",
      "[ 2  0  4  1  5  3  8  6  9  7 12 11 10]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8846426043878275\n",
      "mean auc:  0.9302343018505438\n",
      "\n",
      "index:  774\n",
      "0 label:  1\n",
      "node range:  [774, 772, 773, 775, 776, 777, 779, 780, 174]\n",
      "target node:  774\n",
      "epoch time:  0.10485076904296875\n",
      "[0.368984192609787, 0.34668850898742676, 0.3655906915664673, 0.3446768820285797, 0.35415375232696533, 0.36671391129493713, 0.34565725922584534, 0.34958964586257935, 0.3390786349773407]\n",
      "[0 5 2 4 7 1 6 3 8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8846694796061885\n",
      "mean auc:  0.9306758569021226\n",
      "\n",
      "index:  775\n",
      "0 label:  1\n",
      "node range:  [775, 772, 773, 774, 776, 777, 778, 779, 780, 174, 86, 349, 350]\n",
      "target node:  775\n",
      "epoch time:  0.21239972114562988\n",
      "[0.35692042112350464, 0.3526022136211395, 0.3437579572200775, 0.3381475806236267, 0.35395681858062744, 0.3362421989440918, 0.35709646344184875, 0.34683677554130554, 0.33899274468421936, 0.3367471694946289, 0.3325350284576416, 0.3334386944770813, 0.3334386944770813]\n",
      "[ 6  0  4  1  7  2  8  3  9  5 12 11 10]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8846960167714886\n",
      "mean auc:  0.9309371547972176\n",
      "\n",
      "index:  776\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  777\n",
      "0 label:  1\n",
      "node range:  [777, 772, 773, 774, 775, 776, 778, 779, 780]\n",
      "target node:  777\n",
      "epoch time:  0.17934226989746094\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554758131504059, 0.33900347352027893, 0.34700849652290344, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  778\n",
      "0 label:  1\n",
      "node range:  [778, 772, 773, 775, 776, 777, 779, 780, 174]\n",
      "target node:  778\n",
      "epoch time:  0.13582658767700195\n",
      "[0.368984192609787, 0.346688449382782, 0.3446767032146454, 0.3655906617641449, 0.35415375232696533, 0.3456572890281677, 0.36671388149261475, 0.3495895564556122, 0.3390783369541168]\n",
      "[0 6 3 4 7 1 5 2 8]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8847222222222225\n",
      "mean auc:  0.931368797579735\n",
      "\n",
      "index:  779\n",
      "0 label:  1\n",
      "node range:  [779, 772, 773, 774, 775, 776, 777, 778, 780]\n",
      "target node:  779\n",
      "epoch time:  0.14413166046142578\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900347352027893, 0.34689080715179443, 0.3554757833480835, 0.34700849652290344, 0.35820528864860535, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  780\n",
      "0 label:  1\n",
      "node range:  [780, 773, 774, 775, 776, 777, 778, 779]\n",
      "target node:  780\n",
      "epoch time:  0.1324465274810791\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963, 0.36502206325531006]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  781\n",
      "0 label:  1\n",
      "node range:  [781, 361, 362, 44, 782, 783, 784, 785, 82, 787, 179, 180, 786, 788, 89]\n",
      "target node:  781\n",
      "epoch time:  0.1320950984954834\n",
      "[0.354007363319397, 0.3414153456687927, 0.3414153456687927, 0.3320537507534027, 0.35228922963142395, 0.339849054813385, 0.35228919982910156, 0.3430364727973938, 0.3318745791912079, 0.339849054813385, 0.3320537507534027, 0.350897878408432, 0.33764803409576416, 0.33764806389808655, 0.3354156017303467]\n",
      "[ 0  4  6 11  7  2  1  9  5 13 12 14 10  3  8]\n",
      "truth node:  [0, 4, 5, 6, 7, 9, 12, 13]\n",
      "acc:  0.6666666666666666\n",
      "auc:  0.7678571428571429\n",
      "mean acc:  0.8833678398895792\n",
      "mean auc:  0.930353197239843\n",
      "\n",
      "index:  782\n",
      "0 label:  1\n",
      "node range:  [782, 361, 362, 781, 783, 784, 785, 786, 787, 180, 788, 789, 89]\n",
      "target node:  782\n",
      "epoch time:  0.11012911796569824\n",
      "[0.35700723528862, 0.33338016271591187, 0.3333801329135895, 0.35264313220977783, 0.35718899965286255, 0.34376877546310425, 0.3540269434452057, 0.34687596559524536, 0.3381308317184448, 0.3367106318473816, 0.3362206518650055, 0.33898696303367615, 0.33224788308143616]\n",
      "[ 4  0  6  3  7  5 11  8  9 10  1  2 12]\n",
      "truth node:  [0, 3, 4, 5, 6, 7, 8, 10, 11]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8834019204389577\n",
      "mean auc:  0.9306116480113391\n",
      "\n",
      "index:  783\n",
      "0 label:  1\n",
      "node range:  [783, 781, 782, 784, 785, 786, 180, 789, 788]\n",
      "target node:  783\n",
      "epoch time:  0.08922648429870605\n",
      "[0.3689841628074646, 0.34668853878974915, 0.3655906319618225, 0.34467679262161255, 0.3541537821292877, 0.3667139410972595, 0.33907854557037354, 0.34958964586257935, 0.3456573188304901]\n",
      "[0 5 2 4 7 1 8 3 6]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8834355828220861\n",
      "mean auc:  0.9310373434223126\n",
      "\n",
      "index:  784\n",
      "0 label:  1\n",
      "node range:  [784, 361, 362, 781, 782, 783, 785, 786, 787, 180, 788, 789, 89]\n",
      "target node:  784\n",
      "epoch time:  0.10995197296142578\n",
      "[0.35700723528862, 0.33338016271591187, 0.33338016271591187, 0.35264313220977783, 0.34376874566078186, 0.33813080191612244, 0.3540269434452057, 0.3362206518650055, 0.35718899965286255, 0.3367105722427368, 0.34687596559524536, 0.33898699283599854, 0.33224788308143616]\n",
      "[ 8  0  6  3 10  4 11  5  9  7  2  1 12]\n",
      "truth node:  [0, 3, 4, 5, 6, 7, 8, 10, 11]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.883468834688347\n",
      "mean auc:  0.9312884707320681\n",
      "\n",
      "index:  785\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  786\n",
      "0 label:  1\n",
      "node range:  [786, 781, 782, 783, 784, 785, 787, 788, 789]\n",
      "target node:  786\n",
      "epoch time:  0.09268403053283691\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554757833480835, 0.33900341391563416, 0.34700849652290344, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  787\n",
      "0 label:  1\n",
      "node range:  [787, 781, 782, 784, 785, 786, 180, 789, 788]\n",
      "target node:  787\n",
      "epoch time:  0.09306454658508301\n",
      "[0.368984192609787, 0.3466883599758148, 0.3446767032146454, 0.3655906915664673, 0.35415375232696533, 0.34565725922584534, 0.3390786051750183, 0.34958967566490173, 0.36671385169029236]\n",
      "[0 8 3 4 7 1 5 2 6]\n",
      "truth node:  [0, 1, 2, 3, 4, 5, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8835016835016837\n",
      "mean auc:  0.9317049042427828\n",
      "\n",
      "index:  788\n",
      "0 label:  1\n",
      "node range:  [788, 781, 782, 783, 784, 785, 786, 787, 789]\n",
      "target node:  788\n",
      "epoch time:  0.09601974487304688\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900347352027893, 0.34689080715179443, 0.3554757833480835, 0.34700849652290344, 0.35820525884628296, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  789\n",
      "0 label:  1\n",
      "node range:  [789, 782, 783, 784, 785, 786, 787, 788]\n",
      "target node:  789\n",
      "epoch time:  0.07925081253051758\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.3650220036506653, 0.3425886631011963, 0.3650220036506653]\n",
      "[0 7 5 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  790\n",
      "0 label:  1\n",
      "node range:  [790, 795, 186, 791, 45, 92, 373, 374, 792, 185, 794, 793, 796, 797]\n",
      "target node:  790\n",
      "epoch time:  0.14783668518066406\n",
      "[0.3542739748954773, 0.33880576491355896, 0.3516838252544403, 0.35262054204940796, 0.33388760685920715, 0.3376534879207611, 0.3424219489097595, 0.3424220085144043, 0.3408872187137604, 0.33388757705688477, 0.3438946306705475, 0.3526204824447632, 0.3408872187137604, 0.3388057351112366]\n",
      "[ 0  3 11  2 10  7  6 12  8  1 13  5  4  9]\n",
      "truth node:  [0, 1, 3, 8, 10, 11, 12, 13]\n",
      "acc:  0.6666666666666666\n",
      "auc:  0.7291666666666667\n",
      "mean acc:  0.8821954484605088\n",
      "mean auc:  0.9304847943778666\n",
      "\n",
      "index:  791\n",
      "0 label:  1\n",
      "node range:  [791, 796, 794, 792, 373, 374, 790, 793, 186, 795, 92, 797, 798]\n",
      "target node:  791\n",
      "epoch time:  0.11113548278808594\n",
      "[0.35692042112350464, 0.3381475806236267, 0.35395681858062744, 0.35709646344184875, 0.3334386944770813, 0.3334386944770813, 0.3526022136211395, 0.3437579572200775, 0.3367471694946289, 0.34683674573898315, 0.3325350284576416, 0.3362421989440918, 0.33899274468421936]\n",
      "[ 3  0  2  6  9  7 12  1  8 11  5  4 10]\n",
      "truth node:  [0, 1, 2, 3, 6, 7, 9, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.882235528942116\n",
      "mean auc:  0.9307347190954975\n",
      "\n",
      "index:  792\n",
      "0 label:  1\n",
      "node range:  [792, 795, 790, 791, 793, 186, 794, 797, 798]\n",
      "target node:  792\n",
      "epoch time:  0.10933732986450195\n",
      "[0.3689841330051422, 0.36671385169029236, 0.3466883897781372, 0.3655906617641449, 0.34467679262161255, 0.33907854557037354, 0.3541537821292877, 0.3456573188304901, 0.34958964586257935]\n",
      "[0 1 3 6 8 2 7 4 5]\n",
      "truth node:  [0, 1, 2, 3, 4, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8822751322751323\n",
      "mean auc:  0.9311470124342146\n",
      "\n",
      "index:  793\n",
      "0 label:  1\n",
      "node range:  [793, 796, 794, 792, 373, 374, 791, 790, 186, 795, 92, 797, 798]\n",
      "target node:  793\n",
      "epoch time:  0.1604142189025879\n",
      "[0.35692042112350464, 0.35709643363952637, 0.35395681858062744, 0.3381475806236267, 0.3334386944770813, 0.3334386944770813, 0.3437579572200775, 0.3526022136211395, 0.3367471694946289, 0.3362421989440918, 0.332535058259964, 0.34683677554130554, 0.33899274468421936]\n",
      "[ 1  0  2  7 11  6 12  3  8  9  5  4 10]\n",
      "truth node:  [0, 1, 2, 3, 6, 7, 9, 11, 12]\n",
      "acc:  0.8888888888888888\n",
      "auc:  0.9722222222222222\n",
      "mean acc:  0.8823142669296518\n",
      "mean auc:  0.9313900610128419\n",
      "\n",
      "index:  794\n",
      "0 label:  1\n",
      "================ incorrect pred =====================\n",
      "\n",
      "index:  795\n",
      "0 label:  1\n",
      "node range:  [795, 790, 791, 792, 793, 794, 796, 797, 798]\n",
      "target node:  795\n",
      "epoch time:  0.09305691719055176\n",
      "[0.3604322075843811, 0.3377439081668854, 0.34689080715179443, 0.35820528864860535, 0.33623364567756653, 0.3554757833480835, 0.33900347352027893, 0.34700849652290344, 0.3583422303199768]\n",
      "[0 8 3 5 7 2 6 1 4]\n",
      "foo\n",
      "\n",
      "index:  796\n",
      "0 label:  1\n",
      "node range:  [796, 795, 790, 791, 793, 186, 794, 797, 798]\n",
      "target node:  796\n",
      "epoch time:  0.09653830528259277\n",
      "[0.368984192609787, 0.3456573188304901, 0.34668833017349243, 0.3446767032146454, 0.3655906319618225, 0.3390785753726959, 0.3541537821292877, 0.36671391129493713, 0.3495897054672241]\n",
      "[0 7 4 6 8 2 1 3 5]\n",
      "truth node:  [0, 1, 2, 3, 4, 6, 7, 8]\n",
      "acc:  0.8888888888888888\n",
      "auc:  1.0\n",
      "mean acc:  0.8823529411764706\n",
      "mean auc:  0.931793648889237\n",
      "\n",
      "index:  797\n",
      "0 label:  1\n",
      "node range:  [797, 790, 791, 792, 793, 794, 795, 796, 798]\n",
      "target node:  797\n",
      "epoch time:  0.0798492431640625\n",
      "[0.3604322075843811, 0.3377439081668854, 0.33623364567756653, 0.33900347352027893, 0.34689080715179443, 0.3554757833480835, 0.34700849652290344, 0.35820525884628296, 0.3583422303199768]\n",
      "[0 8 7 5 6 4 3 1 2]\n",
      "foo\n",
      "\n",
      "index:  798\n",
      "0 label:  1\n",
      "node range:  [798, 791, 792, 793, 794, 795, 796, 797]\n",
      "target node:  798\n",
      "epoch time:  0.0703282356262207\n",
      "[0.36824873089790344, 0.3374617099761963, 0.3425886631011963, 0.3374617099761963, 0.34873244166374207, 0.36502206325531006, 0.3425886631011963, 0.3650220036506653]\n",
      "[0 5 7 4 6 2 3 1]\n",
      "foo\n",
      "\n",
      "index:  799\n",
      "0 label:  1\n",
      "node range:  [799, 192, 801, 385, 803, 386, 805, 191, 800, 802, 804, 806, 47, 95]\n",
      "target node:  799\n",
      "epoch time:  0.1385200023651123\n",
      "[0.3542739748954773, 0.3516838550567627, 0.34088727831840515, 0.3424219489097595, 0.3438946604728699, 0.34242191910743713, 0.34088727831840515, 0.33388757705688477, 0.35262051224708557, 0.35262051224708557, 0.3388057351112366, 0.33880579471588135, 0.33388757705688477, 0.3376534581184387]\n",
      "[ 0  9  8  1  4  3  5  6  2 11 10 13 12  7]\n",
      "truth node:  [0, 2, 4, 6, 8, 9, 10, 11]\n",
      "acc:  0.6666666666666666\n",
      "auc:  0.7291666666666667\n",
      "mean acc:  0.8810916179337233\n",
      "mean auc:  0.9306086957768243\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "auc_list = []\n",
    "\n",
    "dataset.subgraph = False\n",
    "dataset.remap = False\n",
    "dataset.setting=1\n",
    "load_model = gcn_model\n",
    "#load_model = torch.load('./checkpoint/community_temp')\n",
    "#load_model = torch.load('./checkpoint/gcn_mix').to('cuda')\n",
    "load_model.eval()\n",
    "\n",
    "all_node_label = []\n",
    "all_node_color = []\n",
    "for idx in dataset.allnodes:\n",
    "    #idx = 519\n",
    "    print('\\nindex: ', idx)\n",
    "    sub_adj,sub_feature, sub_label,sub_edge_label_matrix = dataset.get_subgraph(idx)\n",
    "    #truth_node = np.where(sub_label[:,1] == True)[0]\n",
    "    truth_node = list(get_node_set(sub_edge_label_matrix))\n",
    "    \n",
    "    class_idx = np.argmax(sub_label[0],axis=-1)\n",
    "    print('0 label: ', class_idx)\n",
    "    if indices[idx] != class_idx:\n",
    "        print('================ incorrect pred =====================')\n",
    "        continue\n",
    "    node_range = dataset.extractor.nodes\n",
    "    print('node range: ', node_range)\n",
    "    node_sort, node_color = print_subgraph_explain(dataset = dataset, model = load_model, idx = 0, class_idx = class_idx, visible = False, figsize = (12,9), node_range = node_range)\n",
    "    print(node_color)\n",
    "    print(node_sort)\n",
    "\n",
    "    node_label = np.array([0] * sub_label.shape[0])\n",
    "    #node_label[list(truth_node)] = 1\n",
    "    # find truth node, far node is not real truth\n",
    "    for n in truth_node:\n",
    "        if abs((node_range[n] - node_range[0])) <= 9:\n",
    "            node_label[n] = 1\n",
    "    #        print(n)\n",
    "    if np.sum(node_label) > 9: node_sort, node_color = print_subgraph_explain(dataset = dataset, model = load_model, idx = 0, class_idx = class_idx, visible = True, figsize = (12,9), node_range = node_range)\n",
    "    try:\n",
    "        auc = roc_auc_score(node_label, node_color)\n",
    "    except:\n",
    "        print('foo')\n",
    "        continue\n",
    "        auc = 1.0\n",
    "\n",
    "    print(\"truth node: \", truth_node)\n",
    "    #print(node_sort)\n",
    "    acc = len([node for node in node_sort[:9] if node in truth_node])/9\n",
    "    acc_list.append(acc)\n",
    "    auc_list.append(auc)\n",
    "    #all_node_label.extend(node_label)\n",
    "    #all_node_color.extend(node_color)\n",
    "    print('acc: ', acc)\n",
    "    print('auc: ', auc)\n",
    "    #if acc == 0.0:\n",
    "    #    print(node_sort)\n",
    "    #    print_explain(dataset, load_model, idx, class_idx = np.argmax(sub_label[0],axis=-1), visible = True)\n",
    "    print('mean acc: ', np.mean(acc_list))\n",
    "    print('mean auc: ', np.mean(auc_list))\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(dataset, 0).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Batch(batch=[1231], edge_index=[2, 3130], x=[1231, 10], y=[1231])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-1.3405, -0.3034],\n",
       "        [-1.3357, -0.3051],\n",
       "        [-1.4081, -0.2805],\n",
       "        ...,\n",
       "        [-1.3386, -0.3041],\n",
       "        [-1.2692, -0.3300],\n",
       "        [-1.4808, -0.2581]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "gcn_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "target node:  519\n[[519], [512], [513], [514], [515], [516], [517], [518]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: {'rel': [nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "  'irrel': [nan, nan, nan, nan, nan, nan, nan, nan]},\n",
       " 1: {'rel': [nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "  'irrel': [nan, nan, nan, nan, nan, nan, nan, nan]}}"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "CD_explain(model = gcn_model, dataset = dataset, idx = 0, node_range = node_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[519, 512, 513, 514, 515, 516, 517, 518]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "node_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CD_explain(model, dataset, idx = 0, mask_node_list = None, node_range = None, target_node = None):\n",
    "    \"\"\"\n",
    "    idx: idx of graph to explain\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    data = get_data(dataset, idx)\n",
    "    data = data.to(device)\n",
    "    \n",
    "\n",
    "    mask_list = []\n",
    "    # generate mask\n",
    "    node_range = range(data.x.shape[0]) if node_range is None else node_range\n",
    "    target_node = target_node if target_node is not None else node_range[0]\n",
    "    '''\n",
    "    for i in range(node_range):\n",
    "        # generate data idx mask to check\n",
    "        mask_index = [0] * data.x.shape[0]\n",
    "        mask_index[i] = 1\n",
    "     b mask_node_list is not None and i in mask_node_list:\n",
    "            for n in mask_node_list:\n",
    "                print(i)\n",
    "                print(mask_node_list)\n",
    "                mask_index[n] = 1\n",
    "        mask_list.append(mask_index)\n",
    "    '''\n",
    "\n",
    "    for i in node_range:\n",
    "        if mask_node_list is not None and i in mask_node_list:\n",
    "            mask_list.append(mask_node_list)\n",
    "        else:\n",
    "            mask_list.append([i])\n",
    "    # forward to explain according to mask list\n",
    "    print('target node: ', target_node)\n",
    "    print(mask_list)\n",
    "    class_score = get_score(model = model, data = data, input_mask_list = mask_list, target_node = target_node)\n",
    "    return class_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-0.4491,  1.1768], device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "mask_index = [0] * 1231\n",
    "mask_index[513] = 0\n",
    "preds = gcn_model.forward(data, CD_explain=True, mask_index = mask_index)\n",
    "preds['irrel'][519]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(tensor([], device='cuda:0', dtype=torch.int64), tensor([], device='cuda:0', dtype=torch.int64))\n(tensor([], device='cuda:0', dtype=torch.int64), tensor([], device='cuda:0', dtype=torch.int64))\nout1:  tensor([[-0.7417, -0.7377, -0.8229,  ..., -0.7401, -0.6534, -1.2926],\n        [ 0.6840,  0.6797,  0.7706,  ...,  0.6823,  0.5898,  1.2729]],\n       device='cuda:0', grad_fn=<AddBackward0>)\nout max:  tensor(5.3361, device='cuda:0', grad_fn=<MaxBackward1>)\nout2:  tensor([[-6.0778, -6.0737, -6.1590,  ..., -6.0762, -5.9895, -6.6286],\n        [-4.6521, -4.6564, -4.5654,  ..., -4.6538, -4.7463, -4.0632]],\n       device='cuda:0', grad_fn=<SubBackward0>)\nout3:  tensor([[0.0023, 0.0023, 0.0021,  ..., 0.0023, 0.0025, 0.0013],\n        [0.0095, 0.0095, 0.0104,  ..., 0.0095, 0.0087, 0.0172]],\n       device='cuda:0', grad_fn=<ExpBackward>)\n_rel:  tensor([[0.6774, 0.6765, 0.6949,  ..., 0.6770, 0.6578, 0.7846],\n        [0.3354, 0.3363, 0.3163,  ..., 0.3357, 0.3567, 0.2188]],\n       device='cuda:0', grad_fn=<MulBackward0>)\n_irrel:  tensor([[0.3226, 0.3235, 0.3051,  ..., 0.3230, 0.3422, 0.2154],\n        [0.6646, 0.6637, 0.6837,  ..., 0.6643, 0.6433, 0.7812]],\n       device='cuda:0', grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: {'rel': [0.05073805898427963], 'irrel': [0.024297235533595085]},\n",
       " 1: {'rel': [0.30219730734825134], 'irrel': [0.6227673888206482]}}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "gcn_model.to('cuda')\n",
    "get_score(gcn_model, data, input_mask_list = [[519]], softmax = True, target_node = 519)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, data, input_mask_list, softmax = True, target_node = 0):\n",
    "    Binary_mask_list = []\n",
    "    for i in range(len(input_mask_list)):\n",
    "        mask_index = [0] * data.x.shape[0]\n",
    "        for m in input_mask_list[i]:\n",
    "            mask_index[m] = 1\n",
    "        Binary_mask_list.append(mask_index)\n",
    "    \n",
    "    preds_list = []\n",
    "    model.eval()\n",
    "    \n",
    "    for mask_index in Binary_mask_list:\n",
    "        model.zero_grad()\n",
    "        preds = model.forward(data, CD_explain=True, mask_index = mask_index)\n",
    "        #print(preds)\n",
    "        #print(data.y)\n",
    "        preds['rel'] = preds['rel'].T\n",
    "        preds['irrel'] = preds['irrel'].T\n",
    "        #print(preds['irrel'].shape[0])\n",
    "        #print(dataset.num_classes)\n",
    "        print(torch.where(torch.isnan(preds['rel']) == True))\n",
    "        print(torch.where(torch.isnan(preds['irrel']) == True))\n",
    "        #print(preds)\n",
    "        if softmax:\n",
    "            preds = CD_softmax(preds, index = torch.tensor([0] * preds['irrel'].shape[0]).to(device))\n",
    "        #print(preds)\n",
    "        preds_list.append(preds)\n",
    "        # need to softmax??\n",
    "        #print('preds shape', preds['rel'].shape)\n",
    "    # rel cd score for each class\n",
    "    class_score = {}\n",
    "    for class_idx in range(preds['irrel'].shape[0]):\n",
    "        class_score[class_idx] = {}\n",
    "        class_score[class_idx]['rel'] = []\n",
    "        class_score[class_idx]['irrel'] = []\n",
    "        for preds in preds_list:\n",
    "            class_score[class_idx]['rel'].append((float)((preds['rel'][class_idx][target_node].cpu().detach())))\n",
    "            class_score[class_idx]['irrel'].append((float)((preds['irrel'][class_idx][target_node].cpu().detach())))\n",
    "            #class_score[class_idx]['rel'].append((float)((preds['rel'][0][class_idx].cpu().detach())))\n",
    "            #class_score[class_idx]['irrel'].append((float)((preds['irrel'][0][class_idx].cpu().detach())))\n",
    "\n",
    "    return class_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global o\n",
    "\n",
    "def CD_softmax(src: Tensor, index: Optional[Tensor], ptr: Optional[Tensor] = None,\n",
    "            num_nodes: Optional[int] = None) -> Tensor:\n",
    "\n",
    "    cd_explain = isinstance(src, dict)\n",
    "    if cd_explain:\n",
    "        out = src['rel'] + src['irrel']\n",
    "        out_rel = src['rel']\n",
    "        out_irrel = src['irrel']\n",
    "        print('out1: ', out)\n",
    "    else:\n",
    "        out = src\n",
    "    \n",
    "    #print(out.shape)\n",
    "    global o\n",
    "    o = out\n",
    "    print('out max: ', out.max())\n",
    "    out = out - out.max()\n",
    "    print('out2: ', out)\n",
    "    out = out.exp()\n",
    "    print('out3: ', out)\n",
    "    if cd_explain:\n",
    "        _rel = 1.0/(1.0 + (out_irrel - out_rel).exp())\n",
    "        print('_rel: ', _rel)\n",
    "        _irrel = 1.0 - _rel\n",
    "        print('_irrel: ', _irrel)\n",
    "\n",
    "    if ptr is not None:\n",
    "        out_sum = gather_csr(segment_csr(out, ptr, reduce='sum'), ptr)\n",
    "    elif index is not None:\n",
    "        N = maybe_num_nodes(index, num_nodes)\n",
    "        out_sum = scatter(out, index, dim=0, dim_size=N, reduce='sum')[index]\n",
    "    elif index is None:\n",
    "        index = torch.tensor([0] * out.shape[0])\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    if cd_explain:\n",
    "        #print('out: ', out)\n",
    "        #print('out_sum: ', out_sum)\n",
    "        return {'rel': (out/(out_sum + 1e-16)) * _rel, 'irrel': (out/(out_sum + 1e-16)) * _irrel}\n",
    "    else:\n",
    "        return out / (out_sum + 1e-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       " tensor([162, 186, 234, 240, 246, 252, 162, 186, 234, 240, 246, 252],\n",
       "        device='cuda:0'))"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "torch.where(torch.isnan(o) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(nan, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "o.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}