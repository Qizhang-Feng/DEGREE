{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from Extractor import Extractor\n",
    "from scipy.sparse import coo_matrix,csr_matrix\n",
    "#import tensorflow as tf\n",
    "import torch\n",
    "from utils import *\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "from model import *\n",
    "from train import *\n",
    "\n",
    "from explain import *\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "import sys\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BA_Shape_Dataset(Dataset):\n",
    "    def __init__(self, root, name, setting=1, hops=3, transform = None, pre_transform = None, subgraph = False, remap=False):\n",
    "        super(BA_Shape_Dataset, self).__init__(root, transform, pre_transform)\n",
    "        self.root = root\n",
    "        self.subgraph = subgraph\n",
    "        self.remap = remap\n",
    "        self.name = name\n",
    "        self.setting =setting\n",
    "        with open(os.path.join(self.root, name + '.pkl'), 'rb') as fin:\n",
    "            self.adj, self.features, self.y_train, self.y_val, self.y_test, self.train_mask, self.val_mask, self.test_mask, self.edge_label_matrix  = pkl.load(fin)\n",
    "        self.hops = hops\n",
    "\n",
    "        self.all_label = np.logical_or(self.y_train,np.logical_or(self.y_val,self.y_test))\n",
    "        self.single_label = np.argmax(self.all_label,axis=-1)\n",
    "        #self.allnodes = [i for i in range(self.single_label.shape[0]) if self.single_label[i] != 0] #[i for i in range(400,700,5)]\n",
    "        self.csr_adj = csr_matrix(self.adj)\n",
    "        self.extractor = Extractor(self.csr_adj,self.features,self.edge_label_matrix,self.all_label,self.hops)            \n",
    "    @property\n",
    "    def num_features(self):\n",
    "        return 10\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return self.all_label.shape[1]\n",
    "\n",
    "    @property \n",
    "    def allnodes(self):\n",
    "        if self.setting==1:\n",
    "            if self.name=='syn3':\n",
    "                allnodes = [i for i in range(511,871,6)]\n",
    "            elif self.name=='syn4':\n",
    "                allnodes = [i for i in range(511,800,1)]\n",
    "            else:\n",
    "                allnodes = [i for i in range(400,700,5)] # setting from their original paper\n",
    "        elif self.setting==2:\n",
    "            allnodes = [i for i in range(self.single_label.shape[0]) if self.single_label[i] ==1]\n",
    "        elif self.setting==3:\n",
    "            if self.name == 'syn2':\n",
    "                allnodes = [i for i in range(self.single_label.shape[0]) if self.single_label[i] != 0 and self.single_label[i] != 4]\n",
    "            else:\n",
    "                allnodes = [i for i in range(self.single_label.shape[0]) if self.single_label[i] != 0]\n",
    "        return allnodes\n",
    "\n",
    "    def set_hops(self, hops=3):\n",
    "        self.hops = hops\n",
    "        self.extractor = Extractor(self.csr_adj,self.features,self.edge_label_matrix,self.all_label,self.hops)  \n",
    "\n",
    "    def get_subgraph(self, idx):\n",
    "        #if self.subgraph:\n",
    "        idx = self.allnodes[idx] if self.remap else idx\n",
    "        sub_adj,sub_feature, sub_label,sub_edge_label_matrix = dataset.extractor.subgraph(idx)\n",
    "        return sub_adj,sub_feature, sub_label,sub_edge_label_matrix\n",
    "        #else:\n",
    "        #    return None\n",
    "    def len(self):\n",
    "        if self.subgraph:\n",
    "            if not self.remap:\n",
    "                return len(self.single_label)\n",
    "            return len(self.allnodes)\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    def get(self, idx):\n",
    "        if self.subgraph:\n",
    "            if self.remap:\n",
    "                idx = self.allnodes[idx]\n",
    "            sub_adj,sub_feature, sub_label,sub_edge_label_matrix = self.extractor.subgraph(idx)\n",
    "            edge_index = torch.tensor(preprocess_adj(sub_adj)[0].T, dtype = torch.long)\n",
    "            x = torch.tensor(sub_feature).float()\n",
    "            y = torch.argmax(torch.tensor(sub_label, dtype = torch.int32), dim=-1)\n",
    "            data = Data(edge_index = edge_index, x = x, y = y)\n",
    "        else:\n",
    "\n",
    "            edge_index = torch.tensor(preprocess_adj(self.adj)[0].T, dtype = torch.long)\n",
    "            x = torch.tensor(self.features).float()\n",
    "            y = torch.argmax(torch.tensor(np.logical_or(self.y_train,np.logical_or(self.y_val,self.y_test)), dtype = torch.int32), dim=-1)\n",
    "            data = Data(edge_index = edge_index, x = x, y = y)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "explainer\n"
     ]
    }
   ],
   "source": [
    "dataset = BA_Shape_Dataset(root = './dataset', name = 'syn2', setting = 3)\n",
    "#dataset.allnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "explainer\n"
     ]
    }
   ],
   "source": [
    "gcn_model = GCN_Node(dataset, 3, 20)\n",
    "dataset.set_hops(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "prepare dataloader\n",
      "done\n",
      "Epoch:  0 Avg loss:  2.0779347 ; acc:  0.1072523 ; epoch time:  0.3596928119659424\n",
      "eval test...\n",
      "test acc:  0.13064134\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  1 Avg loss:  2.067303 ; acc:  0.1072523 ; epoch time:  0.3488128185272217\n",
      "eval test...\n",
      "test acc:  0.13064134\n",
      "\n",
      "\n",
      "Epoch:  2 Avg loss:  2.0568254 ; acc:  0.1072523 ; epoch time:  0.3212876319885254\n",
      "eval test...\n",
      "test acc:  0.13064134\n",
      "\n",
      "\n",
      "Epoch:  3 Avg loss:  2.0463288 ; acc:  0.1072523 ; epoch time:  0.33660125732421875\n",
      "eval test...\n",
      "test acc:  0.13064134\n",
      "\n",
      "\n",
      "Epoch:  4 Avg loss:  2.0358975 ; acc:  0.30439225 ; epoch time:  0.35362863540649414\n",
      "eval test...\n",
      "test acc:  0.34916866\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  5 Avg loss:  2.0248094 ; acc:  0.44739532 ; epoch time:  0.34763598442077637\n",
      "eval test...\n",
      "test acc:  0.47981\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  6 Avg loss:  2.0126474 ; acc:  0.43513793 ; epoch time:  0.3192760944366455\n",
      "eval test...\n",
      "test acc:  0.46080762\n",
      "\n",
      "\n",
      "Epoch:  7 Avg loss:  1.9990535 ; acc:  0.42798775 ; epoch time:  0.3345980644226074\n",
      "eval test...\n",
      "test acc:  0.44418055\n",
      "\n",
      "\n",
      "Epoch:  8 Avg loss:  1.9836781 ; acc:  0.4269663 ; epoch time:  0.3329427242279053\n",
      "eval test...\n",
      "test acc:  0.43942994\n",
      "\n",
      "\n",
      "Epoch:  9 Avg loss:  1.966349 ; acc:  0.42594486 ; epoch time:  0.33484387397766113\n",
      "eval test...\n",
      "test acc:  0.43705466\n",
      "\n",
      "\n",
      "Epoch:  10 Avg loss:  1.9469055 ; acc:  0.42492342 ; epoch time:  0.3274390697479248\n",
      "eval test...\n",
      "test acc:  0.43705466\n",
      "\n",
      "\n",
      "Epoch:  11 Avg loss:  1.9254225 ; acc:  0.42492342 ; epoch time:  0.3015613555908203\n",
      "eval test...\n",
      "test acc:  0.43705466\n",
      "\n",
      "\n",
      "Epoch:  12 Avg loss:  1.9018791 ; acc:  0.42185906 ; epoch time:  0.3184993267059326\n",
      "eval test...\n",
      "test acc:  0.43705466\n",
      "\n",
      "\n",
      "Epoch:  13 Avg loss:  1.8764957 ; acc:  0.42185906 ; epoch time:  0.3358118534088135\n",
      "eval test...\n",
      "test acc:  0.43705466\n",
      "\n",
      "\n",
      "Epoch:  14 Avg loss:  1.8493893 ; acc:  0.4228805 ; epoch time:  0.3749399185180664\n",
      "eval test...\n",
      "test acc:  0.43467936\n",
      "\n",
      "\n",
      "Epoch:  15 Avg loss:  1.8204825 ; acc:  0.42492342 ; epoch time:  0.332932710647583\n",
      "eval test...\n",
      "test acc:  0.43467936\n",
      "\n",
      "\n",
      "Epoch:  16 Avg loss:  1.789485 ; acc:  0.42594486 ; epoch time:  0.33525538444519043\n",
      "eval test...\n",
      "test acc:  0.43230405\n",
      "\n",
      "\n",
      "Epoch:  17 Avg loss:  1.7569278 ; acc:  0.4228805 ; epoch time:  0.3418276309967041\n",
      "eval test...\n",
      "test acc:  0.43705466\n",
      "\n",
      "\n",
      "Epoch:  18 Avg loss:  1.7233375 ; acc:  0.42185906 ; epoch time:  0.34018516540527344\n",
      "eval test...\n",
      "test acc:  0.42992875\n",
      "\n",
      "\n",
      "Epoch:  19 Avg loss:  1.6894982 ; acc:  0.42390195 ; epoch time:  0.3447847366333008\n",
      "eval test...\n",
      "test acc:  0.42755347\n",
      "\n",
      "\n",
      "Epoch:  20 Avg loss:  1.6563184 ; acc:  0.42492342 ; epoch time:  0.3261454105377197\n",
      "eval test...\n",
      "test acc:  0.43230405\n",
      "\n",
      "\n",
      "Epoch:  21 Avg loss:  1.6244522 ; acc:  0.4228805 ; epoch time:  0.3258378505706787\n",
      "eval test...\n",
      "test acc:  0.43467936\n",
      "\n",
      "\n",
      "Epoch:  22 Avg loss:  1.5933657 ; acc:  0.42492342 ; epoch time:  0.303006649017334\n",
      "eval test...\n",
      "test acc:  0.43467936\n",
      "\n",
      "\n",
      "Epoch:  23 Avg loss:  1.5631053 ; acc:  0.4269663 ; epoch time:  0.35245275497436523\n",
      "eval test...\n",
      "test acc:  0.43230405\n",
      "\n",
      "\n",
      "Epoch:  24 Avg loss:  1.5340203 ; acc:  0.42492342 ; epoch time:  0.33145737648010254\n",
      "eval test...\n",
      "test acc:  0.43230405\n",
      "\n",
      "\n",
      "Epoch:  25 Avg loss:  1.5065067 ; acc:  0.4290092 ; epoch time:  0.33089733123779297\n",
      "eval test...\n",
      "test acc:  0.43467936\n",
      "\n",
      "\n",
      "Epoch:  26 Avg loss:  1.4810011 ; acc:  0.4290092 ; epoch time:  0.3894636631011963\n",
      "eval test...\n",
      "test acc:  0.43467936\n",
      "\n",
      "\n",
      "Epoch:  27 Avg loss:  1.4576108 ; acc:  0.42594486 ; epoch time:  0.328540563583374\n",
      "eval test...\n",
      "test acc:  0.43467936\n",
      "\n",
      "\n",
      "Epoch:  28 Avg loss:  1.4361635 ; acc:  0.42594486 ; epoch time:  0.33412885665893555\n",
      "eval test...\n",
      "test acc:  0.43467936\n",
      "\n",
      "\n",
      "Epoch:  29 Avg loss:  1.4165 ; acc:  0.42594486 ; epoch time:  0.3155384063720703\n",
      "eval test...\n",
      "test acc:  0.43467936\n",
      "\n",
      "\n",
      "Epoch:  30 Avg loss:  1.3979754 ; acc:  0.42594486 ; epoch time:  0.32596683502197266\n",
      "eval test...\n",
      "test acc:  0.43467936\n",
      "\n",
      "\n",
      "Epoch:  31 Avg loss:  1.3798862 ; acc:  0.42594486 ; epoch time:  0.311542272567749\n",
      "eval test...\n",
      "test acc:  0.43467936\n",
      "\n",
      "\n",
      "Epoch:  32 Avg loss:  1.3620152 ; acc:  0.4269663 ; epoch time:  0.321500301361084\n",
      "eval test...\n",
      "test acc:  0.43467936\n",
      "\n",
      "\n",
      "Epoch:  33 Avg loss:  1.3446412 ; acc:  0.42798775 ; epoch time:  0.33911633491516113\n",
      "eval test...\n",
      "test acc:  0.43705466\n",
      "\n",
      "\n",
      "Epoch:  34 Avg loss:  1.3288348 ; acc:  0.43105212 ; epoch time:  0.3233916759490967\n",
      "eval test...\n",
      "test acc:  0.43705466\n",
      "\n",
      "\n",
      "Epoch:  35 Avg loss:  1.3153611 ; acc:  0.44228807 ; epoch time:  0.3117058277130127\n",
      "eval test...\n",
      "test acc:  0.44655585\n",
      "\n",
      "\n",
      "Epoch:  36 Avg loss:  1.3027606 ; acc:  0.4453524 ; epoch time:  0.3389430046081543\n",
      "eval test...\n",
      "test acc:  0.456057\n",
      "\n",
      "\n",
      "Epoch:  37 Avg loss:  1.2917199 ; acc:  0.45250258 ; epoch time:  0.3294413089752197\n",
      "eval test...\n",
      "test acc:  0.45843232\n",
      "\n",
      "\n",
      "Epoch:  38 Avg loss:  1.2815577 ; acc:  0.4555669 ; epoch time:  0.3199803829193115\n",
      "eval test...\n",
      "test acc:  0.46080762\n",
      "\n",
      "\n",
      "Epoch:  39 Avg loss:  1.2722613 ; acc:  0.46475998 ; epoch time:  0.3028712272644043\n",
      "eval test...\n",
      "test acc:  0.46080762\n",
      "\n",
      "\n",
      "Epoch:  40 Avg loss:  1.2628875 ; acc:  0.46884578 ; epoch time:  0.36315131187438965\n",
      "eval test...\n",
      "test acc:  0.46080762\n",
      "\n",
      "\n",
      "Epoch:  41 Avg loss:  1.2526402 ; acc:  0.46986723 ; epoch time:  0.3135545253753662\n",
      "eval test...\n",
      "test acc:  0.4655582\n",
      "\n",
      "\n",
      "Epoch:  42 Avg loss:  1.2405437 ; acc:  0.47395304 ; epoch time:  0.320751428604126\n",
      "eval test...\n",
      "test acc:  0.47268412\n",
      "\n",
      "\n",
      "Epoch:  43 Avg loss:  1.2275515 ; acc:  0.47191012 ; epoch time:  0.3301866054534912\n",
      "eval test...\n",
      "test acc:  0.4750594\n",
      "\n",
      "\n",
      "Epoch:  44 Avg loss:  1.215206 ; acc:  0.4790603 ; epoch time:  0.3440675735473633\n",
      "eval test...\n",
      "test acc:  0.47981\n",
      "\n",
      "\n",
      "Epoch:  45 Avg loss:  1.2035518 ; acc:  0.485189 ; epoch time:  0.3134734630584717\n",
      "eval test...\n",
      "test acc:  0.4821853\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  46 Avg loss:  1.1927599 ; acc:  0.49846783 ; epoch time:  0.29866671562194824\n",
      "eval test...\n",
      "test acc:  0.48693588\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  47 Avg loss:  1.1842012 ; acc:  0.505618 ; epoch time:  0.34435439109802246\n",
      "eval test...\n",
      "test acc:  0.4893112\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  48 Avg loss:  1.1767995 ; acc:  0.5188969 ; epoch time:  0.3203418254852295\n",
      "eval test...\n",
      "test acc:  0.49881238\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  49 Avg loss:  1.1686895 ; acc:  0.5219612 ; epoch time:  0.337796688079834\n",
      "eval test...\n",
      "test acc:  0.5059383\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  50 Avg loss:  1.1595638 ; acc:  0.52093977 ; epoch time:  0.3092515468597412\n",
      "eval test...\n",
      "test acc:  0.503563\n",
      "\n",
      "\n",
      "Epoch:  51 Avg loss:  1.1503689 ; acc:  0.5168539 ; epoch time:  0.3488779067993164\n",
      "eval test...\n",
      "test acc:  0.50831354\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  52 Avg loss:  1.1412386 ; acc:  0.53013283 ; epoch time:  0.32469964027404785\n",
      "eval test...\n",
      "test acc:  0.51543945\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  53 Avg loss:  1.1323127 ; acc:  0.53524005 ; epoch time:  0.32440900802612305\n",
      "eval test...\n",
      "test acc:  0.51781476\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  54 Avg loss:  1.1233299 ; acc:  0.5393259 ; epoch time:  0.3163580894470215\n",
      "eval test...\n",
      "test acc:  0.50831354\n",
      "\n",
      "\n",
      "Epoch:  55 Avg loss:  1.1133422 ; acc:  0.5434117 ; epoch time:  0.3336467742919922\n",
      "eval test...\n",
      "test acc:  0.5059383\n",
      "\n",
      "\n",
      "Epoch:  56 Avg loss:  1.1033722 ; acc:  0.5434117 ; epoch time:  0.3276524543762207\n",
      "eval test...\n",
      "test acc:  0.51068884\n",
      "\n",
      "\n",
      "Epoch:  57 Avg loss:  1.0948528 ; acc:  0.5423902 ; epoch time:  0.3217172622680664\n",
      "eval test...\n",
      "test acc:  0.51543945\n",
      "\n",
      "\n",
      "Epoch:  58 Avg loss:  1.0873611 ; acc:  0.5485189 ; epoch time:  0.32554030418395996\n",
      "eval test...\n",
      "test acc:  0.51068884\n",
      "\n",
      "\n",
      "Epoch:  59 Avg loss:  1.079842 ; acc:  0.5536262 ; epoch time:  0.3236091136932373\n",
      "eval test...\n",
      "test acc:  0.5344418\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  60 Avg loss:  1.07113 ; acc:  0.55566907 ; epoch time:  0.34520792961120605\n",
      "eval test...\n",
      "test acc:  0.5344418\n",
      "\n",
      "\n",
      "Epoch:  61 Avg loss:  1.0611852 ; acc:  0.55771196 ; epoch time:  0.3158237934112549\n",
      "eval test...\n",
      "test acc:  0.5344418\n",
      "\n",
      "\n",
      "Epoch:  62 Avg loss:  1.051423 ; acc:  0.56281924 ; epoch time:  0.3095853328704834\n",
      "eval test...\n",
      "test acc:  0.5344418\n",
      "\n",
      "\n",
      "Epoch:  63 Avg loss:  1.0424746 ; acc:  0.56486213 ; epoch time:  0.31952834129333496\n",
      "eval test...\n",
      "test acc:  0.5296912\n",
      "\n",
      "\n",
      "Epoch:  64 Avg loss:  1.034138 ; acc:  0.5658836 ; epoch time:  0.3411741256713867\n",
      "eval test...\n",
      "test acc:  0.5344418\n",
      "\n",
      "\n",
      "Epoch:  65 Avg loss:  1.0262097 ; acc:  0.56996936 ; epoch time:  0.3275330066680908\n",
      "eval test...\n",
      "test acc:  0.53919244\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  66 Avg loss:  1.0180628 ; acc:  0.5720123 ; epoch time:  0.3357422351837158\n",
      "eval test...\n",
      "test acc:  0.54156774\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  67 Avg loss:  1.0093272 ; acc:  0.56996936 ; epoch time:  0.3411874771118164\n",
      "eval test...\n",
      "test acc:  0.5463183\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  68 Avg loss:  1.0000776 ; acc:  0.5771195 ; epoch time:  0.31728696823120117\n",
      "eval test...\n",
      "test acc:  0.5486936\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  69 Avg loss:  0.99089575 ; acc:  0.57507664 ; epoch time:  0.33212733268737793\n",
      "eval test...\n",
      "test acc:  0.5510689\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  70 Avg loss:  0.98236597 ; acc:  0.5791624 ; epoch time:  0.3233530521392822\n",
      "eval test...\n",
      "test acc:  0.5486936\n",
      "\n",
      "\n",
      "Epoch:  71 Avg loss:  0.97423714 ; acc:  0.5822268 ; epoch time:  0.33992838859558105\n",
      "eval test...\n",
      "test acc:  0.5558195\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  72 Avg loss:  0.9664233 ; acc:  0.59346277 ; epoch time:  0.314197301864624\n",
      "eval test...\n",
      "test acc:  0.56294537\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  73 Avg loss:  0.95848215 ; acc:  0.59754854 ; epoch time:  0.3444030284881592\n",
      "eval test...\n",
      "test acc:  0.5605701\n",
      "\n",
      "\n",
      "Epoch:  74 Avg loss:  0.9503245 ; acc:  0.59550565 ; epoch time:  0.32346463203430176\n",
      "eval test...\n",
      "test acc:  0.56294537\n",
      "\n",
      "\n",
      "Epoch:  75 Avg loss:  0.942419 ; acc:  0.6016343 ; epoch time:  0.3574185371398926\n",
      "eval test...\n",
      "test acc:  0.5653207\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  76 Avg loss:  0.93489087 ; acc:  0.59857 ; epoch time:  0.32490038871765137\n",
      "eval test...\n",
      "test acc:  0.5724466\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  77 Avg loss:  0.9278976 ; acc:  0.6128703 ; epoch time:  0.3214991092681885\n",
      "eval test...\n",
      "test acc:  0.567696\n",
      "\n",
      "\n",
      "Epoch:  78 Avg loss:  0.92113304 ; acc:  0.61593467 ; epoch time:  0.32341909408569336\n",
      "eval test...\n",
      "test acc:  0.567696\n",
      "\n",
      "\n",
      "Epoch:  79 Avg loss:  0.9144387 ; acc:  0.618999 ; epoch time:  0.33875155448913574\n",
      "eval test...\n",
      "test acc:  0.5653207\n",
      "\n",
      "\n",
      "Epoch:  80 Avg loss:  0.90773654 ; acc:  0.62512773 ; epoch time:  0.30623412132263184\n",
      "eval test...\n",
      "test acc:  0.5748219\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  81 Avg loss:  0.9009796 ; acc:  0.6271706 ; epoch time:  0.32567524909973145\n",
      "eval test...\n",
      "test acc:  0.567696\n",
      "\n",
      "\n",
      "Epoch:  82 Avg loss:  0.89422375 ; acc:  0.6312564 ; epoch time:  0.3346736431121826\n",
      "eval test...\n",
      "test acc:  0.5653207\n",
      "\n",
      "\n",
      "Epoch:  83 Avg loss:  0.8875671 ; acc:  0.6271706 ; epoch time:  0.33354806900024414\n",
      "eval test...\n",
      "test acc:  0.5700713\n",
      "\n",
      "\n",
      "Epoch:  84 Avg loss:  0.8809227 ; acc:  0.6332993 ; epoch time:  0.32837533950805664\n",
      "eval test...\n",
      "test acc:  0.5653207\n",
      "\n",
      "\n",
      "Epoch:  85 Avg loss:  0.8742758 ; acc:  0.639428 ; epoch time:  0.3295860290527344\n",
      "eval test...\n",
      "test acc:  0.5724466\n",
      "\n",
      "\n",
      "Epoch:  86 Avg loss:  0.86766404 ; acc:  0.6435138 ; epoch time:  0.3075387477874756\n",
      "eval test...\n",
      "test acc:  0.5724466\n",
      "\n",
      "\n",
      "Epoch:  87 Avg loss:  0.86105543 ; acc:  0.6465782 ; epoch time:  0.35901451110839844\n",
      "eval test...\n",
      "test acc:  0.5795725\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  88 Avg loss:  0.85469353 ; acc:  0.6486211 ; epoch time:  0.3270084857940674\n",
      "eval test...\n",
      "test acc:  0.58432305\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  89 Avg loss:  0.8484592 ; acc:  0.6516854 ; epoch time:  0.3192019462585449\n",
      "eval test...\n",
      "test acc:  0.58669835\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  90 Avg loss:  0.8423481 ; acc:  0.6537283 ; epoch time:  0.34006381034851074\n",
      "eval test...\n",
      "test acc:  0.59144896\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  91 Avg loss:  0.83626866 ; acc:  0.65474975 ; epoch time:  0.3321828842163086\n",
      "eval test...\n",
      "test acc:  0.59144896\n",
      "\n",
      "\n",
      "Epoch:  92 Avg loss:  0.83021337 ; acc:  0.65270686 ; epoch time:  0.33190178871154785\n",
      "eval test...\n",
      "test acc:  0.59382427\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  93 Avg loss:  0.82424253 ; acc:  0.6537283 ; epoch time:  0.3520383834838867\n",
      "eval test...\n",
      "test acc:  0.5961996\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  94 Avg loss:  0.81839854 ; acc:  0.65781415 ; epoch time:  0.34746503829956055\n",
      "eval test...\n",
      "test acc:  0.59382427\n",
      "\n",
      "\n",
      "Epoch:  95 Avg loss:  0.81268895 ; acc:  0.6588356 ; epoch time:  0.3312103748321533\n",
      "eval test...\n",
      "test acc:  0.5985749\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  96 Avg loss:  0.80711806 ; acc:  0.6608785 ; epoch time:  0.31432628631591797\n",
      "eval test...\n",
      "test acc:  0.60807604\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  97 Avg loss:  0.80160457 ; acc:  0.6608785 ; epoch time:  0.3121302127838135\n",
      "eval test...\n",
      "test acc:  0.60807604\n",
      "\n",
      "\n",
      "Epoch:  98 Avg loss:  0.7961459 ; acc:  0.6659857 ; epoch time:  0.3346419334411621\n",
      "eval test...\n",
      "test acc:  0.61045134\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  99 Avg loss:  0.7907409 ; acc:  0.66496426 ; epoch time:  0.3227205276489258\n",
      "eval test...\n",
      "test acc:  0.60807604\n",
      "\n",
      "\n",
      "Epoch:  100 Avg loss:  0.7853409 ; acc:  0.6659857 ; epoch time:  0.3094909191131592\n",
      "eval test...\n",
      "test acc:  0.61045134\n",
      "\n",
      "\n",
      "Epoch:  101 Avg loss:  0.78006345 ; acc:  0.66700715 ; epoch time:  0.3216671943664551\n",
      "eval test...\n",
      "test acc:  0.61282665\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  102 Avg loss:  0.7748432 ; acc:  0.66700715 ; epoch time:  0.316821813583374\n",
      "eval test...\n",
      "test acc:  0.6199525\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  103 Avg loss:  0.7696169 ; acc:  0.67007154 ; epoch time:  0.34072065353393555\n",
      "eval test...\n",
      "test acc:  0.6223278\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  104 Avg loss:  0.7643744 ; acc:  0.67211443 ; epoch time:  0.3170039653778076\n",
      "eval test...\n",
      "test acc:  0.6223278\n",
      "\n",
      "\n",
      "Epoch:  105 Avg loss:  0.7591023 ; acc:  0.671093 ; epoch time:  0.3355083465576172\n",
      "eval test...\n",
      "test acc:  0.6247031\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  106 Avg loss:  0.75378025 ; acc:  0.6741573 ; epoch time:  0.3604605197906494\n",
      "eval test...\n",
      "test acc:  0.6223278\n",
      "\n",
      "\n",
      "Epoch:  107 Avg loss:  0.7484489 ; acc:  0.6762002 ; epoch time:  0.33211851119995117\n",
      "eval test...\n",
      "test acc:  0.6223278\n",
      "\n",
      "\n",
      "Epoch:  108 Avg loss:  0.74303234 ; acc:  0.67824316 ; epoch time:  0.31720685958862305\n",
      "eval test...\n",
      "test acc:  0.6223278\n",
      "\n",
      "\n",
      "Epoch:  109 Avg loss:  0.7377717 ; acc:  0.6792646 ; epoch time:  0.31677842140197754\n",
      "eval test...\n",
      "test acc:  0.6247031\n",
      "\n",
      "\n",
      "Epoch:  110 Avg loss:  0.7326318 ; acc:  0.6762002 ; epoch time:  0.3339273929595947\n",
      "eval test...\n",
      "test acc:  0.6247031\n",
      "\n",
      "\n",
      "Epoch:  111 Avg loss:  0.7275858 ; acc:  0.6762002 ; epoch time:  0.28894495964050293\n",
      "eval test...\n",
      "test acc:  0.6247031\n",
      "\n",
      "\n",
      "Epoch:  112 Avg loss:  0.7226735 ; acc:  0.67722166 ; epoch time:  0.327042818069458\n",
      "eval test...\n",
      "test acc:  0.6223278\n",
      "\n",
      "\n",
      "Epoch:  113 Avg loss:  0.71790075 ; acc:  0.6762002 ; epoch time:  0.3152041435241699\n",
      "eval test...\n",
      "test acc:  0.6223278\n",
      "\n",
      "\n",
      "Epoch:  114 Avg loss:  0.7132387 ; acc:  0.6741573 ; epoch time:  0.33289384841918945\n",
      "eval test...\n",
      "test acc:  0.6247031\n",
      "\n",
      "\n",
      "Epoch:  115 Avg loss:  0.70858556 ; acc:  0.68028605 ; epoch time:  0.32555508613586426\n",
      "eval test...\n",
      "test acc:  0.6199525\n",
      "\n",
      "\n",
      "Epoch:  116 Avg loss:  0.70394164 ; acc:  0.6843718 ; epoch time:  0.3163926601409912\n",
      "eval test...\n",
      "test acc:  0.6199525\n",
      "\n",
      "\n",
      "Epoch:  117 Avg loss:  0.6993264 ; acc:  0.6813075 ; epoch time:  0.3246645927429199\n",
      "eval test...\n",
      "test acc:  0.6223278\n",
      "\n",
      "\n",
      "Epoch:  118 Avg loss:  0.69466966 ; acc:  0.6813075 ; epoch time:  0.312375545501709\n",
      "eval test...\n",
      "test acc:  0.6199525\n",
      "\n",
      "\n",
      "Epoch:  119 Avg loss:  0.6900412 ; acc:  0.6843718 ; epoch time:  0.3231348991394043\n",
      "eval test...\n",
      "test acc:  0.6270784\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  120 Avg loss:  0.6854766 ; acc:  0.68232894 ; epoch time:  0.33505940437316895\n",
      "eval test...\n",
      "test acc:  0.6223278\n",
      "\n",
      "\n",
      "Epoch:  121 Avg loss:  0.68102545 ; acc:  0.6833504 ; epoch time:  0.33390307426452637\n",
      "eval test...\n",
      "test acc:  0.6223278\n",
      "\n",
      "\n",
      "Epoch:  122 Avg loss:  0.6765643 ; acc:  0.6853933 ; epoch time:  0.3446044921875\n",
      "eval test...\n",
      "test acc:  0.6223278\n",
      "\n",
      "\n",
      "Epoch:  123 Avg loss:  0.6721188 ; acc:  0.68743616 ; epoch time:  0.31584954261779785\n",
      "eval test...\n",
      "test acc:  0.6199525\n",
      "\n",
      "\n",
      "Epoch:  124 Avg loss:  0.6677838 ; acc:  0.691522 ; epoch time:  0.3319065570831299\n",
      "eval test...\n",
      "test acc:  0.6223278\n",
      "\n",
      "\n",
      "Epoch:  125 Avg loss:  0.6635255 ; acc:  0.69254345 ; epoch time:  0.340923547744751\n",
      "eval test...\n",
      "test acc:  0.6199525\n",
      "\n",
      "\n",
      "Epoch:  126 Avg loss:  0.6594035 ; acc:  0.69254345 ; epoch time:  0.3543241024017334\n",
      "eval test...\n",
      "test acc:  0.6270784\n",
      "\n",
      "\n",
      "Epoch:  127 Avg loss:  0.6552479 ; acc:  0.6935649 ; epoch time:  0.3349134922027588\n",
      "eval test...\n",
      "test acc:  0.6294537\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  128 Avg loss:  0.6510542 ; acc:  0.6966292 ; epoch time:  0.3259928226470947\n",
      "eval test...\n",
      "test acc:  0.6294537\n",
      "\n",
      "\n",
      "Epoch:  129 Avg loss:  0.64713943 ; acc:  0.70275795 ; epoch time:  0.3522613048553467\n",
      "eval test...\n",
      "test acc:  0.6270784\n",
      "\n",
      "\n",
      "Epoch:  130 Avg loss:  0.6433106 ; acc:  0.7017365 ; epoch time:  0.3311033248901367\n",
      "eval test...\n",
      "test acc:  0.6294537\n",
      "\n",
      "\n",
      "Epoch:  131 Avg loss:  0.63951576 ; acc:  0.70275795 ; epoch time:  0.3525428771972656\n",
      "eval test...\n",
      "test acc:  0.6247031\n",
      "\n",
      "\n",
      "Epoch:  132 Avg loss:  0.63578737 ; acc:  0.7017365 ; epoch time:  0.31843113899230957\n",
      "eval test...\n",
      "test acc:  0.6294537\n",
      "\n",
      "\n",
      "Epoch:  133 Avg loss:  0.63220793 ; acc:  0.70071507 ; epoch time:  0.3402392864227295\n",
      "eval test...\n",
      "test acc:  0.6365796\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  134 Avg loss:  0.62872624 ; acc:  0.70275795 ; epoch time:  0.3210327625274658\n",
      "eval test...\n",
      "test acc:  0.6342043\n",
      "\n",
      "\n",
      "Epoch:  135 Avg loss:  0.6253061 ; acc:  0.7017365 ; epoch time:  0.3284296989440918\n",
      "eval test...\n",
      "test acc:  0.6342043\n",
      "\n",
      "\n",
      "Epoch:  136 Avg loss:  0.6219512 ; acc:  0.7078652 ; epoch time:  0.32361650466918945\n",
      "eval test...\n",
      "test acc:  0.6365796\n",
      "\n",
      "\n",
      "Epoch:  137 Avg loss:  0.6186756 ; acc:  0.7088866 ; epoch time:  0.32927942276000977\n",
      "eval test...\n",
      "test acc:  0.6342043\n",
      "\n",
      "\n",
      "Epoch:  138 Avg loss:  0.61545604 ; acc:  0.7078652 ; epoch time:  0.35722923278808594\n",
      "eval test...\n",
      "test acc:  0.6389549\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  139 Avg loss:  0.6122329 ; acc:  0.7078652 ; epoch time:  0.3354921340942383\n",
      "eval test...\n",
      "test acc:  0.6413302\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  140 Avg loss:  0.6090483 ; acc:  0.71297246 ; epoch time:  0.3270082473754883\n",
      "eval test...\n",
      "test acc:  0.6437055\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  141 Avg loss:  0.60590607 ; acc:  0.711951 ; epoch time:  0.30559253692626953\n",
      "eval test...\n",
      "test acc:  0.6413302\n",
      "\n",
      "\n",
      "Epoch:  142 Avg loss:  0.60279465 ; acc:  0.7139939 ; epoch time:  0.34133076667785645\n",
      "eval test...\n",
      "test acc:  0.6460808\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  143 Avg loss:  0.59980357 ; acc:  0.711951 ; epoch time:  0.341597318649292\n",
      "eval test...\n",
      "test acc:  0.6484561\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  144 Avg loss:  0.59690136 ; acc:  0.7211441 ; epoch time:  0.31223320960998535\n",
      "eval test...\n",
      "test acc:  0.6389549\n",
      "\n",
      "\n",
      "Epoch:  145 Avg loss:  0.5939858 ; acc:  0.71705824 ; epoch time:  0.32180285453796387\n",
      "eval test...\n",
      "test acc:  0.6437055\n",
      "\n",
      "\n",
      "Epoch:  146 Avg loss:  0.59108585 ; acc:  0.71910113 ; epoch time:  0.3335988521575928\n",
      "eval test...\n",
      "test acc:  0.6437055\n",
      "\n",
      "\n",
      "Epoch:  147 Avg loss:  0.5882276 ; acc:  0.7201226 ; epoch time:  0.3148677349090576\n",
      "eval test...\n",
      "test acc:  0.6460808\n",
      "\n",
      "\n",
      "Epoch:  148 Avg loss:  0.58545333 ; acc:  0.7221655 ; epoch time:  0.31386709213256836\n",
      "eval test...\n",
      "test acc:  0.6437055\n",
      "\n",
      "\n",
      "Epoch:  149 Avg loss:  0.58276945 ; acc:  0.72318697 ; epoch time:  0.3577768802642822\n",
      "eval test...\n",
      "test acc:  0.6460808\n",
      "\n",
      "\n",
      "Epoch:  150 Avg loss:  0.5801242 ; acc:  0.72522986 ; epoch time:  0.32317471504211426\n",
      "eval test...\n",
      "test acc:  0.6437055\n",
      "\n",
      "\n",
      "Epoch:  151 Avg loss:  0.5776411 ; acc:  0.72522986 ; epoch time:  0.3385121822357178\n",
      "eval test...\n",
      "test acc:  0.6508314\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  152 Avg loss:  0.57533926 ; acc:  0.7303371 ; epoch time:  0.31290626525878906\n",
      "eval test...\n",
      "test acc:  0.6460808\n",
      "\n",
      "\n",
      "Epoch:  153 Avg loss:  0.5732895 ; acc:  0.73238003 ; epoch time:  0.31645822525024414\n",
      "eval test...\n",
      "test acc:  0.6508314\n",
      "\n",
      "\n",
      "Epoch:  154 Avg loss:  0.5710853 ; acc:  0.7303371 ; epoch time:  0.33047008514404297\n",
      "eval test...\n",
      "test acc:  0.6508314\n",
      "\n",
      "\n",
      "Epoch:  155 Avg loss:  0.56834924 ; acc:  0.73544437 ; epoch time:  0.335127592086792\n",
      "eval test...\n",
      "test acc:  0.6508314\n",
      "\n",
      "\n",
      "Epoch:  156 Avg loss:  0.5654279 ; acc:  0.7385087 ; epoch time:  0.34010839462280273\n",
      "eval test...\n",
      "test acc:  0.6484561\n",
      "\n",
      "\n",
      "Epoch:  157 Avg loss:  0.56318706 ; acc:  0.7405516 ; epoch time:  0.3138134479522705\n",
      "eval test...\n",
      "test acc:  0.6484561\n",
      "\n",
      "\n",
      "Epoch:  158 Avg loss:  0.56130636 ; acc:  0.7405516 ; epoch time:  0.33135080337524414\n",
      "eval test...\n",
      "test acc:  0.6508314\n",
      "\n",
      "\n",
      "Epoch:  159 Avg loss:  0.55930024 ; acc:  0.74259454 ; epoch time:  0.3363499641418457\n",
      "eval test...\n",
      "test acc:  0.6508314\n",
      "\n",
      "\n",
      "Epoch:  160 Avg loss:  0.55678463 ; acc:  0.7405516 ; epoch time:  0.3304440975189209\n",
      "eval test...\n",
      "test acc:  0.6508314\n",
      "\n",
      "\n",
      "Epoch:  161 Avg loss:  0.55426395 ; acc:  0.73953015 ; epoch time:  0.3265237808227539\n",
      "eval test...\n",
      "test acc:  0.6508314\n",
      "\n",
      "\n",
      "Epoch:  162 Avg loss:  0.5522374 ; acc:  0.74259454 ; epoch time:  0.3175082206726074\n",
      "eval test...\n",
      "test acc:  0.6532067\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  163 Avg loss:  0.5504309 ; acc:  0.7466803 ; epoch time:  0.31854772567749023\n",
      "eval test...\n",
      "test acc:  0.6532067\n",
      "\n",
      "\n",
      "Epoch:  164 Avg loss:  0.54845655 ; acc:  0.7446374 ; epoch time:  0.35337328910827637\n",
      "eval test...\n",
      "test acc:  0.6532067\n",
      "\n",
      "\n",
      "Epoch:  165 Avg loss:  0.546449 ; acc:  0.74974465 ; epoch time:  0.3450429439544678\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  166 Avg loss:  0.5441643 ; acc:  0.7487232 ; epoch time:  0.3180878162384033\n",
      "eval test...\n",
      "test acc:  0.6532067\n",
      "\n",
      "\n",
      "Epoch:  167 Avg loss:  0.5418914 ; acc:  0.7487232 ; epoch time:  0.3401970863342285\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  168 Avg loss:  0.5399471 ; acc:  0.7466803 ; epoch time:  0.3449680805206299\n",
      "eval test...\n",
      "test acc:  0.65795726\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  169 Avg loss:  0.5381715 ; acc:  0.74770176 ; epoch time:  0.34575986862182617\n",
      "eval test...\n",
      "test acc:  0.6484561\n",
      "\n",
      "\n",
      "Epoch:  170 Avg loss:  0.5363953 ; acc:  0.7507661 ; epoch time:  0.32834696769714355\n",
      "eval test...\n",
      "test acc:  0.66033256\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  171 Avg loss:  0.5344206 ; acc:  0.74770176 ; epoch time:  0.3256833553314209\n",
      "eval test...\n",
      "test acc:  0.6484561\n",
      "\n",
      "\n",
      "Epoch:  172 Avg loss:  0.53242445 ; acc:  0.74974465 ; epoch time:  0.3379943370819092\n",
      "eval test...\n",
      "test acc:  0.66033256\n",
      "\n",
      "\n",
      "Epoch:  173 Avg loss:  0.5300851 ; acc:  0.74974465 ; epoch time:  0.3287808895111084\n",
      "eval test...\n",
      "test acc:  0.6508314\n",
      "\n",
      "\n",
      "Epoch:  174 Avg loss:  0.5277517 ; acc:  0.74974465 ; epoch time:  0.3333089351654053\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  175 Avg loss:  0.52556854 ; acc:  0.74974465 ; epoch time:  0.3201577663421631\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  176 Avg loss:  0.52352893 ; acc:  0.7466803 ; epoch time:  0.323319673538208\n",
      "eval test...\n",
      "test acc:  0.6508314\n",
      "\n",
      "\n",
      "Epoch:  177 Avg loss:  0.5216769 ; acc:  0.75280905 ; epoch time:  0.32228732109069824\n",
      "eval test...\n",
      "test acc:  0.66033256\n",
      "\n",
      "\n",
      "Epoch:  178 Avg loss:  0.52003455 ; acc:  0.7507661 ; epoch time:  0.37108731269836426\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  179 Avg loss:  0.518845 ; acc:  0.7609806 ; epoch time:  0.3265068531036377\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  180 Avg loss:  0.5177676 ; acc:  0.7538305 ; epoch time:  0.34908056259155273\n",
      "eval test...\n",
      "test acc:  0.6508314\n",
      "\n",
      "\n",
      "Epoch:  181 Avg loss:  0.5156267 ; acc:  0.7630235 ; epoch time:  0.3195209503173828\n",
      "eval test...\n",
      "test acc:  0.66508317\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  182 Avg loss:  0.51220024 ; acc:  0.7568948 ; epoch time:  0.3363051414489746\n",
      "eval test...\n",
      "test acc:  0.6532067\n",
      "\n",
      "\n",
      "Epoch:  183 Avg loss:  0.5093912 ; acc:  0.7568948 ; epoch time:  0.31841230392456055\n",
      "eval test...\n",
      "test acc:  0.6532067\n",
      "\n",
      "\n",
      "Epoch:  184 Avg loss:  0.5080963 ; acc:  0.7681308 ; epoch time:  0.32857322692871094\n",
      "eval test...\n",
      "test acc:  0.6508314\n",
      "\n",
      "\n",
      "Epoch:  185 Avg loss:  0.5068178 ; acc:  0.764045 ; epoch time:  0.31905269622802734\n",
      "eval test...\n",
      "test acc:  0.6532067\n",
      "\n",
      "\n",
      "Epoch:  186 Avg loss:  0.5042219 ; acc:  0.7691522 ; epoch time:  0.352506160736084\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  187 Avg loss:  0.5016785 ; acc:  0.7630235 ; epoch time:  0.32869648933410645\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  188 Avg loss:  0.5000161 ; acc:  0.76710933 ; epoch time:  0.32651519775390625\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  189 Avg loss:  0.4984435 ; acc:  0.7711951 ; epoch time:  0.35522007942199707\n",
      "eval test...\n",
      "test acc:  0.65795726\n",
      "\n",
      "\n",
      "Epoch:  190 Avg loss:  0.4965373 ; acc:  0.7742595 ; epoch time:  0.3401055335998535\n",
      "eval test...\n",
      "test acc:  0.65795726\n",
      "\n",
      "\n",
      "Epoch:  191 Avg loss:  0.49428093 ; acc:  0.77221656 ; epoch time:  0.32230687141418457\n",
      "eval test...\n",
      "test acc:  0.65795726\n",
      "\n",
      "\n",
      "Epoch:  192 Avg loss:  0.49208933 ; acc:  0.773238 ; epoch time:  0.3526773452758789\n",
      "eval test...\n",
      "test acc:  0.65795726\n",
      "\n",
      "\n",
      "Epoch:  193 Avg loss:  0.49012524 ; acc:  0.7763024 ; epoch time:  0.3557584285736084\n",
      "eval test...\n",
      "test acc:  0.65795726\n",
      "\n",
      "\n",
      "Epoch:  194 Avg loss:  0.48832735 ; acc:  0.77732384 ; epoch time:  0.31822967529296875\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  195 Avg loss:  0.48656067 ; acc:  0.77732384 ; epoch time:  0.34909558296203613\n",
      "eval test...\n",
      "test acc:  0.66270787\n",
      "\n",
      "\n",
      "Epoch:  196 Avg loss:  0.4847181 ; acc:  0.7814096 ; epoch time:  0.32927918434143066\n",
      "eval test...\n",
      "test acc:  0.6508314\n",
      "\n",
      "\n",
      "Epoch:  197 Avg loss:  0.48287502 ; acc:  0.784474 ; epoch time:  0.31562304496765137\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  198 Avg loss:  0.4810771 ; acc:  0.784474 ; epoch time:  0.3696708679199219\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  199 Avg loss:  0.47913307 ; acc:  0.78549546 ; epoch time:  0.3300473690032959\n",
      "eval test...\n",
      "test acc:  0.65795726\n",
      "\n",
      "\n",
      "Epoch:  200 Avg loss:  0.47751632 ; acc:  0.7916241 ; epoch time:  0.3163034915924072\n",
      "eval test...\n",
      "test acc:  0.6460808\n",
      "\n",
      "\n",
      "Epoch:  201 Avg loss:  0.4760378 ; acc:  0.78753835 ; epoch time:  0.3312997817993164\n",
      "eval test...\n",
      "test acc:  0.65795726\n",
      "\n",
      "\n",
      "Epoch:  202 Avg loss:  0.47420132 ; acc:  0.78958124 ; epoch time:  0.3551783561706543\n",
      "eval test...\n",
      "test acc:  0.6484561\n",
      "\n",
      "\n",
      "Epoch:  203 Avg loss:  0.47188365 ; acc:  0.7885598 ; epoch time:  0.3225412368774414\n",
      "eval test...\n",
      "test acc:  0.66508317\n",
      "\n",
      "\n",
      "Epoch:  204 Avg loss:  0.4693529 ; acc:  0.79468846 ; epoch time:  0.31497764587402344\n",
      "eval test...\n",
      "test acc:  0.6413302\n",
      "\n",
      "\n",
      "Epoch:  205 Avg loss:  0.46667457 ; acc:  0.793667 ; epoch time:  0.3599281311035156\n",
      "eval test...\n",
      "test acc:  0.6532067\n",
      "\n",
      "\n",
      "Epoch:  206 Avg loss:  0.4644061 ; acc:  0.79570997 ; epoch time:  0.3306598663330078\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  207 Avg loss:  0.462751 ; acc:  0.7967314 ; epoch time:  0.32219815254211426\n",
      "eval test...\n",
      "test acc:  0.6484561\n",
      "\n",
      "\n",
      "Epoch:  208 Avg loss:  0.46127903 ; acc:  0.7987743 ; epoch time:  0.3302173614501953\n",
      "eval test...\n",
      "test acc:  0.66033256\n",
      "\n",
      "\n",
      "Epoch:  209 Avg loss:  0.46010938 ; acc:  0.8038815 ; epoch time:  0.3305354118347168\n",
      "eval test...\n",
      "test acc:  0.6365796\n",
      "\n",
      "\n",
      "Epoch:  210 Avg loss:  0.45832783 ; acc:  0.79979575 ; epoch time:  0.3103785514831543\n",
      "eval test...\n",
      "test acc:  0.65795726\n",
      "\n",
      "\n",
      "Epoch:  211 Avg loss:  0.45672128 ; acc:  0.8059245 ; epoch time:  0.33568811416625977\n",
      "eval test...\n",
      "test acc:  0.6342043\n",
      "\n",
      "\n",
      "Epoch:  212 Avg loss:  0.45379078 ; acc:  0.8038815 ; epoch time:  0.3367326259613037\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  213 Avg loss:  0.4506615 ; acc:  0.81409603 ; epoch time:  0.3197760581970215\n",
      "eval test...\n",
      "test acc:  0.6413302\n",
      "\n",
      "\n",
      "Epoch:  214 Avg loss:  0.44852528 ; acc:  0.8089888 ; epoch time:  0.31475019454956055\n",
      "eval test...\n",
      "test acc:  0.6532067\n",
      "\n",
      "\n",
      "Epoch:  215 Avg loss:  0.4467855 ; acc:  0.8089888 ; epoch time:  0.3286275863647461\n",
      "eval test...\n",
      "test acc:  0.6508314\n",
      "\n",
      "\n",
      "Epoch:  216 Avg loss:  0.44521222 ; acc:  0.8171604 ; epoch time:  0.31995391845703125\n",
      "eval test...\n",
      "test acc:  0.6365796\n",
      "\n",
      "\n",
      "Epoch:  217 Avg loss:  0.44423318 ; acc:  0.8130746 ; epoch time:  0.3358151912689209\n",
      "eval test...\n",
      "test acc:  0.65795726\n",
      "\n",
      "\n",
      "Epoch:  218 Avg loss:  0.44230032 ; acc:  0.8171604 ; epoch time:  0.33630824089050293\n",
      "eval test...\n",
      "test acc:  0.6389549\n",
      "\n",
      "\n",
      "Epoch:  219 Avg loss:  0.43992704 ; acc:  0.8110317 ; epoch time:  0.3268249034881592\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  220 Avg loss:  0.43740356 ; acc:  0.82022476 ; epoch time:  0.32248687744140625\n",
      "eval test...\n",
      "test acc:  0.6437055\n",
      "\n",
      "\n",
      "Epoch:  221 Avg loss:  0.4344477 ; acc:  0.8212462 ; epoch time:  0.3331758975982666\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  222 Avg loss:  0.4323099 ; acc:  0.82431054 ; epoch time:  0.3282809257507324\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  223 Avg loss:  0.43050408 ; acc:  0.82431054 ; epoch time:  0.3367800712585449\n",
      "eval test...\n",
      "test acc:  0.6508314\n",
      "\n",
      "\n",
      "Epoch:  224 Avg loss:  0.428359 ; acc:  0.82226765 ; epoch time:  0.3166618347167969\n",
      "eval test...\n",
      "test acc:  0.6484561\n",
      "\n",
      "\n",
      "Epoch:  225 Avg loss:  0.42655247 ; acc:  0.82226765 ; epoch time:  0.33670997619628906\n",
      "eval test...\n",
      "test acc:  0.65558195\n",
      "\n",
      "\n",
      "Epoch:  226 Avg loss:  0.4249289 ; acc:  0.825332 ; epoch time:  0.3153367042541504\n",
      "eval test...\n",
      "test acc:  0.6532067\n",
      "\n",
      "\n",
      "Epoch:  227 Avg loss:  0.42328954 ; acc:  0.8375894 ; epoch time:  0.34171175956726074\n",
      "eval test...\n",
      "test acc:  0.6484561\n",
      "\n",
      "\n",
      "Epoch:  228 Avg loss:  0.4220687 ; acc:  0.82635343 ; epoch time:  0.33037352561950684\n",
      "eval test...\n",
      "test acc:  0.6674585\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  229 Avg loss:  0.4216057 ; acc:  0.8355465 ; epoch time:  0.34027552604675293\n",
      "eval test...\n",
      "test acc:  0.6508314\n",
      "\n",
      "\n",
      "Epoch:  230 Avg loss:  0.42151883 ; acc:  0.8232891 ; epoch time:  0.3094482421875\n",
      "eval test...\n",
      "test acc:  0.66033256\n",
      "\n",
      "\n",
      "Epoch:  231 Avg loss:  0.41956908 ; acc:  0.83248216 ; epoch time:  0.32540178298950195\n",
      "eval test...\n",
      "test acc:  0.6532067\n",
      "\n",
      "\n",
      "Epoch:  232 Avg loss:  0.41508785 ; acc:  0.83452505 ; epoch time:  0.3221447467803955\n",
      "eval test...\n",
      "test acc:  0.66270787\n",
      "\n",
      "\n",
      "Epoch:  233 Avg loss:  0.41133732 ; acc:  0.8355465 ; epoch time:  0.34035420417785645\n",
      "eval test...\n",
      "test acc:  0.66033256\n",
      "\n",
      "\n",
      "Epoch:  234 Avg loss:  0.41009185 ; acc:  0.8386109 ; epoch time:  0.31358909606933594\n",
      "eval test...\n",
      "test acc:  0.66033256\n",
      "\n",
      "\n",
      "Epoch:  235 Avg loss:  0.40998325 ; acc:  0.8406538 ; epoch time:  0.30455493927001953\n",
      "eval test...\n",
      "test acc:  0.66508317\n",
      "\n",
      "\n",
      "Epoch:  236 Avg loss:  0.40895227 ; acc:  0.83656794 ; epoch time:  0.32560300827026367\n",
      "eval test...\n",
      "test acc:  0.66033256\n",
      "\n",
      "\n",
      "Epoch:  237 Avg loss:  0.4059162 ; acc:  0.83963233 ; epoch time:  0.31704044342041016\n",
      "eval test...\n",
      "test acc:  0.6674585\n",
      "\n",
      "\n",
      "Epoch:  238 Avg loss:  0.40247068 ; acc:  0.8437181 ; epoch time:  0.33513331413269043\n",
      "eval test...\n",
      "test acc:  0.66270787\n",
      "\n",
      "\n",
      "Epoch:  239 Avg loss:  0.40090674 ; acc:  0.84269667 ; epoch time:  0.31194281578063965\n",
      "eval test...\n",
      "test acc:  0.66508317\n",
      "\n",
      "\n",
      "Epoch:  240 Avg loss:  0.40099844 ; acc:  0.8437181 ; epoch time:  0.31995177268981934\n",
      "eval test...\n",
      "test acc:  0.6674585\n",
      "\n",
      "\n",
      "Epoch:  241 Avg loss:  0.40026692 ; acc:  0.84269667 ; epoch time:  0.3404712677001953\n",
      "eval test...\n",
      "test acc:  0.66508317\n",
      "\n",
      "\n",
      "Epoch:  242 Avg loss:  0.3977447 ; acc:  0.8478039 ; epoch time:  0.3059091567993164\n",
      "eval test...\n",
      "test acc:  0.6745843\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  243 Avg loss:  0.3945114 ; acc:  0.8508683 ; epoch time:  0.3372230529785156\n",
      "eval test...\n",
      "test acc:  0.66270787\n",
      "\n",
      "\n",
      "Epoch:  244 Avg loss:  0.39131442 ; acc:  0.8529112 ; epoch time:  0.3338747024536133\n",
      "eval test...\n",
      "test acc:  0.6674585\n",
      "\n",
      "\n",
      "Epoch:  245 Avg loss:  0.38995898 ; acc:  0.8508683 ; epoch time:  0.3363151550292969\n",
      "eval test...\n",
      "test acc:  0.6745843\n",
      "\n",
      "\n",
      "Epoch:  246 Avg loss:  0.38938957 ; acc:  0.8518897 ; epoch time:  0.3215749263763428\n",
      "eval test...\n",
      "test acc:  0.66508317\n",
      "\n",
      "\n",
      "Epoch:  247 Avg loss:  0.3885253 ; acc:  0.8529112 ; epoch time:  0.3382294178009033\n",
      "eval test...\n",
      "test acc:  0.6722091\n",
      "\n",
      "\n",
      "Epoch:  248 Avg loss:  0.38605514 ; acc:  0.8580184 ; epoch time:  0.32236456871032715\n",
      "eval test...\n",
      "test acc:  0.66270787\n",
      "\n",
      "\n",
      "Epoch:  249 Avg loss:  0.38266757 ; acc:  0.86210424 ; epoch time:  0.3204488754272461\n",
      "eval test...\n",
      "test acc:  0.6698338\n",
      "\n",
      "\n",
      "Epoch:  250 Avg loss:  0.3807631 ; acc:  0.86006135 ; epoch time:  0.32685351371765137\n",
      "eval test...\n",
      "test acc:  0.6745843\n",
      "\n",
      "\n",
      "Epoch:  251 Avg loss:  0.3801226 ; acc:  0.85699695 ; epoch time:  0.3242006301879883\n",
      "eval test...\n",
      "test acc:  0.6722091\n",
      "\n",
      "\n",
      "Epoch:  252 Avg loss:  0.38069877 ; acc:  0.86006135 ; epoch time:  0.3439767360687256\n",
      "eval test...\n",
      "test acc:  0.6722091\n",
      "\n",
      "\n",
      "Epoch:  253 Avg loss:  0.3802824 ; acc:  0.8518897 ; epoch time:  0.3118016719818115\n",
      "eval test...\n",
      "test acc:  0.66270787\n",
      "\n",
      "\n",
      "Epoch:  254 Avg loss:  0.3764902 ; acc:  0.86006135 ; epoch time:  0.34169483184814453\n",
      "eval test...\n",
      "test acc:  0.6745843\n",
      "\n",
      "\n",
      "Epoch:  255 Avg loss:  0.3722008 ; acc:  0.8651686 ; epoch time:  0.3409457206726074\n",
      "eval test...\n",
      "test acc:  0.67933494\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  256 Avg loss:  0.37092465 ; acc:  0.86006135 ; epoch time:  0.32752323150634766\n",
      "eval test...\n",
      "test acc:  0.6698338\n",
      "\n",
      "\n",
      "Epoch:  257 Avg loss:  0.37199092 ; acc:  0.8580184 ; epoch time:  0.3435482978820801\n",
      "eval test...\n",
      "test acc:  0.6674585\n",
      "\n",
      "\n",
      "Epoch:  258 Avg loss:  0.37207332 ; acc:  0.8580184 ; epoch time:  0.33151912689208984\n",
      "eval test...\n",
      "test acc:  0.6698338\n",
      "\n",
      "\n",
      "Epoch:  259 Avg loss:  0.36856985 ; acc:  0.8641471 ; epoch time:  0.3195955753326416\n",
      "eval test...\n",
      "test acc:  0.67695963\n",
      "\n",
      "\n",
      "Epoch:  260 Avg loss:  0.36313096 ; acc:  0.86925435 ; epoch time:  0.3165872097015381\n",
      "eval test...\n",
      "test acc:  0.6745843\n",
      "\n",
      "\n",
      "Epoch:  261 Avg loss:  0.36180636 ; acc:  0.87027586 ; epoch time:  0.3380558490753174\n",
      "eval test...\n",
      "test acc:  0.6722091\n",
      "\n",
      "\n",
      "Epoch:  262 Avg loss:  0.3621355 ; acc:  0.86619 ; epoch time:  0.34204983711242676\n",
      "eval test...\n",
      "test acc:  0.68646085\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  263 Avg loss:  0.36081833 ; acc:  0.8651686 ; epoch time:  0.3438558578491211\n",
      "eval test...\n",
      "test acc:  0.67933494\n",
      "\n",
      "\n",
      "Epoch:  264 Avg loss:  0.35779676 ; acc:  0.87027586 ; epoch time:  0.32032179832458496\n",
      "eval test...\n",
      "test acc:  0.68171024\n",
      "\n",
      "\n",
      "Epoch:  265 Avg loss:  0.35454512 ; acc:  0.8712973 ; epoch time:  0.3473672866821289\n",
      "eval test...\n",
      "test acc:  0.67933494\n",
      "\n",
      "\n",
      "Epoch:  266 Avg loss:  0.3537681 ; acc:  0.8682329 ; epoch time:  0.37308597564697266\n",
      "eval test...\n",
      "test acc:  0.6722091\n",
      "\n",
      "\n",
      "Epoch:  267 Avg loss:  0.35367694 ; acc:  0.86210424 ; epoch time:  0.3573465347290039\n",
      "eval test...\n",
      "test acc:  0.68171024\n",
      "\n",
      "\n",
      "Epoch:  268 Avg loss:  0.35179183 ; acc:  0.87027586 ; epoch time:  0.32848167419433594\n",
      "eval test...\n",
      "test acc:  0.67933494\n",
      "\n",
      "\n",
      "Epoch:  269 Avg loss:  0.34917614 ; acc:  0.87231874 ; epoch time:  0.3254735469818115\n",
      "eval test...\n",
      "test acc:  0.68171024\n",
      "\n",
      "\n",
      "Epoch:  270 Avg loss:  0.3461428 ; acc:  0.87436163 ; epoch time:  0.3224358558654785\n",
      "eval test...\n",
      "test acc:  0.68408555\n",
      "\n",
      "\n",
      "Epoch:  271 Avg loss:  0.3449733 ; acc:  0.8733402 ; epoch time:  0.33507394790649414\n",
      "eval test...\n",
      "test acc:  0.68408555\n",
      "\n",
      "\n",
      "Epoch:  272 Avg loss:  0.34577185 ; acc:  0.87436163 ; epoch time:  0.31392693519592285\n",
      "eval test...\n",
      "test acc:  0.68408555\n",
      "\n",
      "\n",
      "Epoch:  273 Avg loss:  0.34321272 ; acc:  0.8784474 ; epoch time:  0.35939955711364746\n",
      "eval test...\n",
      "test acc:  0.68171024\n",
      "\n",
      "\n",
      "Epoch:  274 Avg loss:  0.33991313 ; acc:  0.8764045 ; epoch time:  0.32169055938720703\n",
      "eval test...\n",
      "test acc:  0.68646085\n",
      "\n",
      "\n",
      "Epoch:  275 Avg loss:  0.33803982 ; acc:  0.8804903 ; epoch time:  0.33603763580322266\n",
      "eval test...\n",
      "test acc:  0.68646085\n",
      "\n",
      "\n",
      "Epoch:  276 Avg loss:  0.33682016 ; acc:  0.8815118 ; epoch time:  0.3611757755279541\n",
      "eval test...\n",
      "test acc:  0.68408555\n",
      "\n",
      "\n",
      "Epoch:  277 Avg loss:  0.3354116 ; acc:  0.8784474 ; epoch time:  0.3226807117462158\n",
      "eval test...\n",
      "test acc:  0.68408555\n",
      "\n",
      "\n",
      "Epoch:  278 Avg loss:  0.33347324 ; acc:  0.8815118 ; epoch time:  0.3285515308380127\n",
      "eval test...\n",
      "test acc:  0.68883616\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  279 Avg loss:  0.33181816 ; acc:  0.8764045 ; epoch time:  0.32345008850097656\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  280 Avg loss:  0.3302617 ; acc:  0.87946886 ; epoch time:  0.3385019302368164\n",
      "eval test...\n",
      "test acc:  0.68883616\n",
      "\n",
      "\n",
      "Epoch:  281 Avg loss:  0.3280047 ; acc:  0.8804903 ; epoch time:  0.32030415534973145\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  282 Avg loss:  0.32676762 ; acc:  0.88253325 ; epoch time:  0.33605337142944336\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  283 Avg loss:  0.32502863 ; acc:  0.8835547 ; epoch time:  0.32328176498413086\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  284 Avg loss:  0.32342684 ; acc:  0.8835547 ; epoch time:  0.34377455711364746\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  285 Avg loss:  0.32169795 ; acc:  0.8804903 ; epoch time:  0.3289616107940674\n",
      "eval test...\n",
      "test acc:  0.68883616\n",
      "\n",
      "\n",
      "Epoch:  286 Avg loss:  0.31978828 ; acc:  0.8886619 ; epoch time:  0.3336951732635498\n",
      "eval test...\n",
      "test acc:  0.68408555\n",
      "\n",
      "\n",
      "Epoch:  287 Avg loss:  0.31802642 ; acc:  0.88968337 ; epoch time:  0.33951544761657715\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  288 Avg loss:  0.31685105 ; acc:  0.88661903 ; epoch time:  0.32708191871643066\n",
      "eval test...\n",
      "test acc:  0.68883616\n",
      "\n",
      "\n",
      "Epoch:  289 Avg loss:  0.31539384 ; acc:  0.8886619 ; epoch time:  0.3240079879760742\n",
      "eval test...\n",
      "test acc:  0.68408555\n",
      "\n",
      "\n",
      "Epoch:  290 Avg loss:  0.31350625 ; acc:  0.88661903 ; epoch time:  0.33912181854248047\n",
      "eval test...\n",
      "test acc:  0.68171024\n",
      "\n",
      "\n",
      "Epoch:  291 Avg loss:  0.31304324 ; acc:  0.8876405 ; epoch time:  0.32817745208740234\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  292 Avg loss:  0.3133181 ; acc:  0.8876405 ; epoch time:  0.33416128158569336\n",
      "eval test...\n",
      "test acc:  0.68408555\n",
      "\n",
      "\n",
      "Epoch:  293 Avg loss:  0.31406847 ; acc:  0.88253325 ; epoch time:  0.31520605087280273\n",
      "eval test...\n",
      "test acc:  0.68171024\n",
      "\n",
      "\n",
      "Epoch:  294 Avg loss:  0.3127483 ; acc:  0.8764045 ; epoch time:  0.34662842750549316\n",
      "eval test...\n",
      "test acc:  0.68408555\n",
      "\n",
      "\n",
      "Epoch:  295 Avg loss:  0.30983633 ; acc:  0.8804903 ; epoch time:  0.3296167850494385\n",
      "eval test...\n",
      "test acc:  0.68408555\n",
      "\n",
      "\n",
      "Epoch:  296 Avg loss:  0.3050688 ; acc:  0.8937692 ; epoch time:  0.32090330123901367\n",
      "eval test...\n",
      "test acc:  0.68883616\n",
      "\n",
      "\n",
      "Epoch:  297 Avg loss:  0.301817 ; acc:  0.89274776 ; epoch time:  0.31255245208740234\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  298 Avg loss:  0.30045447 ; acc:  0.897855 ; epoch time:  0.3230862617492676\n",
      "eval test...\n",
      "test acc:  0.68646085\n",
      "\n",
      "\n",
      "Epoch:  299 Avg loss:  0.30134562 ; acc:  0.88661903 ; epoch time:  0.3481576442718506\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  300 Avg loss:  0.3013444 ; acc:  0.8886619 ; epoch time:  0.3092002868652344\n",
      "eval test...\n",
      "test acc:  0.68408555\n",
      "\n",
      "\n",
      "Epoch:  301 Avg loss:  0.29760763 ; acc:  0.8886619 ; epoch time:  0.3376033306121826\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  302 Avg loss:  0.29411948 ; acc:  0.90296227 ; epoch time:  0.33693742752075195\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  303 Avg loss:  0.29180217 ; acc:  0.9019408 ; epoch time:  0.36362385749816895\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  304 Avg loss:  0.2913598 ; acc:  0.89479065 ; epoch time:  0.33170247077941895\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  305 Avg loss:  0.2907624 ; acc:  0.9019408 ; epoch time:  0.29892706871032715\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  306 Avg loss:  0.28943 ; acc:  0.89479065 ; epoch time:  0.34462618827819824\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  307 Avg loss:  0.28730065 ; acc:  0.9039837 ; epoch time:  0.3330967426300049\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  308 Avg loss:  0.2852412 ; acc:  0.9039837 ; epoch time:  0.3317403793334961\n",
      "eval test...\n",
      "test acc:  0.68883616\n",
      "\n",
      "\n",
      "Epoch:  309 Avg loss:  0.2823745 ; acc:  0.9019408 ; epoch time:  0.32969212532043457\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  310 Avg loss:  0.28119844 ; acc:  0.90704805 ; epoch time:  0.3267974853515625\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  311 Avg loss:  0.28152248 ; acc:  0.90500516 ; epoch time:  0.31946229934692383\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  312 Avg loss:  0.28046694 ; acc:  0.9039837 ; epoch time:  0.33966732025146484\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  313 Avg loss:  0.27808195 ; acc:  0.9009193 ; epoch time:  0.3528273105621338\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  314 Avg loss:  0.27598786 ; acc:  0.9039837 ; epoch time:  0.31453871726989746\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  315 Avg loss:  0.27406704 ; acc:  0.90500516 ; epoch time:  0.34801769256591797\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  316 Avg loss:  0.2725395 ; acc:  0.90909094 ; epoch time:  0.33876657485961914\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  317 Avg loss:  0.2712226 ; acc:  0.9101124 ; epoch time:  0.3203849792480469\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  318 Avg loss:  0.27076414 ; acc:  0.9080695 ; epoch time:  0.3253774642944336\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  319 Avg loss:  0.27015054 ; acc:  0.90909094 ; epoch time:  0.3307931423187256\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  320 Avg loss:  0.26745728 ; acc:  0.9101124 ; epoch time:  0.33300209045410156\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  321 Avg loss:  0.2653913 ; acc:  0.9080695 ; epoch time:  0.3486177921295166\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  322 Avg loss:  0.26424336 ; acc:  0.9141982 ; epoch time:  0.3422369956970215\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  323 Avg loss:  0.26269957 ; acc:  0.90704805 ; epoch time:  0.35317254066467285\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  324 Avg loss:  0.26123354 ; acc:  0.9121553 ; epoch time:  0.350677490234375\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  325 Avg loss:  0.25954068 ; acc:  0.9101124 ; epoch time:  0.33997130393981934\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  326 Avg loss:  0.2581288 ; acc:  0.91521966 ; epoch time:  0.3345489501953125\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  327 Avg loss:  0.25707775 ; acc:  0.9141982 ; epoch time:  0.301361083984375\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  328 Avg loss:  0.25579733 ; acc:  0.9111338 ; epoch time:  0.33283376693725586\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  329 Avg loss:  0.25412878 ; acc:  0.9141982 ; epoch time:  0.31679248809814453\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  330 Avg loss:  0.2531017 ; acc:  0.91726255 ; epoch time:  0.33593130111694336\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  331 Avg loss:  0.25218496 ; acc:  0.91521966 ; epoch time:  0.3100600242614746\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  332 Avg loss:  0.25051284 ; acc:  0.9131768 ; epoch time:  0.3271489143371582\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  333 Avg loss:  0.24997395 ; acc:  0.9111338 ; epoch time:  0.33626723289489746\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  334 Avg loss:  0.24904037 ; acc:  0.9141982 ; epoch time:  0.33734774589538574\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  335 Avg loss:  0.24707398 ; acc:  0.9162411 ; epoch time:  0.3243749141693115\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  336 Avg loss:  0.2468035 ; acc:  0.91726255 ; epoch time:  0.30625200271606445\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  337 Avg loss:  0.24566254 ; acc:  0.91726255 ; epoch time:  0.32297253608703613\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  338 Avg loss:  0.24408142 ; acc:  0.9162411 ; epoch time:  0.3660316467285156\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  339 Avg loss:  0.24322791 ; acc:  0.9141982 ; epoch time:  0.3364832401275635\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  340 Avg loss:  0.24024177 ; acc:  0.91930544 ; epoch time:  0.328840970993042\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  341 Avg loss:  0.23882334 ; acc:  0.9223698 ; epoch time:  0.3268311023712158\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  342 Avg loss:  0.2377607 ; acc:  0.918284 ; epoch time:  0.3432629108428955\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  343 Avg loss:  0.23554096 ; acc:  0.92134833 ; epoch time:  0.328322172164917\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  344 Avg loss:  0.234294 ; acc:  0.918284 ; epoch time:  0.32930707931518555\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  345 Avg loss:  0.2333913 ; acc:  0.9223698 ; epoch time:  0.319225549697876\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  346 Avg loss:  0.23163845 ; acc:  0.9223698 ; epoch time:  0.31751346588134766\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  347 Avg loss:  0.23159488 ; acc:  0.9223698 ; epoch time:  0.3373568058013916\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  348 Avg loss:  0.2317894 ; acc:  0.9284985 ; epoch time:  0.33025217056274414\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  349 Avg loss:  0.231089 ; acc:  0.918284 ; epoch time:  0.3448922634124756\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  350 Avg loss:  0.23046632 ; acc:  0.9264556 ; epoch time:  0.32981061935424805\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  351 Avg loss:  0.22994432 ; acc:  0.9203269 ; epoch time:  0.32761144638061523\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  352 Avg loss:  0.23130178 ; acc:  0.9141982 ; epoch time:  0.31333446502685547\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  353 Avg loss:  0.22900985 ; acc:  0.9233913 ; epoch time:  0.34082579612731934\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  354 Avg loss:  0.22571251 ; acc:  0.92951995 ; epoch time:  0.33718013763427734\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  355 Avg loss:  0.22033627 ; acc:  0.9254342 ; epoch time:  0.33249378204345703\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  356 Avg loss:  0.21897197 ; acc:  0.9264556 ; epoch time:  0.36067843437194824\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  357 Avg loss:  0.21957237 ; acc:  0.9305414 ; epoch time:  0.31629228591918945\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  358 Avg loss:  0.2200684 ; acc:  0.9254342 ; epoch time:  0.3255476951599121\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  359 Avg loss:  0.22041355 ; acc:  0.9284985 ; epoch time:  0.33280229568481445\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  360 Avg loss:  0.21722387 ; acc:  0.9325843 ; epoch time:  0.34968996047973633\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  361 Avg loss:  0.21428491 ; acc:  0.938713 ; epoch time:  0.30945658683776855\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  362 Avg loss:  0.21173857 ; acc:  0.92951995 ; epoch time:  0.3444976806640625\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  363 Avg loss:  0.21134503 ; acc:  0.93156284 ; epoch time:  0.346327543258667\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  364 Avg loss:  0.2134391 ; acc:  0.938713 ; epoch time:  0.3390507698059082\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  365 Avg loss:  0.21401381 ; acc:  0.93156284 ; epoch time:  0.30902957916259766\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  366 Avg loss:  0.21118677 ; acc:  0.9366701 ; epoch time:  0.31166553497314453\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  367 Avg loss:  0.20512067 ; acc:  0.93462723 ; epoch time:  0.3404712677001953\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  368 Avg loss:  0.20602825 ; acc:  0.93360573 ; epoch time:  0.32138752937316895\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  369 Avg loss:  0.20844655 ; acc:  0.9356487 ; epoch time:  0.31232547760009766\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  370 Avg loss:  0.20623367 ; acc:  0.9325843 ; epoch time:  0.34438490867614746\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  371 Avg loss:  0.20231424 ; acc:  0.9427988 ; epoch time:  0.3084135055541992\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  372 Avg loss:  0.20054434 ; acc:  0.93973446 ; epoch time:  0.3438987731933594\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  373 Avg loss:  0.20144482 ; acc:  0.9305414 ; epoch time:  0.324054479598999\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  374 Avg loss:  0.19959499 ; acc:  0.9427988 ; epoch time:  0.35860300064086914\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  375 Avg loss:  0.19862516 ; acc:  0.9427988 ; epoch time:  0.32047152519226074\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  376 Avg loss:  0.19723861 ; acc:  0.93769157 ; epoch time:  0.3366048336029053\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  377 Avg loss:  0.1951089 ; acc:  0.94484174 ; epoch time:  0.3529965877532959\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  378 Avg loss:  0.19324899 ; acc:  0.94177735 ; epoch time:  0.32229113578796387\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  379 Avg loss:  0.19202743 ; acc:  0.94484174 ; epoch time:  0.34389233589172363\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  380 Avg loss:  0.1928541 ; acc:  0.9427988 ; epoch time:  0.31803202629089355\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  381 Avg loss:  0.18966259 ; acc:  0.94688463 ; epoch time:  0.3425018787384033\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  382 Avg loss:  0.18862693 ; acc:  0.94688463 ; epoch time:  0.3032855987548828\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  383 Avg loss:  0.1876874 ; acc:  0.9479061 ; epoch time:  0.32433509826660156\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  384 Avg loss:  0.18722688 ; acc:  0.9427988 ; epoch time:  0.3104269504547119\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  385 Avg loss:  0.18499123 ; acc:  0.9509704 ; epoch time:  0.3296072483062744\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  386 Avg loss:  0.1834511 ; acc:  0.9479061 ; epoch time:  0.32799673080444336\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  387 Avg loss:  0.18296316 ; acc:  0.94484174 ; epoch time:  0.35328149795532227\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  388 Avg loss:  0.18171816 ; acc:  0.9489275 ; epoch time:  0.33725547790527344\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  389 Avg loss:  0.18090054 ; acc:  0.95199186 ; epoch time:  0.32662487030029297\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  390 Avg loss:  0.17877777 ; acc:  0.9509704 ; epoch time:  0.32951927185058594\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  391 Avg loss:  0.17806692 ; acc:  0.95199186 ; epoch time:  0.35100245475769043\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  392 Avg loss:  0.17714682 ; acc:  0.94994897 ; epoch time:  0.31431031227111816\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  393 Avg loss:  0.17576212 ; acc:  0.95709914 ; epoch time:  0.3537585735321045\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  394 Avg loss:  0.17467317 ; acc:  0.95403475 ; epoch time:  0.3445618152618408\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  395 Avg loss:  0.17344718 ; acc:  0.95403475 ; epoch time:  0.3368556499481201\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  396 Avg loss:  0.1727875 ; acc:  0.9530133 ; epoch time:  0.3201010227203369\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  397 Avg loss:  0.17233676 ; acc:  0.9479061 ; epoch time:  0.34992074966430664\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  398 Avg loss:  0.1721187 ; acc:  0.9550562 ; epoch time:  0.3198096752166748\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  399 Avg loss:  0.17108023 ; acc:  0.9509704 ; epoch time:  0.32826852798461914\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  400 Avg loss:  0.17098467 ; acc:  0.94994897 ; epoch time:  0.33974528312683105\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  401 Avg loss:  0.17042677 ; acc:  0.94994897 ; epoch time:  0.34639573097229004\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  402 Avg loss:  0.16894181 ; acc:  0.9530133 ; epoch time:  0.33974313735961914\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  403 Avg loss:  0.16699621 ; acc:  0.9560777 ; epoch time:  0.337263822555542\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  404 Avg loss:  0.16667452 ; acc:  0.9530133 ; epoch time:  0.3596985340118408\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  405 Avg loss:  0.16534306 ; acc:  0.9530133 ; epoch time:  0.3283803462982178\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  406 Avg loss:  0.1636565 ; acc:  0.9652707 ; epoch time:  0.31662797927856445\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  407 Avg loss:  0.16070576 ; acc:  0.9601635 ; epoch time:  0.33188700675964355\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  408 Avg loss:  0.15978271 ; acc:  0.9581206 ; epoch time:  0.31572818756103516\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  409 Avg loss:  0.16056882 ; acc:  0.96220636 ; epoch time:  0.3306882381439209\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  410 Avg loss:  0.16087985 ; acc:  0.9550562 ; epoch time:  0.3268702030181885\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  411 Avg loss:  0.15989618 ; acc:  0.95709914 ; epoch time:  0.35288095474243164\n",
      "eval test...\n",
      "test acc:  0.719715\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  412 Avg loss:  0.15756148 ; acc:  0.96220636 ; epoch time:  0.3360135555267334\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  413 Avg loss:  0.1566473 ; acc:  0.959142 ; epoch time:  0.309889554977417\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  414 Avg loss:  0.15467939 ; acc:  0.96424925 ; epoch time:  0.3308980464935303\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  415 Avg loss:  0.15286504 ; acc:  0.9611849 ; epoch time:  0.35079288482666016\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  416 Avg loss:  0.15170307 ; acc:  0.96731365 ; epoch time:  0.3198862075805664\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  417 Avg loss:  0.15109043 ; acc:  0.96220636 ; epoch time:  0.3547484874725342\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  418 Avg loss:  0.15100887 ; acc:  0.9611849 ; epoch time:  0.3238790035247803\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  419 Avg loss:  0.15024471 ; acc:  0.9652707 ; epoch time:  0.3185126781463623\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  420 Avg loss:  0.14854074 ; acc:  0.9632278 ; epoch time:  0.322371244430542\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  421 Avg loss:  0.14664802 ; acc:  0.9683351 ; epoch time:  0.310727596282959\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  422 Avg loss:  0.14561628 ; acc:  0.9683351 ; epoch time:  0.3272991180419922\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  423 Avg loss:  0.14505652 ; acc:  0.96424925 ; epoch time:  0.3318049907684326\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  424 Avg loss:  0.14451154 ; acc:  0.970378 ; epoch time:  0.32303476333618164\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  425 Avg loss:  0.14384398 ; acc:  0.96424925 ; epoch time:  0.33098316192626953\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  426 Avg loss:  0.14402172 ; acc:  0.96731365 ; epoch time:  0.36949586868286133\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  427 Avg loss:  0.1444865 ; acc:  0.96935654 ; epoch time:  0.3180887699127197\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  428 Avg loss:  0.14584363 ; acc:  0.96220636 ; epoch time:  0.33045387268066406\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  429 Avg loss:  0.14677292 ; acc:  0.96424925 ; epoch time:  0.3428173065185547\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  430 Avg loss:  0.14692359 ; acc:  0.959142 ; epoch time:  0.3240377902984619\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  431 Avg loss:  0.14403327 ; acc:  0.96731365 ; epoch time:  0.29087114334106445\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  432 Avg loss:  0.14087686 ; acc:  0.9683351 ; epoch time:  0.2922375202178955\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  433 Avg loss:  0.13717192 ; acc:  0.970378 ; epoch time:  0.27411818504333496\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  434 Avg loss:  0.1357841 ; acc:  0.97446376 ; epoch time:  0.2924525737762451\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  435 Avg loss:  0.13554308 ; acc:  0.970378 ; epoch time:  0.2833213806152344\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  436 Avg loss:  0.13558725 ; acc:  0.970378 ; epoch time:  0.28854966163635254\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  437 Avg loss:  0.13753453 ; acc:  0.9662922 ; epoch time:  0.3106350898742676\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  438 Avg loss:  0.13489859 ; acc:  0.9724209 ; epoch time:  0.28710055351257324\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  439 Avg loss:  0.1317475 ; acc:  0.9734423 ; epoch time:  0.29007816314697266\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  440 Avg loss:  0.13104522 ; acc:  0.9724209 ; epoch time:  0.2646024227142334\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  441 Avg loss:  0.13072006 ; acc:  0.96935654 ; epoch time:  0.2773892879486084\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  442 Avg loss:  0.1301705 ; acc:  0.97752815 ; epoch time:  0.3113400936126709\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  443 Avg loss:  0.12973376 ; acc:  0.97446376 ; epoch time:  0.29579877853393555\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  444 Avg loss:  0.12845375 ; acc:  0.9724209 ; epoch time:  0.26797962188720703\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  445 Avg loss:  0.12677862 ; acc:  0.97446376 ; epoch time:  0.28796911239624023\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  446 Avg loss:  0.12536229 ; acc:  0.9754852 ; epoch time:  0.3047623634338379\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  447 Avg loss:  0.12601139 ; acc:  0.9724209 ; epoch time:  0.27339839935302734\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  448 Avg loss:  0.12664193 ; acc:  0.970378 ; epoch time:  0.29363393783569336\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  449 Avg loss:  0.12464739 ; acc:  0.97446376 ; epoch time:  0.2995622158050537\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  450 Avg loss:  0.123515695 ; acc:  0.97752815 ; epoch time:  0.26703429222106934\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  451 Avg loss:  0.12410788 ; acc:  0.9713994 ; epoch time:  0.2832334041595459\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  452 Avg loss:  0.1243173 ; acc:  0.9734423 ; epoch time:  0.2775588035583496\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  453 Avg loss:  0.12137299 ; acc:  0.9805925 ; epoch time:  0.2920196056365967\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  454 Avg loss:  0.120264366 ; acc:  0.97650665 ; epoch time:  0.2875792980194092\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  455 Avg loss:  0.121058084 ; acc:  0.97446376 ; epoch time:  0.27731919288635254\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  456 Avg loss:  0.11973368 ; acc:  0.97752815 ; epoch time:  0.28899359703063965\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  457 Avg loss:  0.118989676 ; acc:  0.9785496 ; epoch time:  0.2771601676940918\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  458 Avg loss:  0.118661374 ; acc:  0.9734423 ; epoch time:  0.28108739852905273\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  459 Avg loss:  0.117635235 ; acc:  0.97752815 ; epoch time:  0.28655195236206055\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  460 Avg loss:  0.11539467 ; acc:  0.9785496 ; epoch time:  0.28415536880493164\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  461 Avg loss:  0.11472797 ; acc:  0.97957104 ; epoch time:  0.2794189453125\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  462 Avg loss:  0.11544083 ; acc:  0.9754852 ; epoch time:  0.29594874382019043\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  463 Avg loss:  0.11408919 ; acc:  0.97650665 ; epoch time:  0.28054213523864746\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  464 Avg loss:  0.1130117 ; acc:  0.97650665 ; epoch time:  0.32017946243286133\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  465 Avg loss:  0.11277483 ; acc:  0.9785496 ; epoch time:  0.2889549732208252\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  466 Avg loss:  0.11258096 ; acc:  0.97650665 ; epoch time:  0.28847455978393555\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  467 Avg loss:  0.11025968 ; acc:  0.9785496 ; epoch time:  0.25592923164367676\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  468 Avg loss:  0.11004029 ; acc:  0.9805925 ; epoch time:  0.29276251792907715\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  469 Avg loss:  0.1107073 ; acc:  0.9785496 ; epoch time:  0.28060364723205566\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  470 Avg loss:  0.10978071 ; acc:  0.9785496 ; epoch time:  0.2900412082672119\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  471 Avg loss:  0.108989626 ; acc:  0.97957104 ; epoch time:  0.25255393981933594\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  472 Avg loss:  0.1079575 ; acc:  0.97752815 ; epoch time:  0.29248499870300293\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  473 Avg loss:  0.107080676 ; acc:  0.97752815 ; epoch time:  0.29172253608703613\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  474 Avg loss:  0.10571009 ; acc:  0.9785496 ; epoch time:  0.27364516258239746\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  475 Avg loss:  0.10572696 ; acc:  0.97957104 ; epoch time:  0.285045862197876\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  476 Avg loss:  0.106165856 ; acc:  0.97752815 ; epoch time:  0.2720959186553955\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  477 Avg loss:  0.10470393 ; acc:  0.97957104 ; epoch time:  0.2864344120025635\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  478 Avg loss:  0.10361558 ; acc:  0.9785496 ; epoch time:  0.2828037738800049\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  479 Avg loss:  0.10299137 ; acc:  0.98161393 ; epoch time:  0.2915382385253906\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  480 Avg loss:  0.102011606 ; acc:  0.9805925 ; epoch time:  0.2909119129180908\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  481 Avg loss:  0.1020354 ; acc:  0.97957104 ; epoch time:  0.2876553535461426\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  482 Avg loss:  0.10165818 ; acc:  0.9805925 ; epoch time:  0.3190748691558838\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  483 Avg loss:  0.10163872 ; acc:  0.9785496 ; epoch time:  0.2941710948944092\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  484 Avg loss:  0.10089362 ; acc:  0.97957104 ; epoch time:  0.2981395721435547\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  485 Avg loss:  0.09981166 ; acc:  0.97957104 ; epoch time:  0.29246068000793457\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  486 Avg loss:  0.09871895 ; acc:  0.9785496 ; epoch time:  0.2690551280975342\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  487 Avg loss:  0.09810186 ; acc:  0.97957104 ; epoch time:  0.2864997386932373\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  488 Avg loss:  0.09786049 ; acc:  0.97957104 ; epoch time:  0.28530240058898926\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  489 Avg loss:  0.09830326 ; acc:  0.98161393 ; epoch time:  0.2823984622955322\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  490 Avg loss:  0.09799363 ; acc:  0.98161393 ; epoch time:  0.28098273277282715\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  491 Avg loss:  0.09672691 ; acc:  0.9785496 ; epoch time:  0.2953352928161621\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  492 Avg loss:  0.09530338 ; acc:  0.9785496 ; epoch time:  0.2940635681152344\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  493 Avg loss:  0.09436326 ; acc:  0.9805925 ; epoch time:  0.29943084716796875\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  494 Avg loss:  0.09425024 ; acc:  0.98161393 ; epoch time:  0.3003849983215332\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  495 Avg loss:  0.09372706 ; acc:  0.9826354 ; epoch time:  0.30199551582336426\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  496 Avg loss:  0.09350672 ; acc:  0.98161393 ; epoch time:  0.3145148754119873\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  497 Avg loss:  0.09305968 ; acc:  0.9805925 ; epoch time:  0.2747483253479004\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  498 Avg loss:  0.09240822 ; acc:  0.9805925 ; epoch time:  0.29046106338500977\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  499 Avg loss:  0.092307955 ; acc:  0.9836568 ; epoch time:  0.2872960567474365\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  500 Avg loss:  0.09107041 ; acc:  0.97957104 ; epoch time:  0.28374719619750977\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  501 Avg loss:  0.090178244 ; acc:  0.9805925 ; epoch time:  0.27581286430358887\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  502 Avg loss:  0.089749254 ; acc:  0.9805925 ; epoch time:  0.28017687797546387\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  503 Avg loss:  0.089069776 ; acc:  0.9805925 ; epoch time:  0.2833728790283203\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  504 Avg loss:  0.08868305 ; acc:  0.98161393 ; epoch time:  0.29409265518188477\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  505 Avg loss:  0.087952025 ; acc:  0.9805925 ; epoch time:  0.28038978576660156\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  506 Avg loss:  0.08751107 ; acc:  0.98161393 ; epoch time:  0.28310704231262207\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  507 Avg loss:  0.0867972 ; acc:  0.98161393 ; epoch time:  0.28595709800720215\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  508 Avg loss:  0.086332664 ; acc:  0.9805925 ; epoch time:  0.2595365047454834\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  509 Avg loss:  0.085878834 ; acc:  0.98161393 ; epoch time:  0.28481602668762207\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  510 Avg loss:  0.0853865 ; acc:  0.98161393 ; epoch time:  0.2822248935699463\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  511 Avg loss:  0.084889725 ; acc:  0.98161393 ; epoch time:  0.2645416259765625\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  512 Avg loss:  0.08438014 ; acc:  0.9805925 ; epoch time:  0.2933650016784668\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  513 Avg loss:  0.083878525 ; acc:  0.98161393 ; epoch time:  0.28108811378479004\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  514 Avg loss:  0.08340905 ; acc:  0.9836568 ; epoch time:  0.27779245376586914\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  515 Avg loss:  0.08307525 ; acc:  0.9826354 ; epoch time:  0.28438234329223633\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  516 Avg loss:  0.082575046 ; acc:  0.9826354 ; epoch time:  0.28101325035095215\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  517 Avg loss:  0.08190349 ; acc:  0.98161393 ; epoch time:  0.2934129238128662\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  518 Avg loss:  0.0817993 ; acc:  0.9826354 ; epoch time:  0.26689815521240234\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  519 Avg loss:  0.08110876 ; acc:  0.9826354 ; epoch time:  0.2798488140106201\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  520 Avg loss:  0.080771446 ; acc:  0.98467827 ; epoch time:  0.2854015827178955\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  521 Avg loss:  0.08056983 ; acc:  0.9836568 ; epoch time:  0.2928464412689209\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  522 Avg loss:  0.079896934 ; acc:  0.98467827 ; epoch time:  0.2786750793457031\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  523 Avg loss:  0.079983175 ; acc:  0.9856997 ; epoch time:  0.29588842391967773\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  524 Avg loss:  0.079463914 ; acc:  0.9836568 ; epoch time:  0.29168033599853516\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  525 Avg loss:  0.079211645 ; acc:  0.9856997 ; epoch time:  0.2983853816986084\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  526 Avg loss:  0.07946874 ; acc:  0.98467827 ; epoch time:  0.28556346893310547\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  527 Avg loss:  0.07962315 ; acc:  0.98774266 ; epoch time:  0.27451014518737793\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  528 Avg loss:  0.0789353 ; acc:  0.9826354 ; epoch time:  0.28524208068847656\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  529 Avg loss:  0.0781597 ; acc:  0.98774266 ; epoch time:  0.2965250015258789\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  530 Avg loss:  0.07711094 ; acc:  0.9836568 ; epoch time:  0.29221057891845703\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  531 Avg loss:  0.07610247 ; acc:  0.98672116 ; epoch time:  0.29228687286376953\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  532 Avg loss:  0.07504253 ; acc:  0.98672116 ; epoch time:  0.29544544219970703\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  533 Avg loss:  0.07488335 ; acc:  0.98467827 ; epoch time:  0.29164981842041016\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  534 Avg loss:  0.0747257 ; acc:  0.9887641 ; epoch time:  0.2783191204071045\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  535 Avg loss:  0.07465188 ; acc:  0.9856997 ; epoch time:  0.284543514251709\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  536 Avg loss:  0.074772425 ; acc:  0.9887641 ; epoch time:  0.3053896427154541\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  537 Avg loss:  0.07416491 ; acc:  0.98672116 ; epoch time:  0.30324554443359375\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  538 Avg loss:  0.072984666 ; acc:  0.98774266 ; epoch time:  0.3343944549560547\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  539 Avg loss:  0.07263957 ; acc:  0.98672116 ; epoch time:  0.2867395877838135\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  540 Avg loss:  0.072106466 ; acc:  0.99182844 ; epoch time:  0.28150105476379395\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  541 Avg loss:  0.07122867 ; acc:  0.98978555 ; epoch time:  0.28408098220825195\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  542 Avg loss:  0.070627175 ; acc:  0.990807 ; epoch time:  0.28493785858154297\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  543 Avg loss:  0.07035438 ; acc:  0.99182844 ; epoch time:  0.2902333736419678\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  544 Avg loss:  0.069839895 ; acc:  0.9887641 ; epoch time:  0.27327775955200195\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  545 Avg loss:  0.06933081 ; acc:  0.98978555 ; epoch time:  0.28353238105773926\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  546 Avg loss:  0.06893168 ; acc:  0.99182844 ; epoch time:  0.2812192440032959\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  547 Avg loss:  0.06866207 ; acc:  0.98978555 ; epoch time:  0.289689302444458\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  548 Avg loss:  0.06826585 ; acc:  0.990807 ; epoch time:  0.28726768493652344\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  549 Avg loss:  0.06843827 ; acc:  0.9887641 ; epoch time:  0.2931826114654541\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  550 Avg loss:  0.06876113 ; acc:  0.990807 ; epoch time:  0.2918109893798828\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  551 Avg loss:  0.07006564 ; acc:  0.98774266 ; epoch time:  0.267575740814209\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  552 Avg loss:  0.07087193 ; acc:  0.990807 ; epoch time:  0.28354883193969727\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  553 Avg loss:  0.072795875 ; acc:  0.98774266 ; epoch time:  0.273115873336792\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  554 Avg loss:  0.07398553 ; acc:  0.98774266 ; epoch time:  0.2972898483276367\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  555 Avg loss:  0.078005 ; acc:  0.98467827 ; epoch time:  0.27094221115112305\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  556 Avg loss:  0.07781344 ; acc:  0.98467827 ; epoch time:  0.2674064636230469\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  557 Avg loss:  0.07606652 ; acc:  0.9836568 ; epoch time:  0.2697129249572754\n",
      "eval test...\n",
      "test acc:  0.719715\n",
      "\n",
      "\n",
      "Epoch:  558 Avg loss:  0.06740061 ; acc:  0.990807 ; epoch time:  0.2973780632019043\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  559 Avg loss:  0.066941395 ; acc:  0.99182844 ; epoch time:  0.29215002059936523\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  560 Avg loss:  0.072610065 ; acc:  0.9856997 ; epoch time:  0.26575207710266113\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  561 Avg loss:  0.070587225 ; acc:  0.98774266 ; epoch time:  0.2846946716308594\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  562 Avg loss:  0.06649276 ; acc:  0.9887641 ; epoch time:  0.28987550735473633\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  563 Avg loss:  0.06458014 ; acc:  0.9887641 ; epoch time:  0.2866966724395752\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  564 Avg loss:  0.06645724 ; acc:  0.990807 ; epoch time:  0.29391002655029297\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  565 Avg loss:  0.06705179 ; acc:  0.9856997 ; epoch time:  0.2852334976196289\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  566 Avg loss:  0.06287424 ; acc:  0.98978555 ; epoch time:  0.2757132053375244\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  567 Avg loss:  0.06310544 ; acc:  0.990807 ; epoch time:  0.2719860076904297\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  568 Avg loss:  0.06565504 ; acc:  0.98774266 ; epoch time:  0.29955410957336426\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  569 Avg loss:  0.06216883 ; acc:  0.99182844 ; epoch time:  0.2891979217529297\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  570 Avg loss:  0.061372828 ; acc:  0.99182844 ; epoch time:  0.2737243175506592\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  571 Avg loss:  0.06327183 ; acc:  0.98978555 ; epoch time:  0.2950429916381836\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  572 Avg loss:  0.06099227 ; acc:  0.99387133 ; epoch time:  0.28759288787841797\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  573 Avg loss:  0.060624897 ; acc:  0.9928499 ; epoch time:  0.2812025547027588\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  574 Avg loss:  0.06067647 ; acc:  0.99182844 ; epoch time:  0.28762006759643555\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  575 Avg loss:  0.05958045 ; acc:  0.99387133 ; epoch time:  0.2969698905944824\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  576 Avg loss:  0.05948744 ; acc:  0.99182844 ; epoch time:  0.28014469146728516\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  577 Avg loss:  0.05877708 ; acc:  0.9928499 ; epoch time:  0.27065539360046387\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  578 Avg loss:  0.05800175 ; acc:  0.99387133 ; epoch time:  0.27507996559143066\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  579 Avg loss:  0.058146745 ; acc:  0.9928499 ; epoch time:  0.3101217746734619\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  580 Avg loss:  0.057149965 ; acc:  0.9928499 ; epoch time:  0.28765249252319336\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  581 Avg loss:  0.05698087 ; acc:  0.99387133 ; epoch time:  0.2969181537628174\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  582 Avg loss:  0.057105567 ; acc:  0.9928499 ; epoch time:  0.27100229263305664\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  583 Avg loss:  0.056172352 ; acc:  0.99387133 ; epoch time:  0.272519588470459\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  584 Avg loss:  0.0558928 ; acc:  0.99387133 ; epoch time:  0.28627467155456543\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  585 Avg loss:  0.056295533 ; acc:  0.99387133 ; epoch time:  0.27837276458740234\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  586 Avg loss:  0.05538547 ; acc:  0.99387133 ; epoch time:  0.2901794910430908\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  587 Avg loss:  0.054782066 ; acc:  0.99387133 ; epoch time:  0.3039674758911133\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  588 Avg loss:  0.054844134 ; acc:  0.99387133 ; epoch time:  0.27620482444763184\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  589 Avg loss:  0.054366328 ; acc:  0.99387133 ; epoch time:  0.2907538414001465\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  590 Avg loss:  0.054302856 ; acc:  0.9948928 ; epoch time:  0.2878077030181885\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  591 Avg loss:  0.053600866 ; acc:  0.99387133 ; epoch time:  0.28648829460144043\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  592 Avg loss:  0.053401858 ; acc:  0.99387133 ; epoch time:  0.29352235794067383\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  593 Avg loss:  0.053067937 ; acc:  0.99387133 ; epoch time:  0.296492338180542\n",
      "eval test...\n",
      "test acc:  0.719715\n",
      "\n",
      "\n",
      "Epoch:  594 Avg loss:  0.052826714 ; acc:  0.99387133 ; epoch time:  0.30235910415649414\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  595 Avg loss:  0.052242305 ; acc:  0.9959142 ; epoch time:  0.27837228775024414\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  596 Avg loss:  0.052040555 ; acc:  0.9959142 ; epoch time:  0.2843480110168457\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  597 Avg loss:  0.051419746 ; acc:  0.9948928 ; epoch time:  0.2803940773010254\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  598 Avg loss:  0.051501688 ; acc:  0.9959142 ; epoch time:  0.2992856502532959\n",
      "eval test...\n",
      "test acc:  0.7220903\n",
      "saving...\n",
      "\n",
      "\n",
      "Epoch:  599 Avg loss:  0.05078689 ; acc:  0.9948928 ; epoch time:  0.2921900749206543\n",
      "eval test...\n",
      "test acc:  0.719715\n",
      "\n",
      "\n",
      "Epoch:  600 Avg loss:  0.050516397 ; acc:  0.9959142 ; epoch time:  0.2928159236907959\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  601 Avg loss:  0.0502359 ; acc:  0.9959142 ; epoch time:  0.2933487892150879\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  602 Avg loss:  0.04994883 ; acc:  0.9959142 ; epoch time:  0.29974794387817383\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  603 Avg loss:  0.049557004 ; acc:  0.9959142 ; epoch time:  0.2894470691680908\n",
      "eval test...\n",
      "test acc:  0.719715\n",
      "\n",
      "\n",
      "Epoch:  604 Avg loss:  0.049370043 ; acc:  0.9948928 ; epoch time:  0.26761460304260254\n",
      "eval test...\n",
      "test acc:  0.719715\n",
      "\n",
      "\n",
      "Epoch:  605 Avg loss:  0.048811145 ; acc:  0.9959142 ; epoch time:  0.2693052291870117\n",
      "eval test...\n",
      "test acc:  0.719715\n",
      "\n",
      "\n",
      "Epoch:  606 Avg loss:  0.04858994 ; acc:  0.9959142 ; epoch time:  0.2885627746582031\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  607 Avg loss:  0.048180442 ; acc:  0.9959142 ; epoch time:  0.2805631160736084\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  608 Avg loss:  0.04795427 ; acc:  0.9959142 ; epoch time:  0.3016786575317383\n",
      "eval test...\n",
      "test acc:  0.7220903\n",
      "\n",
      "\n",
      "Epoch:  609 Avg loss:  0.047565654 ; acc:  0.9948928 ; epoch time:  0.3052389621734619\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  610 Avg loss:  0.047516413 ; acc:  0.9959142 ; epoch time:  0.27481698989868164\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  611 Avg loss:  0.046988837 ; acc:  0.9948928 ; epoch time:  0.2726311683654785\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  612 Avg loss:  0.04666849 ; acc:  0.9959142 ; epoch time:  0.301222562789917\n",
      "eval test...\n",
      "test acc:  0.719715\n",
      "\n",
      "\n",
      "Epoch:  613 Avg loss:  0.046261907 ; acc:  0.9959142 ; epoch time:  0.27862119674682617\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  614 Avg loss:  0.045997057 ; acc:  0.9959142 ; epoch time:  0.29717087745666504\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  615 Avg loss:  0.045706518 ; acc:  0.9959142 ; epoch time:  0.2808220386505127\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  616 Avg loss:  0.045287047 ; acc:  0.9959142 ; epoch time:  0.27416372299194336\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  617 Avg loss:  0.045227416 ; acc:  0.9948928 ; epoch time:  0.2736368179321289\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  618 Avg loss:  0.045057278 ; acc:  0.9959142 ; epoch time:  0.28999924659729004\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  619 Avg loss:  0.044834852 ; acc:  0.9948928 ; epoch time:  0.2888453006744385\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  620 Avg loss:  0.04465957 ; acc:  0.9959142 ; epoch time:  0.2811717987060547\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  621 Avg loss:  0.044121798 ; acc:  0.9948928 ; epoch time:  0.2866957187652588\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  622 Avg loss:  0.04362276 ; acc:  0.9959142 ; epoch time:  0.2901298999786377\n",
      "eval test...\n",
      "test acc:  0.719715\n",
      "\n",
      "\n",
      "Epoch:  623 Avg loss:  0.043531872 ; acc:  0.9959142 ; epoch time:  0.27620983123779297\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  624 Avg loss:  0.043251876 ; acc:  0.9959142 ; epoch time:  0.3034346103668213\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  625 Avg loss:  0.043117642 ; acc:  0.9959142 ; epoch time:  0.27953267097473145\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  626 Avg loss:  0.042707585 ; acc:  0.9948928 ; epoch time:  0.310150146484375\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  627 Avg loss:  0.042232674 ; acc:  0.9959142 ; epoch time:  0.26405763626098633\n",
      "eval test...\n",
      "test acc:  0.7220903\n",
      "\n",
      "\n",
      "Epoch:  628 Avg loss:  0.04198569 ; acc:  0.9959142 ; epoch time:  0.29935622215270996\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  629 Avg loss:  0.041889817 ; acc:  0.9948928 ; epoch time:  0.2913055419921875\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  630 Avg loss:  0.041549787 ; acc:  0.9959142 ; epoch time:  0.27352070808410645\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  631 Avg loss:  0.041260857 ; acc:  0.9959142 ; epoch time:  0.27792978286743164\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  632 Avg loss:  0.041003887 ; acc:  0.9959142 ; epoch time:  0.28322649002075195\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  633 Avg loss:  0.040911276 ; acc:  0.9959142 ; epoch time:  0.2974886894226074\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  634 Avg loss:  0.0407684 ; acc:  0.9959142 ; epoch time:  0.27089595794677734\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  635 Avg loss:  0.040742353 ; acc:  0.9959142 ; epoch time:  0.2633953094482422\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  636 Avg loss:  0.04028497 ; acc:  0.9959142 ; epoch time:  0.2989072799682617\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  637 Avg loss:  0.03977888 ; acc:  0.9959142 ; epoch time:  0.29305219650268555\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  638 Avg loss:  0.039731033 ; acc:  0.9959142 ; epoch time:  0.269498348236084\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  639 Avg loss:  0.039712403 ; acc:  0.9959142 ; epoch time:  0.2847754955291748\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  640 Avg loss:  0.039260466 ; acc:  0.9959142 ; epoch time:  0.29700779914855957\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  641 Avg loss:  0.03898898 ; acc:  0.9959142 ; epoch time:  0.2775850296020508\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  642 Avg loss:  0.038781233 ; acc:  0.9959142 ; epoch time:  0.2760300636291504\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  643 Avg loss:  0.038492657 ; acc:  0.9959142 ; epoch time:  0.2854349613189697\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  644 Avg loss:  0.03851935 ; acc:  0.9959142 ; epoch time:  0.2937042713165283\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  645 Avg loss:  0.038131908 ; acc:  0.9959142 ; epoch time:  0.29633545875549316\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  646 Avg loss:  0.03770614 ; acc:  0.9959142 ; epoch time:  0.28539419174194336\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  647 Avg loss:  0.03763643 ; acc:  0.9959142 ; epoch time:  0.2916855812072754\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  648 Avg loss:  0.037385296 ; acc:  0.9959142 ; epoch time:  0.298140287399292\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  649 Avg loss:  0.037049588 ; acc:  0.9959142 ; epoch time:  0.2878715991973877\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  650 Avg loss:  0.036994897 ; acc:  0.9959142 ; epoch time:  0.2712681293487549\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  651 Avg loss:  0.03660733 ; acc:  0.9959142 ; epoch time:  0.2921450138092041\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  652 Avg loss:  0.03645517 ; acc:  0.9959142 ; epoch time:  0.2892470359802246\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  653 Avg loss:  0.036634013 ; acc:  0.9959142 ; epoch time:  0.28389859199523926\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  654 Avg loss:  0.03618794 ; acc:  0.9959142 ; epoch time:  0.2861642837524414\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  655 Avg loss:  0.035720136 ; acc:  0.9959142 ; epoch time:  0.2771573066711426\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  656 Avg loss:  0.035848085 ; acc:  0.9959142 ; epoch time:  0.30438780784606934\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  657 Avg loss:  0.03564377 ; acc:  0.9959142 ; epoch time:  0.2933354377746582\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  658 Avg loss:  0.035325654 ; acc:  0.9959142 ; epoch time:  0.3036072254180908\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  659 Avg loss:  0.03531527 ; acc:  0.99693567 ; epoch time:  0.3027074337005615\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  660 Avg loss:  0.034816187 ; acc:  0.99693567 ; epoch time:  0.281524658203125\n",
      "eval test...\n",
      "test acc:  0.719715\n",
      "\n",
      "\n",
      "Epoch:  661 Avg loss:  0.03457784 ; acc:  0.9959142 ; epoch time:  0.30032944679260254\n",
      "eval test...\n",
      "test acc:  0.719715\n",
      "\n",
      "\n",
      "Epoch:  662 Avg loss:  0.034601238 ; acc:  0.99693567 ; epoch time:  0.2941153049468994\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  663 Avg loss:  0.03431518 ; acc:  0.99795717 ; epoch time:  0.2907273769378662\n",
      "eval test...\n",
      "test acc:  0.719715\n",
      "\n",
      "\n",
      "Epoch:  664 Avg loss:  0.034010433 ; acc:  0.99795717 ; epoch time:  0.297130823135376\n",
      "eval test...\n",
      "test acc:  0.719715\n",
      "\n",
      "\n",
      "Epoch:  665 Avg loss:  0.034118943 ; acc:  0.99693567 ; epoch time:  0.2933182716369629\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  666 Avg loss:  0.033557408 ; acc:  0.99795717 ; epoch time:  0.2852609157562256\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  667 Avg loss:  0.033437785 ; acc:  0.99795717 ; epoch time:  0.2746851444244385\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  668 Avg loss:  0.033262406 ; acc:  0.99693567 ; epoch time:  0.29277801513671875\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  669 Avg loss:  0.03289572 ; acc:  0.99693567 ; epoch time:  0.2992990016937256\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  670 Avg loss:  0.03287375 ; acc:  0.99795717 ; epoch time:  0.2878751754760742\n",
      "eval test...\n",
      "test acc:  0.7220903\n",
      "\n",
      "\n",
      "Epoch:  671 Avg loss:  0.032578666 ; acc:  0.99693567 ; epoch time:  0.2871971130371094\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  672 Avg loss:  0.032499094 ; acc:  0.99795717 ; epoch time:  0.27953171730041504\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  673 Avg loss:  0.03222767 ; acc:  0.99795717 ; epoch time:  0.28111934661865234\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  674 Avg loss:  0.032168254 ; acc:  0.99693567 ; epoch time:  0.28064489364624023\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  675 Avg loss:  0.03187502 ; acc:  0.99795717 ; epoch time:  0.28913354873657227\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  676 Avg loss:  0.032111667 ; acc:  0.99795717 ; epoch time:  0.30301690101623535\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  677 Avg loss:  0.031631194 ; acc:  0.99795717 ; epoch time:  0.30941271781921387\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  678 Avg loss:  0.031504083 ; acc:  0.99693567 ; epoch time:  0.3006889820098877\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  679 Avg loss:  0.031277437 ; acc:  0.99795717 ; epoch time:  0.29853391647338867\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  680 Avg loss:  0.031274367 ; acc:  0.99795717 ; epoch time:  0.28888416290283203\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  681 Avg loss:  0.030987509 ; acc:  0.99693567 ; epoch time:  0.29190945625305176\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  682 Avg loss:  0.03082588 ; acc:  0.99795717 ; epoch time:  0.29051876068115234\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  683 Avg loss:  0.030517694 ; acc:  0.99795717 ; epoch time:  0.30284571647644043\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  684 Avg loss:  0.030501867 ; acc:  0.99795717 ; epoch time:  0.2917754650115967\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  685 Avg loss:  0.030403202 ; acc:  0.99795717 ; epoch time:  0.28795599937438965\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  686 Avg loss:  0.030102769 ; acc:  0.99693567 ; epoch time:  0.3061552047729492\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  687 Avg loss:  0.029807514 ; acc:  0.99795717 ; epoch time:  0.29244375228881836\n",
      "eval test...\n",
      "test acc:  0.7173397\n",
      "\n",
      "\n",
      "Epoch:  688 Avg loss:  0.029948324 ; acc:  0.99795717 ; epoch time:  0.3071894645690918\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  689 Avg loss:  0.02978301 ; acc:  0.99795717 ; epoch time:  0.28419065475463867\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  690 Avg loss:  0.029644303 ; acc:  0.99795717 ; epoch time:  0.2950305938720703\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  691 Avg loss:  0.029553477 ; acc:  0.99795717 ; epoch time:  0.28728747367858887\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  692 Avg loss:  0.029079437 ; acc:  0.99795717 ; epoch time:  0.29334402084350586\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  693 Avg loss:  0.029043997 ; acc:  0.99795717 ; epoch time:  0.27637553215026855\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  694 Avg loss:  0.028953567 ; acc:  0.99795717 ; epoch time:  0.28670763969421387\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  695 Avg loss:  0.02876378 ; acc:  0.99795717 ; epoch time:  0.29370927810668945\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  696 Avg loss:  0.02846087 ; acc:  0.99795717 ; epoch time:  0.29576802253723145\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  697 Avg loss:  0.028340338 ; acc:  0.99795717 ; epoch time:  0.29522228240966797\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  698 Avg loss:  0.028307082 ; acc:  0.99795717 ; epoch time:  0.2802612781524658\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  699 Avg loss:  0.028087324 ; acc:  0.99795717 ; epoch time:  0.28980112075805664\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  700 Avg loss:  0.027851166 ; acc:  0.99795717 ; epoch time:  0.2860417366027832\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  701 Avg loss:  0.027643725 ; acc:  0.99795717 ; epoch time:  0.29343175888061523\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  702 Avg loss:  0.027637538 ; acc:  0.9989786 ; epoch time:  0.2898061275482178\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  703 Avg loss:  0.027502194 ; acc:  0.99795717 ; epoch time:  0.2738034725189209\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  704 Avg loss:  0.027295915 ; acc:  0.99795717 ; epoch time:  0.29110121726989746\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  705 Avg loss:  0.02700437 ; acc:  0.99795717 ; epoch time:  0.29596567153930664\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  706 Avg loss:  0.027083205 ; acc:  0.99795717 ; epoch time:  0.2764415740966797\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  707 Avg loss:  0.027026767 ; acc:  0.9989786 ; epoch time:  0.2696216106414795\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  708 Avg loss:  0.026839143 ; acc:  0.99795717 ; epoch time:  0.3157651424407959\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  709 Avg loss:  0.0264709 ; acc:  0.9989786 ; epoch time:  0.3178122043609619\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  710 Avg loss:  0.0263574 ; acc:  0.9989786 ; epoch time:  0.32384634017944336\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  711 Avg loss:  0.02653154 ; acc:  0.99795717 ; epoch time:  0.3450794219970703\n",
      "eval test...\n",
      "test acc:  0.7149644\n",
      "\n",
      "\n",
      "Epoch:  712 Avg loss:  0.0261563 ; acc:  0.9989786 ; epoch time:  0.33977532386779785\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  713 Avg loss:  0.025961913 ; acc:  0.99795717 ; epoch time:  0.33441662788391113\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  714 Avg loss:  0.025835851 ; acc:  0.99795717 ; epoch time:  0.3351607322692871\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  715 Avg loss:  0.025641078 ; acc:  0.9989786 ; epoch time:  0.362260103225708\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  716 Avg loss:  0.0256131 ; acc:  0.99795717 ; epoch time:  0.31191325187683105\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  717 Avg loss:  0.025392834 ; acc:  0.9989786 ; epoch time:  0.3341176509857178\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  718 Avg loss:  0.025148619 ; acc:  0.9989786 ; epoch time:  0.31084585189819336\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  719 Avg loss:  0.025046062 ; acc:  0.9989786 ; epoch time:  0.3722352981567383\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  720 Avg loss:  0.024855351 ; acc:  0.9989786 ; epoch time:  0.32424426078796387\n",
      "eval test...\n",
      "test acc:  0.7125891\n",
      "\n",
      "\n",
      "Epoch:  721 Avg loss:  0.024764646 ; acc:  0.9989786 ; epoch time:  0.3201324939727783\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  722 Avg loss:  0.024620647 ; acc:  0.9989786 ; epoch time:  0.34641456604003906\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  723 Avg loss:  0.024467396 ; acc:  0.9989786 ; epoch time:  0.34411096572875977\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  724 Avg loss:  0.024383646 ; acc:  0.9989786 ; epoch time:  0.33078479766845703\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  725 Avg loss:  0.024216741 ; acc:  0.9989786 ; epoch time:  0.3364732265472412\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  726 Avg loss:  0.024110364 ; acc:  0.9989786 ; epoch time:  0.34115123748779297\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  727 Avg loss:  0.023928463 ; acc:  0.9989786 ; epoch time:  0.3284034729003906\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  728 Avg loss:  0.023819888 ; acc:  0.9989786 ; epoch time:  0.3100888729095459\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  729 Avg loss:  0.023732238 ; acc:  0.9989786 ; epoch time:  0.33905982971191406\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  730 Avg loss:  0.023525253 ; acc:  0.9989786 ; epoch time:  0.31485748291015625\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  731 Avg loss:  0.023430057 ; acc:  0.9989786 ; epoch time:  0.32080602645874023\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  732 Avg loss:  0.023285346 ; acc:  0.9989786 ; epoch time:  0.32395029067993164\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  733 Avg loss:  0.023153415 ; acc:  0.9989786 ; epoch time:  0.3253507614135742\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  734 Avg loss:  0.023032827 ; acc:  0.9989786 ; epoch time:  0.339428186416626\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  735 Avg loss:  0.022902492 ; acc:  0.9989786 ; epoch time:  0.35590076446533203\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  736 Avg loss:  0.022865823 ; acc:  0.9989786 ; epoch time:  0.3576347827911377\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  737 Avg loss:  0.022760259 ; acc:  0.9989786 ; epoch time:  0.32763099670410156\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  738 Avg loss:  0.022629786 ; acc:  0.9989786 ; epoch time:  0.33567070960998535\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  739 Avg loss:  0.022503065 ; acc:  0.9989786 ; epoch time:  0.3188328742980957\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  740 Avg loss:  0.022326536 ; acc:  0.9989786 ; epoch time:  0.3411595821380615\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  741 Avg loss:  0.02225078 ; acc:  0.9989786 ; epoch time:  0.3371448516845703\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  742 Avg loss:  0.022099268 ; acc:  0.9989786 ; epoch time:  0.32355332374572754\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  743 Avg loss:  0.02199302 ; acc:  0.9989786 ; epoch time:  0.31829118728637695\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  744 Avg loss:  0.021901237 ; acc:  0.9989786 ; epoch time:  0.34711313247680664\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  745 Avg loss:  0.021846421 ; acc:  0.9989786 ; epoch time:  0.33852052688598633\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  746 Avg loss:  0.021646261 ; acc:  0.9989786 ; epoch time:  0.3177378177642822\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  747 Avg loss:  0.021612955 ; acc:  0.9989786 ; epoch time:  0.3146243095397949\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  748 Avg loss:  0.021396248 ; acc:  0.9989786 ; epoch time:  0.32506847381591797\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  749 Avg loss:  0.021437429 ; acc:  0.9989786 ; epoch time:  0.3151431083679199\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  750 Avg loss:  0.021268267 ; acc:  0.9989786 ; epoch time:  0.33238887786865234\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  751 Avg loss:  0.021127492 ; acc:  0.9989786 ; epoch time:  0.33524179458618164\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  752 Avg loss:  0.021097274 ; acc:  0.9989786 ; epoch time:  0.3463869094848633\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  753 Avg loss:  0.020954244 ; acc:  0.9989786 ; epoch time:  0.3199462890625\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  754 Avg loss:  0.020765666 ; acc:  0.9989786 ; epoch time:  0.3313124179840088\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  755 Avg loss:  0.020697873 ; acc:  0.9989786 ; epoch time:  0.3672308921813965\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  756 Avg loss:  0.020520503 ; acc:  0.9989786 ; epoch time:  0.3270425796508789\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  757 Avg loss:  0.02054709 ; acc:  0.9989786 ; epoch time:  0.3183305263519287\n",
      "eval test...\n",
      "test acc:  0.7102138\n",
      "\n",
      "\n",
      "Epoch:  758 Avg loss:  0.020378487 ; acc:  0.9989786 ; epoch time:  0.3226659297943115\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  759 Avg loss:  0.020343829 ; acc:  0.9989786 ; epoch time:  0.3529222011566162\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  760 Avg loss:  0.02013052 ; acc:  0.9989786 ; epoch time:  0.3316221237182617\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  761 Avg loss:  0.02008093 ; acc:  0.9989786 ; epoch time:  0.3562631607055664\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  762 Avg loss:  0.020006424 ; acc:  0.9989786 ; epoch time:  0.3363149166107178\n",
      "eval test...\n",
      "test acc:  0.70783854\n",
      "\n",
      "\n",
      "Epoch:  763 Avg loss:  0.019922383 ; acc:  1.0 ; epoch time:  0.3231344223022461\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  764 Avg loss:  0.01969688 ; acc:  1.0 ; epoch time:  0.320080041885376\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  765 Avg loss:  0.019587457 ; acc:  0.9989786 ; epoch time:  0.36876344680786133\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  766 Avg loss:  0.01953929 ; acc:  0.9989786 ; epoch time:  0.320188045501709\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  767 Avg loss:  0.019414637 ; acc:  1.0 ; epoch time:  0.3327324390411377\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  768 Avg loss:  0.019284619 ; acc:  0.9989786 ; epoch time:  0.3566257953643799\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  769 Avg loss:  0.019225921 ; acc:  0.9989786 ; epoch time:  0.3141210079193115\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  770 Avg loss:  0.019119276 ; acc:  1.0 ; epoch time:  0.3316216468811035\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  771 Avg loss:  0.018977657 ; acc:  1.0 ; epoch time:  0.3480854034423828\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  772 Avg loss:  0.018888107 ; acc:  1.0 ; epoch time:  0.31512880325317383\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  773 Avg loss:  0.018874165 ; acc:  1.0 ; epoch time:  0.32295823097229004\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  774 Avg loss:  0.018745225 ; acc:  1.0 ; epoch time:  0.3559753894805908\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  775 Avg loss:  0.018570598 ; acc:  0.9989786 ; epoch time:  0.344897985458374\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  776 Avg loss:  0.018553168 ; acc:  1.0 ; epoch time:  0.32234644889831543\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  777 Avg loss:  0.01855613 ; acc:  1.0 ; epoch time:  0.33293700218200684\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  778 Avg loss:  0.018443879 ; acc:  1.0 ; epoch time:  0.3367478847503662\n",
      "eval test...\n",
      "test acc:  0.70546323\n",
      "\n",
      "\n",
      "Epoch:  779 Avg loss:  0.018265208 ; acc:  1.0 ; epoch time:  0.3413259983062744\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  780 Avg loss:  0.018273817 ; acc:  1.0 ; epoch time:  0.3495631217956543\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  781 Avg loss:  0.018154442 ; acc:  1.0 ; epoch time:  0.31406378746032715\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  782 Avg loss:  0.0180667 ; acc:  1.0 ; epoch time:  0.35005760192871094\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  783 Avg loss:  0.017918302 ; acc:  1.0 ; epoch time:  0.329880952835083\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  784 Avg loss:  0.017882964 ; acc:  1.0 ; epoch time:  0.3238837718963623\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  785 Avg loss:  0.01779053 ; acc:  1.0 ; epoch time:  0.34942197799682617\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  786 Avg loss:  0.017602148 ; acc:  1.0 ; epoch time:  0.35187673568725586\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  787 Avg loss:  0.017543826 ; acc:  1.0 ; epoch time:  0.32456207275390625\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  788 Avg loss:  0.017484853 ; acc:  1.0 ; epoch time:  0.33768367767333984\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  789 Avg loss:  0.017423078 ; acc:  1.0 ; epoch time:  0.32193756103515625\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  790 Avg loss:  0.017318951 ; acc:  1.0 ; epoch time:  0.34508466720581055\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  791 Avg loss:  0.01715876 ; acc:  1.0 ; epoch time:  0.327559232711792\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  792 Avg loss:  0.017158652 ; acc:  1.0 ; epoch time:  0.32602357864379883\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  793 Avg loss:  0.017092733 ; acc:  1.0 ; epoch time:  0.31885528564453125\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  794 Avg loss:  0.016951635 ; acc:  1.0 ; epoch time:  0.3511085510253906\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  795 Avg loss:  0.016806958 ; acc:  1.0 ; epoch time:  0.3443186283111572\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  796 Avg loss:  0.01685727 ; acc:  1.0 ; epoch time:  0.33505749702453613\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  797 Avg loss:  0.016700445 ; acc:  1.0 ; epoch time:  0.32517409324645996\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  798 Avg loss:  0.016596518 ; acc:  1.0 ; epoch time:  0.37163782119750977\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  799 Avg loss:  0.016559668 ; acc:  1.0 ; epoch time:  0.3115849494934082\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  800 Avg loss:  0.016435167 ; acc:  1.0 ; epoch time:  0.31705164909362793\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  801 Avg loss:  0.016371356 ; acc:  1.0 ; epoch time:  0.31536102294921875\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  802 Avg loss:  0.016254647 ; acc:  1.0 ; epoch time:  0.3516693115234375\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  803 Avg loss:  0.016209606 ; acc:  1.0 ; epoch time:  0.311521053314209\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  804 Avg loss:  0.01611204 ; acc:  1.0 ; epoch time:  0.3237929344177246\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  805 Avg loss:  0.016009774 ; acc:  1.0 ; epoch time:  0.3334493637084961\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  806 Avg loss:  0.015931316 ; acc:  1.0 ; epoch time:  0.3470330238342285\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  807 Avg loss:  0.015828058 ; acc:  1.0 ; epoch time:  0.33100342750549316\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  808 Avg loss:  0.015755689 ; acc:  1.0 ; epoch time:  0.32956790924072266\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  809 Avg loss:  0.015678443 ; acc:  1.0 ; epoch time:  0.3446943759918213\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  810 Avg loss:  0.01560871 ; acc:  1.0 ; epoch time:  0.33631300926208496\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  811 Avg loss:  0.015501849 ; acc:  1.0 ; epoch time:  0.33457231521606445\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  812 Avg loss:  0.01539101 ; acc:  1.0 ; epoch time:  0.34157681465148926\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  813 Avg loss:  0.015309946 ; acc:  1.0 ; epoch time:  0.33368611335754395\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  814 Avg loss:  0.01523473 ; acc:  1.0 ; epoch time:  0.32553911209106445\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  815 Avg loss:  0.0151819205 ; acc:  1.0 ; epoch time:  0.3190650939941406\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  816 Avg loss:  0.015103819 ; acc:  1.0 ; epoch time:  0.34267210960388184\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  817 Avg loss:  0.014965764 ; acc:  1.0 ; epoch time:  0.3332345485687256\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  818 Avg loss:  0.014939624 ; acc:  1.0 ; epoch time:  0.3273487091064453\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  819 Avg loss:  0.0148945125 ; acc:  1.0 ; epoch time:  0.34160852432250977\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  820 Avg loss:  0.014755274 ; acc:  1.0 ; epoch time:  0.3199429512023926\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  821 Avg loss:  0.014769212 ; acc:  1.0 ; epoch time:  0.3155243396759033\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  822 Avg loss:  0.014624301 ; acc:  1.0 ; epoch time:  0.35185790061950684\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  823 Avg loss:  0.01453329 ; acc:  1.0 ; epoch time:  0.3588528633117676\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  824 Avg loss:  0.014509289 ; acc:  1.0 ; epoch time:  0.3139793872833252\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  825 Avg loss:  0.014378438 ; acc:  1.0 ; epoch time:  0.3133561611175537\n",
      "eval test...\n",
      "test acc:  0.7030879\n",
      "\n",
      "\n",
      "Epoch:  826 Avg loss:  0.014318666 ; acc:  1.0 ; epoch time:  0.33049821853637695\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  827 Avg loss:  0.0143070305 ; acc:  1.0 ; epoch time:  0.35543227195739746\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  828 Avg loss:  0.0142226815 ; acc:  1.0 ; epoch time:  0.3349776268005371\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  829 Avg loss:  0.014089879 ; acc:  1.0 ; epoch time:  0.31281518936157227\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  830 Avg loss:  0.0140975155 ; acc:  1.0 ; epoch time:  0.3507523536682129\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  831 Avg loss:  0.014002869 ; acc:  1.0 ; epoch time:  0.34045863151550293\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  832 Avg loss:  0.013886752 ; acc:  1.0 ; epoch time:  0.32612037658691406\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  833 Avg loss:  0.013834597 ; acc:  1.0 ; epoch time:  0.29888153076171875\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  834 Avg loss:  0.013770005 ; acc:  1.0 ; epoch time:  0.3571462631225586\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  835 Avg loss:  0.01369476 ; acc:  1.0 ; epoch time:  0.3039131164550781\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  836 Avg loss:  0.013624085 ; acc:  1.0 ; epoch time:  0.3156740665435791\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  837 Avg loss:  0.013562494 ; acc:  1.0 ; epoch time:  0.3258397579193115\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  838 Avg loss:  0.013517817 ; acc:  1.0 ; epoch time:  0.3376448154449463\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  839 Avg loss:  0.013423029 ; acc:  1.0 ; epoch time:  0.32166266441345215\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  840 Avg loss:  0.013359654 ; acc:  1.0 ; epoch time:  0.3000338077545166\n",
      "eval test...\n",
      "test acc:  0.7007126\n",
      "\n",
      "\n",
      "Epoch:  841 Avg loss:  0.013340736 ; acc:  1.0 ; epoch time:  0.31551623344421387\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  842 Avg loss:  0.013253012 ; acc:  1.0 ; epoch time:  0.3277568817138672\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  843 Avg loss:  0.01317733 ; acc:  1.0 ; epoch time:  0.33193111419677734\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  844 Avg loss:  0.013107181 ; acc:  1.0 ; epoch time:  0.33109402656555176\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  845 Avg loss:  0.013082103 ; acc:  1.0 ; epoch time:  0.3381235599517822\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  846 Avg loss:  0.012980704 ; acc:  1.0 ; epoch time:  0.3459048271179199\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  847 Avg loss:  0.0129565075 ; acc:  1.0 ; epoch time:  0.3290109634399414\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  848 Avg loss:  0.012888782 ; acc:  1.0 ; epoch time:  0.3324556350708008\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  849 Avg loss:  0.0127960965 ; acc:  1.0 ; epoch time:  0.3614668846130371\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  850 Avg loss:  0.012774714 ; acc:  1.0 ; epoch time:  0.3285224437713623\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  851 Avg loss:  0.012714442 ; acc:  1.0 ; epoch time:  0.34360361099243164\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  852 Avg loss:  0.012620213 ; acc:  1.0 ; epoch time:  0.36570024490356445\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  853 Avg loss:  0.012629618 ; acc:  1.0 ; epoch time:  0.3493812084197998\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  854 Avg loss:  0.012504504 ; acc:  1.0 ; epoch time:  0.3307771682739258\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  855 Avg loss:  0.012466329 ; acc:  1.0 ; epoch time:  0.3178400993347168\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  856 Avg loss:  0.012435592 ; acc:  1.0 ; epoch time:  0.3226633071899414\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  857 Avg loss:  0.012326451 ; acc:  1.0 ; epoch time:  0.31820106506347656\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  858 Avg loss:  0.012293137 ; acc:  1.0 ; epoch time:  0.3507676124572754\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  859 Avg loss:  0.012224226 ; acc:  1.0 ; epoch time:  0.32177305221557617\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  860 Avg loss:  0.012161059 ; acc:  1.0 ; epoch time:  0.32552528381347656\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  861 Avg loss:  0.012106727 ; acc:  1.0 ; epoch time:  0.3321824073791504\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  862 Avg loss:  0.012066867 ; acc:  1.0 ; epoch time:  0.31694531440734863\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  863 Avg loss:  0.012003325 ; acc:  1.0 ; epoch time:  0.32790184020996094\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  864 Avg loss:  0.011942914 ; acc:  1.0 ; epoch time:  0.33971476554870605\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  865 Avg loss:  0.011898967 ; acc:  1.0 ; epoch time:  0.3229250907897949\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  866 Avg loss:  0.011853555 ; acc:  1.0 ; epoch time:  0.34604763984680176\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  867 Avg loss:  0.011791572 ; acc:  1.0 ; epoch time:  0.3029766082763672\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  868 Avg loss:  0.011742791 ; acc:  1.0 ; epoch time:  0.3094899654388428\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  869 Avg loss:  0.01169512 ; acc:  1.0 ; epoch time:  0.36052656173706055\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  870 Avg loss:  0.011683677 ; acc:  1.0 ; epoch time:  0.3349568843841553\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  871 Avg loss:  0.011613269 ; acc:  1.0 ; epoch time:  0.33507370948791504\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  872 Avg loss:  0.011541593 ; acc:  1.0 ; epoch time:  0.3410627841949463\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  873 Avg loss:  0.011543554 ; acc:  1.0 ; epoch time:  0.32517504692077637\n",
      "eval test...\n",
      "test acc:  0.68883616\n",
      "\n",
      "\n",
      "Epoch:  874 Avg loss:  0.01143993 ; acc:  1.0 ; epoch time:  0.3273465633392334\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  875 Avg loss:  0.011403142 ; acc:  1.0 ; epoch time:  0.332533597946167\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  876 Avg loss:  0.011343159 ; acc:  1.0 ; epoch time:  0.33895158767700195\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  877 Avg loss:  0.011298314 ; acc:  1.0 ; epoch time:  0.31614255905151367\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  878 Avg loss:  0.011264876 ; acc:  1.0 ; epoch time:  0.3440556526184082\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  879 Avg loss:  0.01121227 ; acc:  1.0 ; epoch time:  0.3313252925872803\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  880 Avg loss:  0.01116526 ; acc:  1.0 ; epoch time:  0.32515597343444824\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  881 Avg loss:  0.011169735 ; acc:  1.0 ; epoch time:  0.32646751403808594\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  882 Avg loss:  0.0110991765 ; acc:  1.0 ; epoch time:  0.32642078399658203\n",
      "eval test...\n",
      "test acc:  0.6983373\n",
      "\n",
      "\n",
      "Epoch:  883 Avg loss:  0.011026185 ; acc:  1.0 ; epoch time:  0.34000086784362793\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  884 Avg loss:  0.0109920595 ; acc:  1.0 ; epoch time:  0.33622002601623535\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  885 Avg loss:  0.010949926 ; acc:  1.0 ; epoch time:  0.34067869186401367\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  886 Avg loss:  0.010870362 ; acc:  1.0 ; epoch time:  0.32338404655456543\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  887 Avg loss:  0.010885008 ; acc:  1.0 ; epoch time:  0.37740564346313477\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  888 Avg loss:  0.010784264 ; acc:  1.0 ; epoch time:  0.34760117530822754\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  889 Avg loss:  0.010723495 ; acc:  1.0 ; epoch time:  0.30129122734069824\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  890 Avg loss:  0.010723346 ; acc:  1.0 ; epoch time:  0.32212257385253906\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  891 Avg loss:  0.010612335 ; acc:  1.0 ; epoch time:  0.3411076068878174\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  892 Avg loss:  0.010595951 ; acc:  1.0 ; epoch time:  0.3246269226074219\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  893 Avg loss:  0.010533603 ; acc:  1.0 ; epoch time:  0.3298375606536865\n",
      "eval test...\n",
      "test acc:  0.6912114\n",
      "\n",
      "\n",
      "Epoch:  894 Avg loss:  0.010470751 ; acc:  1.0 ; epoch time:  0.3198659420013428\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  895 Avg loss:  0.010454285 ; acc:  1.0 ; epoch time:  0.32538390159606934\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  896 Avg loss:  0.010383941 ; acc:  1.0 ; epoch time:  0.324756383895874\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  897 Avg loss:  0.010338272 ; acc:  1.0 ; epoch time:  0.3233039379119873\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  898 Avg loss:  0.010293542 ; acc:  1.0 ; epoch time:  0.3470311164855957\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  899 Avg loss:  0.010261767 ; acc:  1.0 ; epoch time:  0.3205127716064453\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  900 Avg loss:  0.010209876 ; acc:  1.0 ; epoch time:  0.3279848098754883\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  901 Avg loss:  0.010163686 ; acc:  1.0 ; epoch time:  0.32326292991638184\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  902 Avg loss:  0.010118452 ; acc:  1.0 ; epoch time:  0.31575751304626465\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  903 Avg loss:  0.010085153 ; acc:  1.0 ; epoch time:  0.3191800117492676\n",
      "eval test...\n",
      "test acc:  0.6935867\n",
      "\n",
      "\n",
      "Epoch:  904 Avg loss:  0.010034816 ; acc:  1.0 ; epoch time:  0.3351583480834961\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  905 Avg loss:  0.010003148 ; acc:  1.0 ; epoch time:  0.3520934581756592\n",
      "eval test...\n",
      "test acc:  0.695962\n",
      "\n",
      "\n",
      "Epoch:  906 Avg loss:  0.009948938 ; acc:  1.0 ; epoch time:  0.32729458808898926\n",
      "early stop\n"
     ]
    }
   ],
   "source": [
    "dataset.setting = 3\n",
    "dataset.subgraph = False\n",
    "dataset.remap = True\n",
    "#train(gcn_model, dataset, max_epoch=1000, lr=0.005, train_batch_size = 1024, temp_name = 'community_temp')\n",
    "node_pred_task_train(gcn_model, dataset, max_epoch=1000, lr=0.005, temp_name='community_temp', train_rate = 0.70, save_model = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_model = torch.load('./checkpoint/community_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "prepare dataloader\n",
      "done\n",
      "Epoch:  0 Avg loss:  2.9537191 ; acc:  0.7151807 ; epoch time:  2.35606050491333\n",
      "Epoch:  1 Avg loss:  1.6656601 ; acc:  0.7950278 ; epoch time:  2.291776657104492\n",
      "Epoch:  2 Avg loss:  1.4816986 ; acc:  0.8152323 ; epoch time:  2.270766258239746\n",
      "Epoch:  3 Avg loss:  1.7021397 ; acc:  0.8165064 ; epoch time:  2.34914493560791\n",
      "Epoch:  4 Avg loss:  1.85531 ; acc:  0.8166733 ; epoch time:  2.308025598526001\n",
      "Epoch:  5 Avg loss:  1.8359437 ; acc:  0.8167643 ; epoch time:  2.39426589012146\n",
      "Epoch:  6 Avg loss:  1.6931294 ; acc:  0.81711316 ; epoch time:  2.3895483016967773\n",
      "Epoch:  7 Avg loss:  1.5028516 ; acc:  0.81863 ; epoch time:  2.3883438110351562\n",
      "Epoch:  8 Avg loss:  1.3349968 ; acc:  0.818812 ; epoch time:  2.5111613273620605\n",
      "Epoch:  9 Avg loss:  1.2339685 ; acc:  0.8165216 ; epoch time:  2.422281503677368\n",
      "Epoch:  10 Avg loss:  1.2117757 ; acc:  0.8129418 ; epoch time:  2.4183578491210938\n",
      "Epoch:  11 Avg loss:  1.2392082 ; acc:  0.80783004 ; epoch time:  2.4235286712646484\n",
      "Epoch:  12 Avg loss:  1.2656018 ; acc:  0.80212665 ; epoch time:  2.3476006984710693\n",
      "Epoch:  13 Avg loss:  1.2539108 ; acc:  0.8006553 ; epoch time:  2.3322789669036865\n",
      "Epoch:  14 Avg loss:  1.2000563 ; acc:  0.80274856 ; epoch time:  2.3185763359069824\n",
      "Epoch:  15 Avg loss:  1.1234539 ; acc:  0.80699575 ; epoch time:  2.5091660022735596\n",
      "Epoch:  16 Avg loss:  1.0482411 ; acc:  0.81084853 ; epoch time:  2.3431649208068848\n",
      "Epoch:  17 Avg loss:  0.9917721 ; acc:  0.8155356 ; epoch time:  2.3027639389038086\n",
      "Epoch:  18 Avg loss:  0.9573872 ; acc:  0.81793225 ; epoch time:  2.32840895652771\n",
      "Epoch:  19 Avg loss:  0.9393942 ; acc:  0.8187362 ; epoch time:  2.315809726715088\n",
      "Epoch:  20 Avg loss:  0.9288495 ; acc:  0.81976765 ; epoch time:  2.320291757583618\n",
      "Epoch:  21 Avg loss:  0.91734815 ; acc:  0.8202227 ; epoch time:  2.5481579303741455\n",
      "Epoch:  22 Avg loss:  0.8996752 ; acc:  0.8202379 ; epoch time:  2.6726677417755127\n",
      "Epoch:  23 Avg loss:  0.87473136 ; acc:  0.8206929 ; epoch time:  2.37493896484375\n",
      "Epoch:  24 Avg loss:  0.8443519 ; acc:  0.82045025 ; epoch time:  2.327803134918213\n",
      "Epoch:  25 Avg loss:  0.81202567 ; acc:  0.8205109 ; epoch time:  2.3774101734161377\n",
      "Epoch:  26 Avg loss:  0.78147876 ; acc:  0.8204047 ; epoch time:  2.302241563796997\n",
      "Epoch:  27 Avg loss:  0.75555366 ; acc:  0.8194946 ; epoch time:  2.4196722507476807\n",
      "Epoch:  28 Avg loss:  0.73573047 ; acc:  0.81885755 ; epoch time:  2.475539445877075\n",
      "Epoch:  29 Avg loss:  0.72165453 ; acc:  0.81724966 ; epoch time:  2.4535036087036133\n",
      "Epoch:  30 Avg loss:  0.7115074 ; acc:  0.8161272 ; epoch time:  2.522678852081299\n",
      "Epoch:  31 Avg loss:  0.7027233 ; acc:  0.81473166 ; epoch time:  2.3736934661865234\n",
      "Epoch:  32 Avg loss:  0.6930935 ; acc:  0.814398 ; epoch time:  2.4655869007110596\n",
      "Epoch:  33 Avg loss:  0.68140966 ; acc:  0.81427664 ; epoch time:  2.2975142002105713\n",
      "Epoch:  34 Avg loss:  0.6676955 ; acc:  0.8147772 ; epoch time:  2.357067346572876\n",
      "Epoch:  35 Avg loss:  0.6530135 ; acc:  0.81532323 ; epoch time:  2.3377480506896973\n",
      "Epoch:  36 Avg loss:  0.6388596 ; acc:  0.81677943 ; epoch time:  2.3771889209747314\n",
      "Epoch:  37 Avg loss:  0.62642807 ; acc:  0.8180384 ; epoch time:  2.387082576751709\n",
      "Epoch:  38 Avg loss:  0.61635625 ; acc:  0.81893337 ; epoch time:  2.2999463081359863\n",
      "Epoch:  39 Avg loss:  0.6085468 ; acc:  0.81966144 ; epoch time:  2.418018341064453\n",
      "Epoch:  40 Avg loss:  0.60244477 ; acc:  0.82029855 ; epoch time:  2.4117228984832764\n",
      "Epoch:  41 Avg loss:  0.59739023 ; acc:  0.82035923 ; epoch time:  2.368082284927368\n",
      "Epoch:  42 Avg loss:  0.5927043 ; acc:  0.8206474 ; epoch time:  2.310389518737793\n",
      "Epoch:  43 Avg loss:  0.58786637 ; acc:  0.8207536 ; epoch time:  2.3138041496276855\n",
      "Epoch:  44 Avg loss:  0.5827332 ; acc:  0.82157266 ; epoch time:  2.3078792095184326\n",
      "Epoch:  45 Avg loss:  0.57740337 ; acc:  0.82198226 ; epoch time:  2.3045012950897217\n",
      "Epoch:  46 Avg loss:  0.5721247 ; acc:  0.82210356 ; epoch time:  2.3041610717773438\n",
      "Epoch:  47 Avg loss:  0.56721437 ; acc:  0.82189125 ; epoch time:  2.308088541030884\n",
      "Epoch:  48 Avg loss:  0.562892 ; acc:  0.8215575 ; epoch time:  2.3196990489959717\n",
      "Epoch:  49 Avg loss:  0.5592372 ; acc:  0.82120866 ; epoch time:  2.3408262729644775\n",
      "Epoch:  50 Avg loss:  0.55616814 ; acc:  0.8215575 ; epoch time:  2.403032064437866\n",
      "Epoch:  51 Avg loss:  0.55354565 ; acc:  0.82125413 ; epoch time:  2.3653805255889893\n",
      "Epoch:  52 Avg loss:  0.55113584 ; acc:  0.8211783 ; epoch time:  2.3962249755859375\n",
      "Epoch:  53 Avg loss:  0.5487552 ; acc:  0.8211783 ; epoch time:  2.3912882804870605\n",
      "Epoch:  54 Avg loss:  0.5463507 ; acc:  0.8214817 ; epoch time:  2.290276050567627\n",
      "Epoch:  55 Avg loss:  0.5439296 ; acc:  0.8218154 ; epoch time:  2.3133678436279297\n",
      "Epoch:  56 Avg loss:  0.5415686 ; acc:  0.8223918 ; epoch time:  2.4222681522369385\n",
      "Epoch:  57 Avg loss:  0.53941673 ; acc:  0.8227255 ; epoch time:  2.309936046600342\n",
      "Epoch:  58 Avg loss:  0.53757894 ; acc:  0.8227558 ; epoch time:  2.3383126258850098\n",
      "Epoch:  59 Avg loss:  0.5360668 ; acc:  0.82287717 ; epoch time:  2.2938637733459473\n",
      "Epoch:  60 Avg loss:  0.53478914 ; acc:  0.8229227 ; epoch time:  2.3614368438720703\n",
      "Epoch:  61 Avg loss:  0.5335984 ; acc:  0.82316536 ; epoch time:  2.3297550678253174\n",
      "Epoch:  62 Avg loss:  0.5323755 ; acc:  0.82308954 ; epoch time:  2.31896710395813\n",
      "Epoch:  63 Avg loss:  0.5310466 ; acc:  0.8231199 ; epoch time:  2.3028793334960938\n",
      "Epoch:  64 Avg loss:  0.5295953 ; acc:  0.8232867 ; epoch time:  2.3292055130004883\n",
      "Epoch:  65 Avg loss:  0.52806944 ; acc:  0.82342327 ; epoch time:  2.3003733158111572\n",
      "Epoch:  66 Avg loss:  0.52654743 ; acc:  0.823666 ; epoch time:  2.304971218109131\n",
      "Epoch:  67 Avg loss:  0.52509606 ; acc:  0.82369626 ; epoch time:  2.3736326694488525\n",
      "Epoch:  68 Avg loss:  0.52375644 ; acc:  0.82395416 ; epoch time:  2.4082303047180176\n",
      "Epoch:  69 Avg loss:  0.52255106 ; acc:  0.82403 ; epoch time:  2.5044522285461426\n",
      "Epoch:  70 Avg loss:  0.521427 ; acc:  0.8244092 ; epoch time:  2.5285677909851074\n",
      "Epoch:  71 Avg loss:  0.52031994 ; acc:  0.82439405 ; epoch time:  2.4300613403320312\n",
      "Epoch:  72 Avg loss:  0.5191717 ; acc:  0.8247429 ; epoch time:  2.324611186981201\n",
      "Epoch:  73 Avg loss:  0.51796764 ; acc:  0.82490975 ; epoch time:  2.3568382263183594\n",
      "Epoch:  74 Avg loss:  0.51673543 ; acc:  0.8250918 ; epoch time:  2.3422205448150635\n",
      "Epoch:  75 Avg loss:  0.5155329 ; acc:  0.82537997 ; epoch time:  2.324960947036743\n",
      "Epoch:  76 Avg loss:  0.5144007 ; acc:  0.8256227 ; epoch time:  2.3292882442474365\n",
      "Epoch:  77 Avg loss:  0.5133565 ; acc:  0.825471 ; epoch time:  2.357241630554199\n",
      "Epoch:  78 Avg loss:  0.512386 ; acc:  0.82554686 ; epoch time:  2.3648641109466553\n",
      "Epoch:  79 Avg loss:  0.511453 ; acc:  0.82560754 ; epoch time:  2.3685033321380615\n",
      "Epoch:  80 Avg loss:  0.5105132 ; acc:  0.82569855 ; epoch time:  2.3895652294158936\n",
      "Epoch:  81 Avg loss:  0.5095477 ; acc:  0.82598674 ; epoch time:  2.377072811126709\n",
      "Epoch:  82 Avg loss:  0.5085622 ; acc:  0.82612324 ; epoch time:  2.2926411628723145\n",
      "Epoch:  83 Avg loss:  0.50757706 ; acc:  0.8261688 ; epoch time:  2.330204486846924\n",
      "Epoch:  84 Avg loss:  0.5066179 ; acc:  0.82645696 ; epoch time:  2.420717239379883\n",
      "Epoch:  85 Avg loss:  0.5056974 ; acc:  0.8264873 ; epoch time:  2.416577100753784\n",
      "Epoch:  86 Avg loss:  0.50481343 ; acc:  0.8265783 ; epoch time:  2.37823224067688\n",
      "Epoch:  87 Avg loss:  0.5039538 ; acc:  0.82666934 ; epoch time:  2.404817819595337\n",
      "Epoch:  88 Avg loss:  0.5031053 ; acc:  0.8266238 ; epoch time:  2.3656349182128906\n",
      "Epoch:  89 Avg loss:  0.5022631 ; acc:  0.82683617 ; epoch time:  2.4100613594055176\n",
      "Epoch:  90 Avg loss:  0.5014298 ; acc:  0.8269272 ; epoch time:  2.3396310806274414\n",
      "Epoch:  91 Avg loss:  0.500619 ; acc:  0.82697266 ; epoch time:  2.322117328643799\n",
      "Epoch:  92 Avg loss:  0.49983788 ; acc:  0.8271699 ; epoch time:  2.439056873321533\n",
      "Epoch:  93 Avg loss:  0.49908805 ; acc:  0.8274884 ; epoch time:  2.3880774974823\n",
      "Epoch:  94 Avg loss:  0.498358 ; acc:  0.82767045 ; epoch time:  2.3696210384368896\n",
      "Epoch:  95 Avg loss:  0.4976326 ; acc:  0.82767045 ; epoch time:  2.3997297286987305\n",
      "Epoch:  96 Avg loss:  0.49691275 ; acc:  0.8275339 ; epoch time:  2.5173065662384033\n",
      "Epoch:  97 Avg loss:  0.49621037 ; acc:  0.8276401 ; epoch time:  2.4174365997314453\n",
      "Epoch:  98 Avg loss:  0.4955322 ; acc:  0.8277463 ; epoch time:  2.451948881149292\n",
      "Epoch:  99 Avg loss:  0.49487874 ; acc:  0.82780695 ; epoch time:  2.3911869525909424\n",
      "Epoch:  100 Avg loss:  0.49424312 ; acc:  0.82767045 ; epoch time:  2.530226230621338\n",
      "Epoch:  101 Avg loss:  0.49362206 ; acc:  0.8274732 ; epoch time:  2.389425754547119\n",
      "Epoch:  102 Avg loss:  0.49301675 ; acc:  0.8275339 ; epoch time:  2.4350554943084717\n",
      "Epoch:  103 Avg loss:  0.4924285 ; acc:  0.8277766 ; epoch time:  2.41042423248291\n",
      "Epoch:  104 Avg loss:  0.4918584 ; acc:  0.82780695 ; epoch time:  2.3582420349121094\n",
      "Epoch:  105 Avg loss:  0.49131143 ; acc:  0.8277766 ; epoch time:  2.332655668258667\n",
      "Epoch:  106 Avg loss:  0.49078226 ; acc:  0.8280193 ; epoch time:  2.399312734603882\n",
      "Epoch:  107 Avg loss:  0.4902688 ; acc:  0.827989 ; epoch time:  2.333590507507324\n",
      "Epoch:  108 Avg loss:  0.48976824 ; acc:  0.827989 ; epoch time:  2.331205368041992\n",
      "Epoch:  109 Avg loss:  0.48928094 ; acc:  0.82794344 ; epoch time:  2.387117385864258\n",
      "Epoch:  110 Avg loss:  0.48880956 ; acc:  0.82835305 ; epoch time:  2.4644839763641357\n",
      "Epoch:  111 Avg loss:  0.48835418 ; acc:  0.82835305 ; epoch time:  2.3616855144500732\n",
      "Epoch:  112 Avg loss:  0.48791417 ; acc:  0.8282772 ; epoch time:  2.378268241882324\n",
      "Epoch:  113 Avg loss:  0.487486 ; acc:  0.82826203 ; epoch time:  2.43452787399292\n",
      "Epoch:  114 Avg loss:  0.48706657 ; acc:  0.8283985 ; epoch time:  2.3060057163238525\n",
      "Epoch:  115 Avg loss:  0.48665679 ; acc:  0.82842886 ; epoch time:  2.3753669261932373\n",
      "Epoch:  116 Avg loss:  0.48625877 ; acc:  0.828444 ; epoch time:  2.3657326698303223\n",
      "Epoch:  117 Avg loss:  0.48587275 ; acc:  0.8283075 ; epoch time:  2.392486333847046\n",
      "Epoch:  118 Avg loss:  0.48549688 ; acc:  0.8283682 ; epoch time:  2.313706398010254\n",
      "Epoch:  119 Avg loss:  0.48513064 ; acc:  0.82858056 ; epoch time:  2.6040687561035156\n",
      "Epoch:  120 Avg loss:  0.4847699 ; acc:  0.82858056 ; epoch time:  2.483656644821167\n",
      "Epoch:  121 Avg loss:  0.4844181 ; acc:  0.82864124 ; epoch time:  2.470418691635132\n",
      "Epoch:  122 Avg loss:  0.4840758 ; acc:  0.8286564 ; epoch time:  2.400740385055542\n",
      "Epoch:  123 Avg loss:  0.4837431 ; acc:  0.8286564 ; epoch time:  2.4097955226898193\n",
      "Epoch:  124 Avg loss:  0.48341888 ; acc:  0.82864124 ; epoch time:  2.3931124210357666\n",
      "Epoch:  125 Avg loss:  0.48310268 ; acc:  0.82864124 ; epoch time:  2.5924110412597656\n",
      "Epoch:  126 Avg loss:  0.48279315 ; acc:  0.82862604 ; epoch time:  2.4724948406219482\n",
      "Epoch:  127 Avg loss:  0.48249143 ; acc:  0.8284592 ; epoch time:  2.458733558654785\n",
      "Epoch:  128 Avg loss:  0.48219755 ; acc:  0.8283682 ; epoch time:  2.4144277572631836\n",
      "Epoch:  129 Avg loss:  0.48190966 ; acc:  0.8283682 ; epoch time:  2.4417107105255127\n",
      "Epoch:  130 Avg loss:  0.48162654 ; acc:  0.8283985 ; epoch time:  2.5290372371673584\n",
      "Epoch:  131 Avg loss:  0.48134774 ; acc:  0.8284592 ; epoch time:  2.432107925415039\n",
      "Epoch:  132 Avg loss:  0.4810743 ; acc:  0.828535 ; epoch time:  2.4157726764678955\n",
      "Epoch:  133 Avg loss:  0.4808067 ; acc:  0.8286564 ; epoch time:  2.4073078632354736\n",
      "Epoch:  134 Avg loss:  0.4805432 ; acc:  0.8287019 ; epoch time:  2.3864753246307373\n",
      "Epoch:  135 Avg loss:  0.48028296 ; acc:  0.8286716 ; epoch time:  2.3705081939697266\n",
      "Epoch:  136 Avg loss:  0.48002687 ; acc:  0.8287626 ; epoch time:  2.4218125343322754\n",
      "Epoch:  137 Avg loss:  0.47977507 ; acc:  0.8287929 ; epoch time:  2.409912347793579\n",
      "Epoch:  138 Avg loss:  0.47952646 ; acc:  0.8287019 ; epoch time:  2.449153423309326\n",
      "Epoch:  139 Avg loss:  0.47927982 ; acc:  0.82882327 ; epoch time:  2.3638455867767334\n",
      "Epoch:  140 Avg loss:  0.47903594 ; acc:  0.8289901 ; epoch time:  2.388406753540039\n",
      "Epoch:  141 Avg loss:  0.4787946 ; acc:  0.82900524 ; epoch time:  2.4111690521240234\n",
      "Epoch:  142 Avg loss:  0.4785565 ; acc:  0.8289294 ; epoch time:  2.352360963821411\n",
      "Epoch:  143 Avg loss:  0.4783207 ; acc:  0.8290356 ; epoch time:  2.423097610473633\n",
      "Epoch:  144 Avg loss:  0.4780867 ; acc:  0.82911146 ; epoch time:  2.5332536697387695\n",
      "Epoch:  145 Avg loss:  0.47785458 ; acc:  0.82909626 ; epoch time:  2.389190435409546\n",
      "Epoch:  146 Avg loss:  0.477625 ; acc:  0.82915694 ; epoch time:  2.400761604309082\n",
      "Epoch:  147 Avg loss:  0.4773963 ; acc:  0.82924795 ; epoch time:  2.374518394470215\n",
      "Epoch:  148 Avg loss:  0.4771701 ; acc:  0.82917213 ; epoch time:  2.3866283893585205\n",
      "Epoch:  149 Avg loss:  0.47694626 ; acc:  0.8293086 ; epoch time:  2.392671823501587\n",
      "Epoch:  150 Avg loss:  0.47672513 ; acc:  0.82943 ; epoch time:  2.355231523513794\n",
      "Epoch:  151 Avg loss:  0.47650486 ; acc:  0.82941484 ; epoch time:  2.3731539249420166\n",
      "Epoch:  152 Avg loss:  0.47628567 ; acc:  0.8295817 ; epoch time:  2.384835958480835\n",
      "Epoch:  153 Avg loss:  0.47606802 ; acc:  0.8296727 ; epoch time:  2.363673686981201\n",
      "Epoch:  154 Avg loss:  0.4758524 ; acc:  0.82970303 ; epoch time:  2.3922252655029297\n",
      "Epoch:  155 Avg loss:  0.4756371 ; acc:  0.8297334 ; epoch time:  2.4491188526153564\n",
      "Epoch:  156 Avg loss:  0.47542182 ; acc:  0.8298244 ; epoch time:  2.4348573684692383\n",
      "Epoch:  157 Avg loss:  0.47520715 ; acc:  0.83000636 ; epoch time:  2.388278007507324\n",
      "Epoch:  158 Avg loss:  0.4749926 ; acc:  0.83006704 ; epoch time:  2.449451446533203\n",
      "Epoch:  159 Avg loss:  0.47477984 ; acc:  0.8300974 ; epoch time:  2.4603471755981445\n",
      "Epoch:  160 Avg loss:  0.47456843 ; acc:  0.8302036 ; epoch time:  2.3888790607452393\n",
      "Epoch:  161 Avg loss:  0.47435948 ; acc:  0.83023393 ; epoch time:  2.384970188140869\n",
      "Epoch:  162 Avg loss:  0.47415185 ; acc:  0.8302946 ; epoch time:  2.406581401824951\n",
      "Epoch:  163 Avg loss:  0.47394413 ; acc:  0.83030975 ; epoch time:  2.4092917442321777\n",
      "Epoch:  164 Avg loss:  0.47374007 ; acc:  0.8303401 ; epoch time:  2.431844711303711\n",
      "Epoch:  165 Avg loss:  0.47353935 ; acc:  0.8304463 ; epoch time:  2.4248695373535156\n",
      "Epoch:  166 Avg loss:  0.47333977 ; acc:  0.8304463 ; epoch time:  2.4505069255828857\n",
      "Epoch:  167 Avg loss:  0.4731417 ; acc:  0.83061314 ; epoch time:  2.3690295219421387\n",
      "Epoch:  168 Avg loss:  0.4729457 ; acc:  0.83059794 ; epoch time:  2.4411327838897705\n",
      "Epoch:  169 Avg loss:  0.4727521 ; acc:  0.8306435 ; epoch time:  2.445010185241699\n",
      "Epoch:  170 Avg loss:  0.47255942 ; acc:  0.8306738 ; epoch time:  2.3859121799468994\n",
      "Epoch:  171 Avg loss:  0.472368 ; acc:  0.83077997 ; epoch time:  2.3919270038604736\n",
      "Epoch:  172 Avg loss:  0.47217792 ; acc:  0.83074963 ; epoch time:  2.407770872116089\n",
      "Epoch:  173 Avg loss:  0.47198975 ; acc:  0.8307345 ; epoch time:  2.3924612998962402\n",
      "Epoch:  174 Avg loss:  0.4718035 ; acc:  0.8308255 ; epoch time:  2.3866212368011475\n",
      "Epoch:  175 Avg loss:  0.47161856 ; acc:  0.83085585 ; epoch time:  2.354522228240967\n",
      "Epoch:  176 Avg loss:  0.47143564 ; acc:  0.8309165 ; epoch time:  2.38897967338562\n",
      "Epoch:  177 Avg loss:  0.47125474 ; acc:  0.83099234 ; epoch time:  2.4025840759277344\n",
      "Epoch:  178 Avg loss:  0.47107568 ; acc:  0.831053 ; epoch time:  2.388479709625244\n",
      "Epoch:  179 Avg loss:  0.4708979 ; acc:  0.8311137 ; epoch time:  2.376370429992676\n",
      "Epoch:  180 Avg loss:  0.47072056 ; acc:  0.8311744 ; epoch time:  2.398348093032837\n",
      "Epoch:  181 Avg loss:  0.47054425 ; acc:  0.8310985 ; epoch time:  2.384000539779663\n",
      "Epoch:  182 Avg loss:  0.47036892 ; acc:  0.83114403 ; epoch time:  2.4270544052124023\n",
      "Epoch:  183 Avg loss:  0.47019494 ; acc:  0.8311744 ; epoch time:  2.415015935897827\n",
      "Epoch:  184 Avg loss:  0.47002146 ; acc:  0.83138674 ; epoch time:  2.3684864044189453\n",
      "Epoch:  185 Avg loss:  0.4698491 ; acc:  0.83138674 ; epoch time:  2.369004487991333\n",
      "Epoch:  186 Avg loss:  0.46967706 ; acc:  0.83138674 ; epoch time:  2.3998305797576904\n",
      "Epoch:  187 Avg loss:  0.4695049 ; acc:  0.8314929 ; epoch time:  2.35921311378479\n",
      "Epoch:  188 Avg loss:  0.4693334 ; acc:  0.83147776 ; epoch time:  2.4642293453216553\n",
      "Epoch:  189 Avg loss:  0.46916375 ; acc:  0.8314474 ; epoch time:  2.397326946258545\n",
      "Epoch:  190 Avg loss:  0.46899566 ; acc:  0.8314171 ; epoch time:  2.388960361480713\n",
      "Epoch:  191 Avg loss:  0.468828 ; acc:  0.83152324 ; epoch time:  2.3788959980010986\n",
      "Epoch:  192 Avg loss:  0.46866292 ; acc:  0.8315081 ; epoch time:  2.37900972366333\n",
      "Epoch:  193 Avg loss:  0.4684991 ; acc:  0.8315536 ; epoch time:  2.374307632446289\n",
      "Epoch:  194 Avg loss:  0.46833578 ; acc:  0.83159906 ; epoch time:  2.409303665161133\n",
      "Epoch:  195 Avg loss:  0.46817315 ; acc:  0.8316446 ; epoch time:  2.3837361335754395\n",
      "Epoch:  196 Avg loss:  0.46801144 ; acc:  0.83165973 ; epoch time:  2.4199254512786865\n",
      "Epoch:  197 Avg loss:  0.46785074 ; acc:  0.83175075 ; epoch time:  2.3876898288726807\n",
      "Epoch:  198 Avg loss:  0.46769065 ; acc:  0.8317356 ; epoch time:  2.4420995712280273\n",
      "Epoch:  199 Avg loss:  0.46753114 ; acc:  0.83184177 ; epoch time:  2.44450044631958\n"
     ]
    }
   ],
   "source": [
    "dataset.subgraph = True\n",
    "dataset.remap = True\n",
    "train(gcn_model, dataset, max_epoch=200, lr=0.005, train_batch_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:  0 Avg loss:  0.71721673 ; acc:  0.9121429 ; epoch time:  0.020233631134033203\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(0.9121429, dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "dataset.setting = 3\n",
    "dataset.subgraph = False\n",
    "dataset.remap = False\n",
    "#gcn_model = torch.load('./checkpoint/gcn_com_sub')\n",
    "eval(gcn_model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(gcn_model, './checkpoint/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "index:  0\n",
      "index:  1\n",
      "index:  2\n",
      "index:  3\n",
      "index:  4\n",
      "index:  5\n",
      "index:  6\n",
      "index:  7\n",
      "index:  8\n",
      "index:  9\n",
      "index:  10\n",
      "index:  11\n",
      "index:  12\n",
      "index:  13\n",
      "index:  14\n",
      "index:  15\n",
      "index:  16\n",
      "index:  17\n",
      "index:  18\n",
      "index:  19\n",
      "index:  20\n",
      "index:  21\n",
      "index:  22\n",
      "index:  23\n",
      "index:  24\n",
      "index:  25\n",
      "index:  26\n",
      "index:  27\n",
      "index:  28\n",
      "index:  29\n",
      "index:  30\n",
      "index:  31\n",
      "index:  32\n",
      "index:  33\n",
      "index:  34\n",
      "index:  35\n",
      "index:  36\n",
      "index:  37\n",
      "index:  38\n",
      "index:  39\n",
      "index:  40\n",
      "index:  41\n",
      "index:  42\n",
      "index:  43\n",
      "index:  44\n",
      "index:  45\n",
      "index:  46\n",
      "index:  47\n",
      "index:  48\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e83c3edba1c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#print(preds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/nightknight/新加卷/git/hierarchcal-gnn-interpretations/utils.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(dataset, idx, batch_size, shuffle)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    185\u001b[0m         dataset at the specified indices.\"\"\"\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-5852e25b8477>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0msub_adj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msub_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msub_edge_label_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_adj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_adj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/nightknight/新加卷/git/hierarchcal-gnn-interpretations/Extractor.py\u001b[0m in \u001b[0;36msubgraph\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mremap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mremap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mremap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "dataset.setting = 3\n",
    "dataset.subgraph = True\n",
    "dataset.remap = True\n",
    "#load_model = torch.load('./checkpoint/gcn_mix').to('cuda')\n",
    "load_model = gcn_model\n",
    "load_model.eval()\n",
    "in_correct = []\n",
    "for idx in range(dataset.len()):\n",
    "    print('index: ', idx)\n",
    "    data = get_data(dataset, idx).to('cuda')\n",
    "    pred = load_model.forward(data)\n",
    "    #print(preds)\n",
    "    label = data.y.to('cuda')\n",
    "\n",
    "    _, indices = torch.max(pred, 1)\n",
    "    #print(pred)\n",
    "    #print(label)\n",
    "    #print(torch.sum(label))\n",
    "    #print(indices)\n",
    "    #print(torch.argmax(load_model(data)[0]))\n",
    "    if (indices[0] == label[0]):\n",
    "        correct += 1\n",
    "    else:\n",
    "        in_correct.append(idx)\n",
    "print(correct)\n",
    "print(in_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "explainer\n",
      "\n",
      "index:  0\n",
      "0 label:  1\n",
      "epoch time:  1.5644793510437012\n",
      "acc:  1.0\n",
      "auc:  0.7905270655270656\n",
      "mean acc:  1.0\n",
      "mean auc:  0.7905270655270656\n",
      "\n",
      "index:  1\n",
      "0 label:  1\n",
      "epoch time:  0.586745023727417\n",
      "acc:  1.0\n",
      "auc:  0.7011494252873562\n",
      "mean acc:  1.0\n",
      "mean auc:  0.745838245407211\n",
      "\n",
      "index:  2\n",
      "0 label:  2\n",
      "epoch time:  0.10940814018249512\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  1.0\n",
      "mean auc:  0.830558830271474\n",
      "\n",
      "index:  3\n",
      "0 label:  2\n",
      "epoch time:  0.5214858055114746\n",
      "acc:  1.0\n",
      "auc:  0.6360225140712945\n",
      "mean acc:  1.0\n",
      "mean auc:  0.7819247512214291\n",
      "\n",
      "index:  4\n",
      "0 label:  3\n",
      "epoch time:  0.20128726959228516\n",
      "acc:  0.8\n",
      "auc:  0.697089947089947\n",
      "mean acc:  0.96\n",
      "mean auc:  0.7649577903951327\n",
      "\n",
      "index:  5\n",
      "0 label:  1\n",
      "epoch time:  0.9581899642944336\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.9666666666666667\n",
      "mean auc:  0.8041314919959439\n",
      "\n",
      "index:  6\n",
      "0 label:  1\n",
      "epoch time:  0.16858673095703125\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.9714285714285714\n",
      "mean auc:  0.8321127074250948\n",
      "\n",
      "index:  7\n",
      "0 label:  2\n",
      "epoch time:  0.05781245231628418\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.975\n",
      "mean auc:  0.8530986189969579\n",
      "\n",
      "index:  8\n",
      "0 label:  2\n",
      "epoch time:  0.1725475788116455\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.9777777777777779\n",
      "mean auc:  0.8694209946639626\n",
      "\n",
      "index:  9\n",
      "0 label:  3\n",
      "epoch time:  0.16925668716430664\n",
      "acc:  0.8\n",
      "auc:  0.8\n",
      "mean acc:  0.9600000000000002\n",
      "mean auc:  0.8624788951975664\n",
      "\n",
      "index:  10\n",
      "0 label:  1\n",
      "epoch time:  1.1953835487365723\n",
      "acc:  1.0\n",
      "auc:  0.7887500000000001\n",
      "mean acc:  0.9636363636363637\n",
      "mean auc:  0.855776268361424\n",
      "\n",
      "index:  11\n",
      "0 label:  1\n",
      "epoch time:  0.22644495964050293\n",
      "acc:  1.0\n",
      "auc:  0.8306878306878306\n",
      "mean acc:  0.9666666666666668\n",
      "mean auc:  0.8536855652219578\n",
      "\n",
      "index:  12\n",
      "0 label:  2\n",
      "epoch time:  0.08643817901611328\n",
      "acc:  1.0\n",
      "auc:  0.875\n",
      "mean acc:  0.9692307692307693\n",
      "mean auc:  0.8553251371279611\n",
      "\n",
      "index:  13\n",
      "0 label:  2\n",
      "epoch time:  0.2688121795654297\n",
      "acc:  1.0\n",
      "auc:  0.7896389324960753\n",
      "mean acc:  0.9714285714285715\n",
      "mean auc:  0.8506332653685407\n",
      "\n",
      "index:  14\n",
      "0 label:  3\n",
      "epoch time:  0.29776573181152344\n",
      "acc:  1.0\n",
      "auc:  0.6998480243161094\n",
      "mean acc:  0.9733333333333334\n",
      "mean auc:  0.8405809159650453\n",
      "\n",
      "index:  15\n",
      "0 label:  1\n",
      "epoch time:  2.0624265670776367\n",
      "acc:  1.0\n",
      "auc:  0.643797411869701\n",
      "mean acc:  0.975\n",
      "mean auc:  0.8282819469590863\n",
      "\n",
      "index:  16\n",
      "0 label:  1\n",
      "epoch time:  1.3157999515533447\n",
      "acc:  1.0\n",
      "auc:  0.7316129032258064\n",
      "mean acc:  0.9764705882352942\n",
      "mean auc:  0.8225955326218346\n",
      "\n",
      "index:  17\n",
      "0 label:  2\n",
      "epoch time:  0.2155313491821289\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.9777777777777779\n",
      "mean auc:  0.832451336365066\n",
      "\n",
      "index:  18\n",
      "0 label:  2\n",
      "epoch time:  0.3769845962524414\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.9789473684210527\n",
      "mean auc:  0.8412696870826941\n",
      "\n",
      "index:  19\n",
      "0 label:  3\n",
      "epoch time:  0.5417733192443848\n",
      "acc:  0.8\n",
      "auc:  0.7366452991452992\n",
      "mean acc:  0.9700000000000001\n",
      "mean auc:  0.8360384676858243\n",
      "\n",
      "index:  20\n",
      "0 label:  1\n",
      "epoch time:  1.5662522315979004\n",
      "acc:  1.0\n",
      "auc:  0.5929919137466307\n",
      "mean acc:  0.9714285714285715\n",
      "mean auc:  0.8244648222601485\n",
      "\n",
      "index:  21\n",
      "0 label:  1\n",
      "epoch time:  0.26752448081970215\n",
      "acc:  1.0\n",
      "auc:  0.7738636363636364\n",
      "mean acc:  0.9727272727272728\n",
      "mean auc:  0.8221647683557616\n",
      "\n",
      "index:  22\n",
      "0 label:  2\n",
      "epoch time:  0.15521788597106934\n",
      "acc:  1.0\n",
      "auc:  0.7604166666666667\n",
      "mean acc:  0.9739130434782609\n",
      "mean auc:  0.8194800682823227\n",
      "\n",
      "index:  23\n",
      "0 label:  2\n",
      "epoch time:  0.7992584705352783\n",
      "acc:  0.6\n",
      "auc:  0.35286225402504473\n",
      "mean acc:  0.9583333333333334\n",
      "mean auc:  0.8000376593549361\n",
      "\n",
      "index:  24\n",
      "0 label:  3\n",
      "epoch time:  0.3061389923095703\n",
      "acc:  1.0\n",
      "auc:  0.5750000000000001\n",
      "mean acc:  0.96\n",
      "mean auc:  0.7910361529807386\n",
      "\n",
      "index:  25\n",
      "0 label:  1\n",
      "epoch time:  1.2245416641235352\n",
      "acc:  1.0\n",
      "auc:  0.8035714285714286\n",
      "mean acc:  0.9615384615384616\n",
      "mean auc:  0.7915182789649958\n",
      "\n",
      "index:  26\n",
      "0 label:  1\n",
      "epoch time:  0.4438507556915283\n",
      "acc:  1.0\n",
      "auc:  0.7034970238095238\n",
      "mean acc:  0.9629629629629629\n",
      "mean auc:  0.7882582324777562\n",
      "\n",
      "index:  27\n",
      "0 label:  2\n",
      "epoch time:  0.19972634315490723\n",
      "acc:  1.0\n",
      "auc:  0.4035087719298246\n",
      "mean acc:  0.9642857142857143\n",
      "mean auc:  0.7745171803153301\n",
      "\n",
      "index:  28\n",
      "0 label:  2\n",
      "epoch time:  0.29367995262145996\n",
      "acc:  0.8\n",
      "auc:  0.5625\n",
      "mean acc:  0.9586206896551724\n",
      "mean auc:  0.7672062430630774\n",
      "\n",
      "index:  29\n",
      "0 label:  3\n",
      "epoch time:  0.3669567108154297\n",
      "acc:  0.8\n",
      "auc:  0.556390977443609\n",
      "mean acc:  0.9533333333333334\n",
      "mean auc:  0.7601790675424284\n",
      "\n",
      "index:  30\n",
      "0 label:  1\n",
      "epoch time:  1.1038837432861328\n",
      "acc:  1.0\n",
      "auc:  0.9999999999999999\n",
      "mean acc:  0.9548387096774194\n",
      "mean auc:  0.767915226653963\n",
      "\n",
      "index:  31\n",
      "0 label:  1\n",
      "epoch time:  0.3187448978424072\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.95625\n",
      "mean auc:  0.7751678758210266\n",
      "\n",
      "index:  32\n",
      "0 label:  2\n",
      "epoch time:  0.17509961128234863\n",
      "acc:  0.8\n",
      "auc:  0.825\n",
      "mean acc:  0.9515151515151515\n",
      "mean auc:  0.7766779401900864\n",
      "\n",
      "index:  33\n",
      "0 label:  2\n",
      "epoch time:  0.5844192504882812\n",
      "acc:  0.8\n",
      "auc:  0.9943396226415094\n",
      "mean acc:  0.9470588235294118\n",
      "mean auc:  0.7830797543798341\n",
      "\n",
      "index:  34\n",
      "0 label:  3\n",
      "epoch time:  0.8129980564117432\n",
      "acc:  1.0\n",
      "auc:  0.6283837579617835\n",
      "mean acc:  0.9485714285714286\n",
      "mean auc:  0.7786598687678897\n",
      "\n",
      "index:  35\n",
      "0 label:  1\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3961955e69bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#    continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0 label: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mnode_sort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_explain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/nightknight/新加卷/git/hierarchcal-gnn-interpretations/explain.py\u001b[0m in \u001b[0;36mprint_explain\u001b[0;34m(dataset, model, idx, class_idx, visible, figsize, node_range, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mbegin_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mclass_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCD_explain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;31m#print(class_score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbegin_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/nightknight/新加卷/git/hierarchcal-gnn-interpretations/explain.py\u001b[0m in \u001b[0;36mCD_explain\u001b[0;34m(model, dataset, idx, mask_node_list, node_range)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/nightknight/新加卷/git/hierarchcal-gnn-interpretations/utils.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(dataset, idx, batch_size, shuffle)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    185\u001b[0m         dataset at the specified indices.\"\"\"\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-5852e25b8477>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0msub_adj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msub_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msub_edge_label_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_adj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_adj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/nightknight/新加卷/git/hierarchcal-gnn-interpretations/Extractor.py\u001b[0m in \u001b[0;36msubgraph\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mremap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mnewid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mnb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mremap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0mnb_new_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "auc_list = []\n",
    "clust_list = []\n",
    "edge_auc_list = []\n",
    "\n",
    "\n",
    "\n",
    "dataset.subgraph = True\n",
    "dataset.remap = True\n",
    "dataset.setting=3\n",
    "dataset.set_hops(3)\n",
    "load_model = gcn_model\n",
    "#load_model = torch.load('./checkpoint/gcn_com_temp').to('cuda')\n",
    "load_model.eval()\n",
    "\n",
    "all_node_label = []\n",
    "all_node_color = []\n",
    "\n",
    "#for idx in range(dataset.len()):\n",
    "for idx in range(len(dataset)):\n",
    "    #if idx in in_correct:\n",
    "    #    continue\n",
    "    #idx=15\n",
    "    print('\\nindex: ', idx)\n",
    "    sub_adj,sub_feature, sub_label,sub_edge_label_matrix = dataset.get_subgraph(idx)\n",
    "    #truth_node = np.where(sub_label[:,1] == True)[0]\n",
    "    truth_node = get_node_set(sub_edge_label_matrix)\n",
    "    #if len(truth_node) > 6:\n",
    "    #    continue\n",
    "    print('0 label: ', np.argmax(sub_label[0],axis=-1))\n",
    "    node_sort, node_color = print_explain(dataset, load_model, idx, class_idx = np.argmax(sub_label[0],axis=-1), visible = False)\n",
    "\n",
    "\n",
    "\n",
    "    node_label = np.array([0] * sub_label.shape[0])\n",
    "    node_label[list(truth_node)] = 1\n",
    "    #pred  = np.array([0] * sub_label.shape[0])\n",
    "    #pred[node_sort[:6]] = 1\n",
    "    \n",
    "    #edge_label = []\n",
    "    #edge_pred = []\n",
    "    #for r,c in list(zip(sub_adj.row,sub_adj.col)):\n",
    "    #    sub_edge_label = sub_edge_label_matrix.todense()\n",
    "    #    edge_label.append(sub_edge_label[r,c] or sub_edge_label[c,r])\n",
    "    #    edge_pred.append((node_color[r] + node_color[c])/2)\n",
    "    #print(edge_label)\n",
    "    try:\n",
    "        auc = roc_auc_score(node_label, node_color)\n",
    "    except:\n",
    "        print('foo')\n",
    "        auc = 1.0\n",
    "\n",
    "    #print(truth_node)\n",
    "    #print(node_sort)\n",
    "    acc = len([node for node in node_sort[:5] if node in truth_node])/5\n",
    "    acc_list.append(acc)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "\n",
    "\n",
    "    print('acc: ', acc)\n",
    "    print('auc: ', auc)\n",
    "    #if auc == 0.0:\n",
    "    #    print_explain(dataset, load_model, idx, class_idx = 0, visible = True)\n",
    "    print('mean acc: ', np.mean(acc_list))\n",
    "    print('mean auc: ', np.mean(auc_list))\n",
    "    #print('mean clust: ', np.mean(clust_list))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "explainer\n",
      "\n",
      "index:=======================================  15\n",
      "0 label:  1\n",
      "edge sort:  [2722 2724 2719 2721    0 2725 2313 2716    2 2718 2726 2720 2727 2754\n",
      " 3635 2717 2752 2748 2983 3879 1803  890 1298 2045 3474 3006 1754  666\n",
      " 2394 2340 3010 3570 2823 3213 2300 1773 2547 1648 1398  745 2656 2142\n",
      " 3969 3516 2001 2395 2393 2171 2038 2414 2481  285 2081 1949 3220 3266\n",
      "   77 1604 2216 2461 1213 2435 3812 4297 1659 2651  940 2127 1960  938\n",
      " 3231 2998 2278 1463 2338 1458  592 1984 1400  877  751 2176 1477 2102\n",
      "  742 2234 1174 2346  758 2609 2434 2545 1651  544 1459 1739 1276 1219\n",
      "  946 1536 1740 1986 2999 3275 2203 1868 2240 1427 1016 2204  533  746\n",
      "  664 1571  733 2269 4036 1306 1447 2996 2408 1601  869  543 2979 3785\n",
      " 2220  916 3596 3981 2985 3941 4123 3728  681 2222 3476 4137 1562 1377\n",
      " 2415 2287 2025 2044 1323 1535  298  549 1520  736 4388 3212 3216 4008\n",
      " 3230 2769 4050 3194  651 2049 1010  536  959 2039 3584 3254  744 2270\n",
      " 2175 2710 2768 2986 1658 1966 4382 4104 1695  747 3946 2471 2007 4133\n",
      "  662 1474  684 2446 4300 3901 3200 4142 2844 2816 3970 2712 1515  945\n",
      " 1943  957 2029 2705 1397  661  709   38 2649 2103 4097 3738 3429 4267\n",
      " 3301 3898 1684 1872 4376 3380 2342 2428 2485 1578 1968 1457 1887 1620\n",
      " 1602 1223 1806 2429  290   90 2622  266 4136 4441 4245 4409 1218 2032\n",
      " 1189 2519 1607 1516 3012 3659 2660 1869  780 2382 3780 3676 3425 3671\n",
      "  309 2701 3015 3731 1965 1900 3578 3735 1209 1175 4461 3279 3261 3742\n",
      " 3894 1682 3588  926 2111 1206 1403  318 1134 1990 4277 1139  274 4339\n",
      " 3007 3488  329 1770  932  787 2689 3005 1769 3443 4404 2994 3409 3421\n",
      " 1533 2230  893  303 3359 2827 4316 1476 3285 2117 4459 4018 1122 1956\n",
      " 1866 2337 3924 4401  325 1611 2550  254 3237 3290 3248 4234 2329  734\n",
      " 1525 1211 2140  273 1530  683 1599  324 1465 1693 4292 4051 4094 3197\n",
      " 4221 1844 3247 1897 3669 4170 4384 2877 1589 1522 2041 2354 1987 2218\n",
      " 3552 3881 2296 1453 3882 3799 3416 2772 1305 1681 1380  539 3921 3803\n",
      " 3255 3891 3430 4275 2470 1753 3014 3673 4260 3283 2684 1449 1167 2536\n",
      " 2413 1176 2976 4225 3479 3294 4159 3280 1873 1471 3169 2889 1759 1874\n",
      " 2765 2841 2335  913 1127 2551  923 1895 4342 2838 1364 1989 1230 2383\n",
      " 2557 1738    3 2723 1725 1612  408 1091  931  760 3202 3592 2442 1351\n",
      " 3692 3375 3768 3540 4000 2988 4258 4020 1434 2652 2591 2399 2248 2565\n",
      " 2184 3435 1766 2023   40 1988 1164 1586 2527 1541 3029 3263 2616 2082\n",
      " 2686 1314 2379 1435 3208 3834  739 1709 2187 1109 3678 4052 3973 3273\n",
      " 1743 2358 3282 3718 3480 3604 3235 3190 4099 3790  293  255  829   41\n",
      " 3867 4058 1171 1108 2590 4093 2235 2214  737 1587 1224 2563 3548 3971\n",
      " 1546 4490 2228  146 2217  660 3381 2770 1826 1221 4274 3388 1539  575\n",
      " 2336 2552  532  644  150 2495 1761 2641 4060 3195 2031 1688 3287 3000\n",
      " 2619  759 1083 1700  282 2422  854  979 4322 3561 2092 1583 1781 1749\n",
      " 1302  276 3003 4081 4259 2100 3297 3586 3585 4056  929  730 3240 3378\n",
      " 2006 2657 2615 1172  658 1215 1311 2410 1188 2008  310 1057 3193 3289\n",
      " 3291 3306  598 2191 3721 3700 2839 4371 1944 1186 2180 1898 4432 3607\n",
      " 1842 4002  925 1099  906 2403 3009 3538  242 1591 4242 4227 3797 3191\n",
      " 3574 3265 3758 3414 2279 2490 4396 3677 3192 3277 3791 3897 2776 4161\n",
      " 1104 2116  134 1065 4247 2978 2860 3510 2028 2097 3608 3298 2298 2268\n",
      " 1431 1653 1741 1184  200 1526 1952 1475 2579 2546 3431 3830 3284 4298\n",
      " 1953 1810 1277 1254 1920  590 3196 3387 4061 3292 3077 3172 2855 4073\n",
      " 1687 2164 4345 4233 3018 3800  935  401 1231 2219 3238 3304 3576 4452\n",
      "  109 1356 2357 1468 2136 2521   96  584 3176 4055 4337 2762 2771 3392\n",
      "  608 1454 1114 2562 3504 3336 4332 3249  178  850 1962  432 1395 1913\n",
      " 3809 2833 3495 3730 1625 2364 2853 3244 3441 3486 2987 2788 1946 2188\n",
      " 2608  727   79  451 1626 1771 1208 4280 3904 3209 1163  899 1982 1307\n",
      " 3379 3616 1584 1917 3547 3338 1751  904 1588 2183 1959  928 2423 1450\n",
      "   71 2467 2420 2404 1440  540 2412 2106 2612  265 1746 1085 1575 2534\n",
      " 1954  264 3831 3679 2371 1783 4331 3227 2409 2672  766 1579 2331 2370\n",
      " 1926 2290 2607 1938  652  911 4311 4370 2991 3026 4447 3597 3753 4092\n",
      "  308 2698 3670 3617 1901 2639 3071 2819 4398 4232 1924 2566 3961 3756\n",
      " 2425 1805  992 1581 2834 4276 2891 3215 1876 1886 1758 1322 2520 2396\n",
      "  306 1007 1706 2556 4157 1862 1811 2499 3206 3796  279 1470  943 1357\n",
      " 1012 2606  607 1432  965 1430  870  129 1136 2052 4219 3583 2482  477\n",
      " 2683 1312 1882 1772 1191 2671 2548 1469 2543 1544 4293 4077 2386  915\n",
      " 1227  600 4135 4378 3545 1441 3572 4366 1893 1177 2368 2096 2343  320\n",
      " 3088 3557 1418 1266 4059 2825 1760 2104 1228 1711 2777 3618 2263 2004\n",
      " 3224 4218 4195 4160 3736 4391 1385 2033 1386 2215   74 3413 4196 4047\n",
      " 3383 3450 3393 3451 2655  463  754  267  964 2202 3267 4273 1997  436\n",
      " 2486 1321 3091 3702  251  117 1841 1275  602  803 4358 3963 4451 3544\n",
      " 3415 3888 3649 3357 3475 4129 2361  765 3740  810 1466 3016 1482 1540\n",
      " 4206 3965 1627 2516 4217 3555 1166 2193 2581 2266 3028 3186 1098 1778\n",
      " 1481 2326 2709 1130  875 1017 3449 3967 1317 2592 1073  898 4127  767\n",
      " 3966 3859 2503 2389 1722 1798 2857 3417 1804 1309 4395 3402 1394 1824\n",
      " 4224 4325  665 2483 1847 3832  302  874 4144 2775 4016 2851 3715 3204\n",
      " 3296 3503 1216 1202 3828 3978 1992 1210 1537 2564 2365 1929 2272   62\n",
      " 2107 1362 2781 4270 2295  606 4125 3086 3229 3977  433  724  387 2571\n",
      "  852  675 1222  137 2491 1063 3975 3021  894  398  656 1183 1473  474\n",
      " 1825 2367 2416 1484 1151  763 2229 2160 2974 3747 2975 4194  321 1553\n",
      "  461  756 1840 4321 2773 4106 2405  476 3918 3210 1573   69 3745 3710\n",
      " 1140 1382 4243 3917 4374 3228  955  535   36  667 2426   70 2274 2555\n",
      "  534  924  315 2231 1752  450 3268 3419 4343 4006 2431  949  280 2356\n",
      " 4352 3725 3312 2017 4269 2000  605 1391 1567   68 1200 2330 3577 2810\n",
      " 2678 1379 3189 3219 2400  542 1334 4500 2647 1193  425 2501   72 2226\n",
      " 4320 3508 3207 4272  252  159 2484  740 1576  947 2011  958 2661 1229\n",
      " 1365 2363 2323 2118 2258   59 4158  284 4326 3783 1142  762 2005 2568\n",
      " 2276 4431 2627 1857 3942 3568 3696 3518 1272  413 2014 1660 3652 3895\n",
      " 1566 1483  951 1649  674 2714 3741 2016  741   39 1147 2460 1075 1092\n",
      " 2836 3922 1654 1119 3243 4212 3234 3079 3424 3262 3664 4132 1260  601\n",
      " 4198 3733  587  299  472 1405 1205  439 3743 3840  966 2397 1080 1478\n",
      " 2047  399 4473  419   64 1485 2079 2132  815 2009 1565 1125 2690  853\n",
      " 2035 1409 3478 3198 4213 4309  459  670 2977 3761 2645 1061  726  591\n",
      " 3446 3269 4359 2763 1086 1777  410 2173   78 2273  162  384 1439  473\n",
      " 1181  597 1472 2577 1843 1580 2020  269 1413 1863  861 2733 1014 2496\n",
      " 1074 2703 1569 2098 1182 2507  944 2360  881 2332 3972 3560 2492 1444\n",
      "  283 2436 4448 3422 1401  901 1303 1609 4324 4130   28  209 4220 3205\n",
      " 4083 4294 1141  537 1363 2634 1178  438 2706  467 3201 3573  418 1464\n",
      " 1691  579 2574  455   22 1460 2105 2239  390 2594   73 1574 2464  423\n",
      "  311 2621  930 1115 1939 2325 3316 4308 3072 2849 1107 2170 2854 3366\n",
      " 1756  788 2366 2012 3271 4303 2662 2402 2549 1192 4499 4498 1918  300\n",
      " 1726  865   52 2152 1079 2227 2500  286  557  808 1888 2573 2898 1069\n",
      "  437 4450 2328  902 2843 2806 4413 2995 3650 3860 2040 1072 1945  646\n",
      " 3903 3775 1570 1111 3472 3482  970 1723 3841 4023  424 2487 1655 1927\n",
      "  934  271   46 1028 3428 3782 4202 3569  541 1548 1269 2620 4453 3651\n",
      " 4263 3427 4403 4139 3920 4203 3949 2764  457  529 2027  270 1066  395\n",
      " 2654 1839 3481 3610 3614 4368  873 1608 4021 3218  443 2259 1077 1170\n",
      " 3444 3519 1424 2141 2430  903 4265 4279 1360 1390   85  849 3498 4231\n",
      " 1304 2580   53 2172  312 2168 2254 1934 3787 4468 2083  761 3374 3645\n",
      " 3682 2831 3838 3432  866 1767 1325 2524  910 2137 3423 3551 2070  132\n",
      " 2497  545 1624 2344  905   44 3080 3276 3272 3884 1692 1120 2003  939\n",
      "  563 1133 2289  317 3697 3103 1623 1169 2666 1712 1697  968 3067 3766\n",
      " 2086  406 2506 1015 3589 3032 4048 3763  260 2735 3187 1563 3078  446\n",
      " 3998 3453 3182 3883 2631 2381 2089 1201 1748 1144 3493 4190 1650 1845\n",
      " 3022 2789 4425 3734 2022  649 1549 1727 2285 1316 1220  914 1415 1132\n",
      " 1572  863 2508 1780 2249  442 2073 1904  430  294  871  179  897  729\n",
      "   91  427 1600 1388 2165 1702 1462  141  800 2640 1529 1940 2813 3889\n",
      " 3598 3527 2526 2291 3445 4434 3558 3253 2162  275 1528 1417 3052 3217\n",
      " 4333 4302 4375 3356 1950 1416   57 2213 3372 4078 2252 2667 3567 3241\n",
      " 2542 1705 3389 4105 3070 2791   37 1958 4268 2866 1657 1936  604 2277\n",
      " 4207 3426 4454 3517 1199 1152   81 1437 1999 1969  195 2247 1796 2424\n",
      " 3706 3943  558 2058 3089 3590 3789 3395 2275 2586 3180 3591 2095  855\n",
      " 1060 2253 1082 1666 1103 1076 2459  611 2863 3723 4022 3563 3919 3711\n",
      "  586  261 3856 3505 1203   55 3348 3699 1883 1273 3346 3661 1794 2537\n",
      " 2585 2644 4386 3720 3295 3491 3870 3434 4053 4095 1517  421  594  956\n",
      " 1615 2051 3911 3915  907   99 4039 3369 3401 3987 1880 2322  149 1637\n",
      "  645 1928 1005 2673 2194 1764 3087 3539   47 1053 2738 1442 1214  599\n",
      " 3399 3837 1071 1951 2306  879 3452 3440 1884 4126 4467 4131 4355 4192\n",
      " 1428  140 1699 2433 1081 2401  466  974 1877 1068  961 2696 2694  595\n",
      " 2355   65 1762 2130 1613 1168 3732 3066 1961  393 3352 4470 3541 2741\n",
      "  919  400  574 1518 2588  588  297  527 2473  969 2477 1456 4096 3825\n",
      "  876 1479 2262 2440 4155 4417 3613 4307 1755 2479  962 2099  668   82\n",
      " 2192  657 3802 2576 2659   42 3798 3875 2080 2463 2488  581 3531 3500\n",
      " 3877 3680 1414 2737 1542 1812  755 2567 2225   16 1799 2333 3656 3925\n",
      " 2126  856 1568  422   48 2120 4305 4143  407 2699 3554 2862 2603 1856\n",
      " 1301 1852 3363 3844 3252 3174 1262 1271 3170 4007 4145 2859 3250 4406\n",
      "  281 2387 2989 2847 4381 4443 2236 1310 3305 2730   45  952 2643  435\n",
      "  307 2094 2283 1196 2288  278 1383  860 4054 3081  291  160 4019 4154\n",
      " 1822   26 3308 4246 1846 1059 3031 3405 1808 1436 2807 2880 1618 2540\n",
      "  960 2668 2301 1564 3223 4178 3214 2852   54 1162 2982 3861 3612 3514\n",
      "  685 1656 3550 3980 2676 2018 4296 3515   34 2602 3709 4107  447 4491\n",
      " 1867 2177   63 2297 3910 3497 2774 3494 2246   18  648  809  416 1359\n",
      " 2257 2190 3068 3506 3442 3776 3259 2824 2421  147 3367 3002 1698  327\n",
      " 1619 2570 1850 1795 3323 2798 3300 3707 1707  448 3562 3490  922 1545\n",
      " 3034 4185 2687 1935 2302 1889 1774 1721  917  100 3964 3805 1523 1408\n",
      " 4003 3872 3354 3239 1421  417 1425 1480 4214 3722 2876 3968 2265 2085\n",
      "  314 1264 2444 2598  799 1217 3902 2870 1146 2123 1064 2517 3386 4407\n",
      "  444 1371  732 1124 4201 3781 2633  128 1358  196 2794 3168  135 2139\n",
      " 3438 3084 1337  415  583 1009 2518 1404 2385   67 2179 2478 4209 4341\n",
      " 2840 4383 2133 2122  738 2417  857 1154 3601 1730 2456 2021  192 1143\n",
      "  641  263 2832 3773 4360 4109  764 2223 1931 2048 3501 3222 4330 4416\n",
      "  858 2245 3299 4189 1534 2681  610 1641 1701  580 3950 3885 2805 3681\n",
      " 2626 1800  749  696 3448 2327   60 1355 3705 4419 3167 3767 3177 3303\n",
      "  576 2392  927  701 2398  322  319 1411 3509 3724 2443  326 2829 3713\n",
      " 3537 4412  560 2078 2472 2680 4038 3593 4193 3974  538 2221 2119  805\n",
      "  460 2629  792 1399 1451 2282 2114  133 4063 2799 2256 1964  548 2560\n",
      "  677  896 3365 3982  941 1233 1198  565 1011 2449 3587 3410  892 1851\n",
      " 2303 2109 3347 4197 2186  566 3017 4199 3926 2784  441 1315 3714 3181\n",
      "  405 2076 3864 3226  789  301  912 1486 2623  394 1582  323  389  456\n",
      "  124  640 1719 2345 3999 4457  552  458   29 1860  199 2293 1259  469\n",
      " 3520 4210 4336 3319 1352 1410  814 1757 3418 2897  258  429 3829 3398\n",
      " 4408 4140  983 2093 4444 3391  568 2232 1714  449 3004 3437 3179 3566\n",
      " 3543 4410 3996 3507 2088 1116  735 1513 1036 2178 2653 2261 3178 3377\n",
      " 2658   11 4318 3868 2670 1052  220  526 1187  797 1508  144 1126   50\n",
      " 1024  654 1509 1859 3774 2865 1912  121 3985 3575 3907 4091  578 1686\n",
      " 2072  402 2043  838 4148 2828 2856 3403 2075 1823 2663 2419 1406 1937\n",
      "  440 1235 3647 3513 1396  573 1392 1236 1797  426 1922 1594 3890 3752\n",
      " 2677 2539  531  589 3373 4456 3600 3343   24 4471 1652 1665 1879  642\n",
      " 3023 2818    4 3470  676 2036 1129  409 2074 1552  104 2138  119 1894\n",
      " 1543   66 1123 1148 3655 4262 4009   58 3959 4394  153   27   92  452\n",
      "   43  868 3400 3845  305 2692   61 1366 2761 4042 3341 4169 1864 1690\n",
      " 3913 4426  572 2267  248    6  556  794  639   35 2224 1190 1054 1577\n",
      " 2455  807 3314 4472 3396 3808  882 2181  731 2124 3582 3914 3447 4045\n",
      "   20 1384 1747 1165 1237 1765 3360 3727 2835 4291 1448  111 3035 3689\n",
      " 2682  130 2441  950 3962 4415 3371 3257 2624 1026  743  127 2055 4476\n",
      " 2292  110 1239 2466 3944 3726 1896 1854 1745  328   13 2713  462  772\n",
      " 3364 4314 1923  975   21 1446 2814  900  114 2515 1715 1106  420 2352\n",
      " 1640 2450  719 1149 2760 1995 2688 2438 4255 4497 1194  986 4187 3242\n",
      "  191 1137 2582  551 3333 3408 4076 4418 3024 2884 2572 2474 2359  145\n",
      " 4353 3069 1335 2050 4335 3532 1145 2110 3786 4151  554 1914  113 2489\n",
      "  391  816 1270  691  570 2729 2077 2280  139 1387  295  454  908  182\n",
      " 3362 3827 1703  748 4191 3013 3770 4379  185  802 2071 2407 2255 1488\n",
      " 3769 4071  680 2685  259  453 4012 3233 3869 4100 4449 2858  555  757\n",
      " 1670 2522 4437 3001 2783 4319  208 2525 2373 2390 3211 4349  546   33\n",
      " 3986 3322 1547  475 1267 2131 4393 1669 3899 3317 3839 2868 1180  564\n",
      " 4079 3420  655 1030 3350 2894 1445 1240 3330 3355 3221 4041 3665 4128\n",
      " 4149 2861 1067  231  973  403  268 1996 3658 4380 2182 1558  706 1504\n",
      "  859 1344 1809  638 1779 1941 2665 1647  169 1948  102 2113  936  559\n",
      " 2469 1667  707 1512 1511  663 2742 2739 1241  659 3361 3807 1801  785\n",
      "   10  801 2892 3260 3019 3936 3581 3905 2320 1503 4186 3090 2611   97\n",
      " 1110   49  991 1510 1179 1644 1332 1234   14 2166  603 1319 1095 1197\n",
      " 4204 3771  812 2339 1718 1720 1033 2013  823  396   23 4489 3311 3788\n",
      " 3744 2779 4075 4152  148 1617 3719 3349 3225 3749   32  383 1807 1902\n",
      " 3074 3047 1299  108 3603 2802 3908 2294 2732 1639   30  289 2121 2541\n",
      "  131  933 2128  188  205 1737 2638  172 1257 2695 1094 1955 4445 3708\n",
      " 1158  313 1263 2558 1642 2617  845 2384  711 1320 3313 3806 3328 3278\n",
      " 2632 2812 1694 1491 2635 2091 3329 4062 3096 2850 2755 2084 3041 2848\n",
      " 4168 2904  795 1426  988 1225 1088 1593  728  672 1350 4502 2264 2559\n",
      " 2362  813 1204  987 2054  786 3310 4261 1870  161  386  257 2792 2271\n",
      " 3674 3751    8 1911 3286 2893 2046  981 2600 1501 1025 2734 2056  304\n",
      " 3686 4334 2905 3579 3332 3390 2024 1560 4438 3082 1643 4211 2873 3933\n",
      " 2209  470 2238 1636 3813 2782 3765 3654 2369 1646 1118  468 1916   94\n",
      " 4057 4111   86 2544  678  921 1296 1793  942 1347 1043 1776 2451  714\n",
      "  154   75 2867 3810 2899 4102    9 1942  201 1610 4266 3684   95 2584\n",
      " 1919 2454 1490 1443 4124 3060  836 2642 2053  700 2233  705 1685 1093\n",
      " 1668 3948 1907 2185  190 1100 2618  720  577 1621 3795 4156 1521  112\n",
      " 1297   17 3683 4249 3489 3059 1555 1393 1256  989 3772 3892  173  752\n",
      " 2992 3044 1492 3836 3093 3848 2903 4162 3835 3315 1006  186  206 1768\n",
      " 3672 2909  164 2569 3342 3595 2901 3511 1910  878 1724 1354  316 1349\n",
      "  547  122  827  593 2648  175 2766 2878 3384 2895 1933  168 2498  779\n",
      " 3556 3061 3382 2800 3483 2900 3909 2871 3307 2797  553 1905 4367 4436\n",
      " 3757 3394  181 2019 2796 4433  920  653  250 1255 1596   89 1661 1318\n",
      "  833  397  187 1055 4035 2890 3871 3887  704 2134  887  623 3937 3321\n",
      "  647  717  163  428 3075 3099 1232   56 2161  105 1308  842 2736 1333\n",
      "  197 2286 1551 2251 2212 1532 3309 3764  985 1128 1855 1663 3411 3663\n",
      " 1243 1531 1728 1084 3020 3951 2795 3184 1021 2702 1837  157  237 1313\n",
      " 1284  414 3754 3092 3523 3008 1238  567 3667 3063 2453 1042 1556  445\n",
      " 2610  835 2034  844 1467  496 1288 1135 1878 2597 2753 2750  166 2593\n",
      " 3094 3857 3038 4357 3609 2803 1328 3232  993 2427 3801 1342 1429  239\n",
      "  843 1324 4082 4013 4241 2864 3064 3675 3039 3979 1763 1096   87  155\n",
      " 3055 4428 3288 1340 3318 4327 3030 3325   83  768 1736 1294 3053 4414\n",
      " 2875 3945  846 1775  184  953 2780  412 4040 3175 2826 3324 2135  840\n",
      "  984 1019 3033 4172  571 1353 2881 2845 2448 1339 2042  817   12  848\n",
      " 4101 3694 4004 2883 4115 3886 4166 3695 1828 1550 4163 3778  698  811\n",
      " 1029  561 2583  834  710  125  886  464  888  650 4113 4323 2589  773\n",
      "  847 1784 4064 4147  830 1827  508 1102  585  167 1947 1557  626 1070\n",
      " 2476 4495  750  722 4313 3953 2984 4348  977 1983 4463 3199 3468 4080\n",
      " 3376 3056  292  216 1226 1027 2842 2785 4346 3687 4462 4229 3688 2778\n",
      " 2820 3095  232 1113 1957 1160 2026  980 1487  142  361    1 2090 1496\n",
      "  194 1300 3528 3353 4299 3685 2906 3605 3638 4222 2457  994 4175 3492\n",
      " 4084 3331 1038 1258  204 2468 4365 4464 4103 3334 1597 2523 2304  774\n",
      " 1420  990 4034 3327  277 1348 3657 3939  776 1710 3639 3011  692 1899\n",
      " 4179 3345 2533 1278  221 2604 2697  227  781 2630 2260 1090  862 1561\n",
      "  136 1155 4492 2315 2869 3873 4372 4465 1138  233 1813   25 3256 3599\n",
      " 2348 1848 2349 1858 4347 2872 1494 1834 1708  718 3737 3820 3046 4399\n",
      " 4254 4455 3048 4400  819 2553 2896 3404 1506 1185 1713 2060 3100 3477\n",
      "  690 1865 2125  839 3900 3637 4312 3602 1035 2174 3051 4037 2601 1285\n",
      "  804  978 4067 3843  716 2731 1089  189 3171 3050 2646  621 2958 3454\n",
      "  643  489 4200 3065  253  215 1853  972 1173  721  235 1212  170  669\n",
      " 3339 3559 3463 4356  392  713  478  120 2599  715 1207  512 2353 1881\n",
      "   98  687 1792  889 2341 1290  183 2664  218  385 2129 1500 3412 3693\n",
      "  198 1402 4369 4439  240 2378 3458 3128 1329  569 2514 1153 1915 1499\n",
      " 1629 1361 2613 1031 1704 2211 2376  783 1281 1836 1330 1112 3062 3646\n",
      " 4328 4174 1013 1498 4427 3054 1289 2334 1341 1419 3642 2711 2493 1505\n",
      " 3958 2207 3955 3594 4167 3462 2480  246 4033 3947 3564 4250  703 1062\n",
      " 1493 4223 3083 4070  771 1645 4141 4387 1603 1292 4031 3457  630 1381\n",
      "  609 2375 3340 4165 4205 4256 1087  103 4046 3464 1293 2462 1495  143\n",
      " 4215 4117   19 1345 4257 3461 2535  214 1921  694 2445 2157 3203 3643\n",
      " 2237  236 3058 3456 3460 3553  872  225  171  688  115  156 3640 4235\n",
      " 3466 3335   93 1903 4120 3085 2675  818 1717  708 4252 3997 3759 3455\n",
      " 3779 4181 1985 1507 3912 3037 4240 3712 2625 2158 3465 4290  909  498\n",
      " 4340 3952  937  624  241 2411 2554 1282  753  224 3530 3668 3469 3855\n",
      " 1606  635 3157 3459 1662  202 4116 3471  723  223  637 2437 1331 2002\n",
      " 3853 3358 4121 3245 2756 2350 1595 1963    5  152  782  798 2578  825\n",
      "  244 2447 3957 3866 4226 4236 2715  234 4362 3717 3814 3502 3057 4442\n",
      " 4397 4119 1614  821 3932 2815 4423 3370 1034  963 1433  631 2377 1559\n",
      " 4475 2751 4118 4458  673  775 2317 2759 2321 2015 1735 3467 2504 1295\n",
      " 3929 4354   76  210  619 1967 4385 4043 2418 2347  243 1598 2790 3040\n",
      "  487  530  482  296 2509   84 1590  948 3546 3954 2704  625 4068 4317\n",
      "  636 1622 1519  632 1368 1871 3615 4065 1156  193 1906  693  697 1998\n",
      "  176  820 1370 1875 2513 2305 3823 3804  174  769 3183 3931 2243  471\n",
      " 3406 4014 4304 4180 1628 2693 3156 3368 2059  679  699  828  628 1261\n",
      " 2700  503 1733  778  826 1097  519 1527 2319 1716 1279 2538 4479 4486\n",
      "  116  212  177  831  864 1635 2886 3097 1634 2628  777 1161 3935 2874\n",
      " 1039 1265 1734 1242 2250  515 1280  107 3042 2885 2205  513 3824 3876\n",
      " 2210 1909 2494 2068  230 1056 2980 3815  791 1032 3549 4177 4114 4390\n",
      " 1838  481 1117 1633 2786 2879 4501 2154 3049 4032 1078 1249 3102 3691\n",
      "  837  784 1286  682 4484 4478 1343 1157 1452  518 4350 3320 3337 3535\n",
      " 2153 1585 4239 1994 1291 2372 4238 3653 3748 3524  633 1524  158  213\n",
      " 2636  620 1051  702 4182 3281 2531 1696 1131  509 1631 2108 1367  138\n",
      "   88  211 2065  465 4487 4483  506 2115 2159  880 1832 1378  521 2406\n",
      " 4481 3988 1885 1372 2284  824 3036 3822  490 2614 3045 4010 2510  151\n",
      "  505 2101  497  895 2432  522  613  123 1018  228  971  226  507 2707\n",
      "  486 2595  494 2650 1274  514  495 2030 3690 4015   80  612 1632 1422\n",
      "  520 2391  484 2575 2458  523 1376 1538 3928 4150 2587  485  883  180\n",
      " 2281  516  126 1971 1058 1373  499 2674  510 2163 3526 3101 4351 3849\n",
      " 1930 1818 2156 1890  491  725 2388  634  288 2529  525 1789 1892 1973\n",
      " 1744  247  165  479 2195 2757 1849 1246 1046 1022 4474 1374 2144   51\n",
      "  671  617 3166 3704 2708 2146 4171 2908 2145 2561 2532  867 4110 4364\n",
      " 1338 1041 2147 2605  511 2169  493  806 1742 1252  793  492 3107 3793\n",
      " 1121 2318 2149 1105  582 1729 3542 3930 1829  891 2143 2502 2087  502\n",
      "  222  689  501  954 1750 1790 4488 4480 2167 2067 3629 4183 1346 1815\n",
      " 2749 2747 2637 1251  614  262 2837 3927 1802 2528 2679  500 3991 3777\n",
      " 1514 1732 1830 1861 4088 3662 3521 2902 3863 3992 4173 3852 1049 1423\n",
      " 1253 2010 3854 3433 1268  629 4363 3628 2997 4420 3826 3109 3624 4466\n",
      " 3817 3270 4164 4494 2189 1835 3536 3626 4264 3106 3636 2830 1247  411\n",
      " 1050 2324 3162 3571 2811 3993 4069 4112 4402 3989 3258 4085 3994 3716\n",
      " 3115 3990 3147 2809 2150 1455 3129 3484 3565 3132 4089 4389 3865 4044\n",
      " 3293 4087 2374 1375 3851 3818 3119 3027 4477 3846 2801 4090 2148  596\n",
      " 3127 3439 3622 3906 3956 3630  622  796 3620 2907 3145 3984 1047  562\n",
      " 1040 1327  504 1023 4422 3627 4066 3632 3634 4072 3146 2793 1044  229\n",
      " 1616 1833 4411 3625 3631 3344 2200  841 3111 3842 3149 4392 4237 3623\n",
      " 2691 2062 3755 3525 3113 3880 4421 3236 3703 3133 3534 3161  238 2241\n",
      " 1819 1461 4146 3160 4122 3619 3633 3644  627 1159  207 1785 4446 3126\n",
      " 1389 2064 3698 3165 1991 1980 3105 4244 4184 2804 1020  356 2954 4074\n",
      " 3794 3137 2197  360  371 1489 1976  347  517 4503 1974 1731 1326  365\n",
      " 1816  249 3144 3976 2505 2069 3116 2808  616  488 1932 2066 2037 1981\n",
      " 4024 2887 1787  382  337  256 2596  345  340  483  336  217 3621 2968\n",
      "  338  388 1045  357 1638  377  332 1817 3043 2942 2439 2198 3641 3529\n",
      " 4049 3123 2063  355 2316  370 1925  343 2199 1908 2244 1689 3533 3131\n",
      " 1000  404 3397 3819  346  712  822  349 4027 4338  352  885 2475  381\n",
      "  851  351  367 1369 1407 1978  344  615  374 1554  996 2669 2957 3436\n",
      "  333 1831 2744 1814 1004  790  331   31  363 1283 1979 1150  368 1412\n",
      "  995  884  999 1008 1002 1683  342  550  272  998  369 1438 4278 3139\n",
      " 1782 2201 1195  359  997  982 1592  375  341  528  366 1336 2057  354\n",
      "  362 2208  339  431 4188 4288  106 1245  334  118 1664  378    7  330\n",
      " 4248 3136 3893 3142  373 2351  219  480  350  832 2155  358 4493 4496\n",
      " 1605 4485 3122 4429  376 1630 2242  364  380 2452 3124 4435  976 1972\n",
      " 1970 1287 2196 1001  353  918 4028 4405 1244   15 2061  101 2307 1003\n",
      "  770  348 4504 4285 3858 3112 2745 3847 4216 3104  686 1679 3159 4460\n",
      " 2822 3148 2380 4289 2964 3522 2938 2882 3326 3125 3076 3120  379 1675\n",
      " 2912 3746 3163 3606 3833 3110 3117 2821 3138 3811 1671  203 4253 3816\n",
      " 2944 3098 2530  335 2993 4026 3878 2921 2917 3821  618  695 2969 4176\n",
      " 2817 2935 1037 1248 3995 2934  967 1672 4284 4469 3141 3874 3496 2962\n",
      " 3960 2929 4505 2311 2465 1677 3983 3114 2740 1674 2937 2846 2787 2933\n",
      " 4283 2981 3351 2953 2914 3760 2973 4208 1676 2299 3135 3762 1820 1975\n",
      " 2965 4153 3143 4329 1680 2206 4271 3108 3151 2946 2916 3792 2940 2990\n",
      " 1497  372 3118 2945 2939 4005 2950 4430 2913 4230  245 1673 4287 4306\n",
      " 3274 2951 2955 3385 2758 2971 3512 3130 2922 4315 4098 2956 4301 2919\n",
      " 2928 3940 2966 3580 2918 4295 3739 2911 1502 2310 4377 2931 2930 4373\n",
      " 3185 2948 3666 2970 2926 4344 3784 2915 2746 1891 2927 3934 4001 2936\n",
      " 2959 3473 3499 4025 3611 2967 3264 3155 2947 4017 2924 3916 3302 2952\n",
      " 2932 2767 4310 2920 3896 2923 3729 2910  524 2512 4138 2963 4424 3407\n",
      " 4228 3134 3923 2925 2151 2309  287 1786 4134 4281 2511 4030 2941 3025\n",
      " 2728 4482 2949 3246 2943 1821 1993 3073 1788 2112 3487 2961 3660 4029\n",
      " 3140 3862 4282 3750 3701 2972 2314 1250 3150 2888 3154 3251 2960 4108\n",
      " 4086 2312 3850 3938 4440 4286 1977  434 4361 4251 3485 3158 1678 2308\n",
      " 3164 3648 4011 3152 2743 1791 3153 3188 3121 3173 1048 1101]\n",
      "auc:  0.5817780509611086\n",
      "auc mean:  0.5817780509611086\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "auc_list = []\n",
    "clust_list = []\n",
    "\n",
    "node_num_list = []\n",
    "dataset.subgraph = True\n",
    "dataset.remap = True\n",
    "dataset.setting=3\n",
    "dataset.set_hops(3)\n",
    "#load_model = gcn_model\n",
    "load_model = torch.load('./checkpoint/gcn_com_sub').to('cuda')\n",
    "load_model.eval()\n",
    "\n",
    "all_node_label = []\n",
    "all_node_color = []\n",
    "#for idx in range(dataset.len()):\n",
    "for idx in range(800):\n",
    "    #if idx in in_correct:\n",
    "    #    continue\n",
    "    idx=15\n",
    "    print('\\nindex:======================================= ', idx)\n",
    "    sub_adj,sub_feature, sub_label,sub_edge_label_matrix = dataset.get_subgraph(idx)\n",
    "    #truth_node = np.where(sub_label[:,1] == True)[0]\n",
    "    truth_node = get_node_set(sub_edge_label_matrix)\n",
    "    #if len(truth_node) > 6:\n",
    "    #    continue\n",
    "    class_index = np.argmax(sub_label[0],axis=-1)\n",
    "    print('0 label: ', class_index)\n",
    "    #node_sort, node_color = print_explain(dataset, load_model, idx, class_idx = class_index, visible = False)\n",
    "\n",
    "    #_, _, adj, edge_pred = find_edge(load_model, dataset, idx, class_idx = None, node_sort = node_sort, topk = 5, start_num=1)\n",
    "    #print(_)\n",
    "\n",
    "    edge_dense = sub_edge_label_matrix.todense()\n",
    "    edge_list = preprocess_adj(sub_edge_label_matrix)[0]\n",
    "    edge_label = []\n",
    "    for r,c in list(zip(sub_adj.row,sub_adj.col)):\n",
    "        edge_label.append(edge_dense[r,c] or edge_dense[c,r])\n",
    "\n",
    "\n",
    "\n",
    "    edge_score = Edge_explain(load_model, dataset, idx = idx, edge_list = edge_list)\n",
    "    edge_colors = []\n",
    "    for i in range(len(edge_score[0]['rel'])):\n",
    "        edge_colors.append( edge_score[class_index]['rel'][i] )#- edge_score[0]['rel'][i] )\n",
    "    print('edge sort: ', np.argsort(edge_colors)[::-1])\n",
    "    #print(edge_list[np.argsort(edge_colors)[::-1]])\n",
    "    try:\n",
    "        auc = roc_auc_score(edge_label,edge_colors)\n",
    "    except:\n",
    "        auc = 1.0\n",
    "    print('auc: ', auc)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "    print('auc mean: ', np.mean(auc_list))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "index:  400\n",
      "0 label:  1\n",
      "node range:  [400, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 37, 38, 42, 43, 44, 45, 46, 47, 49, 50, 52, 54, 55, 56, 57, 58, 60, 61, 65, 68, 69, 71, 72, 73, 75, 76, 78, 81, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 105, 109, 111, 112, 113, 114, 115, 116, 118, 122, 123, 128, 129, 130, 135, 136, 137, 140, 141, 143, 144, 145, 148, 150, 151, 153, 154, 155, 157, 159, 161, 163, 164, 167, 170, 173, 174, 177, 178, 181, 183, 185, 189, 190, 191, 194, 197, 199, 200, 201, 202, 207, 216, 217, 223, 224, 229, 231, 233, 235, 240, 241, 243, 244, 245, 246, 253, 262, 266, 269, 271, 272, 279, 281, 284, 285, 293, 300, 325, 330, 401, 402, 403, 404, 415, 425, 435, 455, 505, 569, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 717, 718, 719, 720, 722, 724, 725, 726, 729, 730, 731, 732, 733, 735, 737, 742, 743, 744, 745, 746, 749, 751, 753, 754, 755, 756, 757, 758, 759, 761, 763, 764, 766, 767, 768, 770, 773, 774, 777, 778, 779, 781, 783, 784, 785, 788, 790, 791, 794, 796, 797, 802, 803, 810, 811, 812, 813, 815, 817, 820, 822, 824, 826, 827, 829, 835, 837, 838, 839, 840, 843, 844, 847, 849, 852, 853, 855, 862, 863, 869, 870, 873, 877, 878, 881, 883, 884, 897, 902, 905, 908, 909, 910, 911, 920, 924, 925, 926, 931, 935, 937, 939, 944, 946, 952, 953, 954, 957, 958, 962, 964, 965, 972, 973, 977, 981, 982, 987, 988, 991, 993, 997, 1010, 1230, 1255, 1266, 1359]\n",
      "target node:  400\n",
      "epoch time:  1.932403802871704\n",
      "[309 105  98  99 100 101 102 103 104 106 115 107 108 109 110 111 112 113\n",
      "  97  96  95  94  79  80  81  82  83  84  85  86  87  88  89  90  91  92\n",
      "  93 114 116  77 144 137 138 139 140 141 142 143 145 117 146 147 148 149\n",
      " 150 151 152 136 135 134 133 118 119 120 121 122 123 124 125 126 127 128\n",
      " 129 130 131 132  78  76 308  27  20  21  22  23  24  25  26  28  37  29\n",
      "  30  31  32  33  34  35  19  18  17  16   1   2   3   4   5   6   7   8\n",
      "   9  10  11  12  13  14  15  36  38  75  66  59  60  61  62  63  64  65\n",
      "  67  39  68  69  70  71  72  73  74  58  57  56  55  40  41  42  43  44\n",
      "  45  46  47  48  49  50  51  52  53  54 153 154 155 260 253 254 255 256\n",
      " 257 258 259 261 270 262 263 264 265 266 267 268 252 251 250 249 234 235\n",
      " 236 237 238 239 240 241 242 243 244 245 246 247 248 269 271 156 299 292\n",
      " 293 294 295 296 297 298 300 272 301 302 303 304 305 306 307 291 290 289\n",
      " 288 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 233 232\n",
      " 231 183 176 177 178 179 180 181 182 184 230 185 186 187 188 189 190 191\n",
      " 175 174 173 172 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 192 193 194 213 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      " 228 229 214 212 195 211 196 197 198 199 200 201 202 203 204 205 206 207\n",
      " 208 209 210   0]\n",
      "0\n",
      "160\n",
      "157\n",
      "158\n",
      "159\n",
      "truth node:  [0, 160, 157, 158, 159]\n",
      "acc:  0.0\n",
      "auc:  0.5\n",
      "mean acc:  0.0\n",
      "mean auc:  0.5\n",
      "\n",
      "index:  405\n",
      "0 label:  1\n",
      "node range:  [405, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 26, 27, 31, 32, 33, 37, 38, 39, 40, 41, 43, 45, 46, 49, 50, 53, 61, 62, 63, 64, 65, 69, 70, 71, 74, 77, 78, 590, 80, 83, 86, 89, 90, 91, 93, 95, 99, 100, 101, 102, 103, 104, 105, 107, 108, 112, 114, 115, 116, 119, 120, 121, 122, 123, 124, 125, 132, 135, 142, 146, 149, 155, 156, 159, 163, 167, 169, 172, 174, 180, 181, 182, 186, 701, 704, 705, 194, 706, 708, 201, 202, 204, 206, 718, 209, 721, 724, 214, 726, 217, 223, 225, 226, 1249, 234, 235, 238, 242, 250, 256, 261, 1295, 1296, 1297, 274, 275, 1299, 1298, 278, 281, 288, 293, 295, 297, 298, 1328, 1345, 845, 847, 345, 877, 878, 883, 909, 406, 407, 408, 409, 430, 977, 470, 471, 473, 474]\n",
      "target node:  405\n",
      "epoch time:  1.1327483654022217\n",
      "[157  49  56  55  54  53  52  51  50  48  58  47  46  45  44  43  42  41\n",
      "  57  59  39  69  76  75  74  73  72  71  70  68  60  67  66  65  64  63\n",
      "  62  61  40  38 156   9  16  15  14  13  12  11  10   8  18   7   6   5\n",
      "   4   3   2   1  17  19  37  29  36  35  34  33  32  31  30  28  20  27\n",
      "  26  25  24  23  22  21  77  78  79 128 135 134 133 132 131 130 129 127\n",
      " 137 126 125 124 123 122 121 120 136 138  80 148 155 154 153 152 151 150\n",
      " 149 147 139 146 145 144 143 142 141 140 119 118 117  89  96  95  94  93\n",
      "  92  91  90  88 116  87  86  85  84  83  82  81  97  98  99 100 115 114\n",
      " 113 112 111 110 109 108 107 106 105 104 103 102 101   0]\n",
      "0\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "truth node:  [0, 130, 131, 148, 149, 150, 151, 157, 154, 155, 156, 125, 126, 127]\n",
      "acc:  0.2\n",
      "auc:  0.5\n",
      "mean acc:  0.1\n",
      "mean auc:  0.5\n",
      "\n",
      "index:  410\n",
      "0 label:  1\n",
      "node range:  [410, 0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 41, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 65, 66, 67, 68, 72, 74, 75, 77, 80, 81, 82, 83, 84, 87, 90, 91, 93, 94, 96, 99, 104, 105, 107, 108, 110, 111, 114, 118, 119, 120, 121, 124, 125, 126, 131, 132, 136, 137, 140, 142, 143, 144, 146, 152, 156, 157, 160, 164, 166, 172, 174, 176, 177, 179, 185, 190, 193, 196, 197, 201, 204, 205, 218, 220, 225, 226, 232, 235, 236, 239, 241, 244, 245, 246, 249, 253, 255, 259, 261, 264, 265, 267, 268, 274, 277, 279, 280, 282, 283, 286, 287, 291, 295, 298, 299, 305, 320, 378, 397, 411, 412, 413, 414, 425, 450, 480, 488, 489, 511, 517, 529, 595, 596, 599, 635, 637, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 728, 729, 730, 731, 732, 733, 735, 736, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747, 748, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 784, 785, 786, 787, 789, 791, 792, 793, 794, 796, 797, 798, 800, 801, 802, 803, 804, 806, 807, 808, 810, 811, 812, 813, 815, 816, 817, 819, 820, 822, 825, 826, 828, 830, 831, 832, 833, 835, 837, 838, 839, 840, 841, 842, 843, 844, 846, 847, 849, 850, 851, 854, 855, 856, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 877, 878, 879, 882, 883, 884, 886, 889, 893, 895, 898, 900, 902, 903, 907, 908, 909, 910, 912, 914, 916, 917, 918, 920, 922, 923, 924, 925, 926, 933, 935, 936, 937, 938, 942, 943, 946, 948, 949, 951, 952, 953, 954, 958, 959, 961, 962, 963, 965, 966, 975, 976, 977, 978, 980, 981, 988, 989, 990, 995, 996, 1005, 1010, 1011, 1012, 1013, 1014, 1020, 1021, 1023, 1024, 1060, 1075, 1091, 1092, 1093, 1148, 1155, 1167, 1316, 1317, 1318, 1380]\n",
      "target node:  410\n",
      "epoch time:  2.4416537284851074\n",
      "[397 124 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 125 123 148 122 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 120 121 147 149  99 174 176 177\n",
      " 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195\n",
      " 196 175 173 150 172 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 100  98 396  24  26  27  28  29  30  31\n",
      "  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  25  23  48\n",
      "  22   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  47  49  97  74  76  77  78  79  80  81  82  83  84  85\n",
      "  86  87  88  89  90  91  92  93  94  95  96  75  73  50  72  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      " 197 198 199 323 325 326 327 328 329 330 331 332 333 334 335 336 337 338\n",
      " 339 340 341 342 343 344 345 324 322 347 321 300 301 302 303 304 305 306\n",
      " 307 308 309 310 311 312 313 314 315 316 317 318 319 320 346 348 200 373\n",
      " 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392\n",
      " 393 394 395 374 372 349 371 350 351 352 353 354 355 356 357 358 359 360\n",
      " 361 362 363 364 365 366 367 368 369 370 299 298 297 224 226 227 228 229\n",
      " 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 225\n",
      " 223 296 222 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 247 248 249 250 275 276 277 278 279 280 281 282\n",
      " 283 284 285 286 287 288 289 290 291 292 293 294 295 274 273 272 260 251\n",
      " 252 253 254 255 256 257 258 259 261 271 262 263 264 265 266 267 268 269\n",
      " 270   0]\n",
      "0\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "truth node:  [0, 385, 384, 388, 389, 390, 394, 395, 396, 150, 151, 152, 153, 162, 163, 164, 377, 378, 379, 380, 381, 382, 383]\n",
      "acc:  0.0\n",
      "auc:  0.5\n",
      "mean acc:  0.06666666666666667\n",
      "mean auc:  0.5\n",
      "\n",
      "index:  415\n",
      "0 label:  1\n",
      "node range:  [415, 0, 1, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 545, 35, 37, 38, 42, 43, 44, 49, 50, 52, 55, 56, 60, 61, 62, 63, 1030, 65, 69, 70, 71, 73, 75, 76, 78, 81, 85, 86, 89, 91, 92, 93, 95, 97, 100, 615, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 118, 120, 123, 125, 126, 129, 131, 140, 141, 143, 147, 151, 155, 156, 163, 164, 167, 168, 178, 181, 182, 183, 186, 700, 190, 704, 194, 707, 196, 708, 199, 200, 711, 202, 716, 718, 206, 721, 210, 722, 723, 725, 215, 727, 729, 224, 1249, 236, 749, 238, 240, 241, 242, 243, 245, 757, 759, 253, 256, 771, 772, 262, 263, 266, 269, 270, 274, 789, 792, 283, 795, 800, 293, 1328, 823, 315, 325, 837, 839, 856, 886, 889, 895, 897, 907, 400, 918, 416, 417, 418, 419, 929, 434, 948, 950, 959, 972, 976, 996]\n",
      "target node:  415\n",
      "epoch time:  1.1285452842712402\n",
      "[170  53  61  60  59  58  57  56  55  54  52  42  51  50  49  48  47  46\n",
      "  45  44  62  63  64  65  82  81  80  79  78  77  76  75  74  73  72  71\n",
      "  70  69  68  67  66  43  41  84  10  18  17  16  15  14  13  12  11   9\n",
      "  40   8   7   6   5   4   3   2   1  19  20  21  22  39  38  37  36  35\n",
      "  34  33  32  31  30  29  28  27  26  25  24  23  83  85 169 139 147 146\n",
      " 145 144 143 142 141 140 138 128 137 136 135 134 133 132 131 130 148 149\n",
      " 150 151 168 167 166 165 164 163 162 161 160 159 158 157 156 155 154 153\n",
      " 152 129 127  86  96 104 103 102 101 100  99  98  97  95 126  94  93  92\n",
      "  91  90  89  88  87 105 106 107 108 125 124 123 122 121 120 119 118 117\n",
      " 116 115 114 113 112 111 110 109   0]\n",
      "0\n",
      "161\n",
      "162\n",
      "160\n",
      "159\n",
      "truth node:  [0, 161, 162, 160, 159]\n",
      "acc:  0.0\n",
      "auc:  0.5\n",
      "mean acc:  0.05\n",
      "mean auc:  0.5\n",
      "\n",
      "index:  420\n",
      "0 label:  1\n",
      "node range:  [420, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 1066, 1067, 43, 45, 555, 47, 48, 49, 50, 51, 52, 53, 54, 57, 59, 60, 61, 64, 65, 66, 67, 70, 71, 72, 73, 585, 75, 76, 77, 79, 82, 83, 1108, 85, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 104, 105, 106, 108, 109, 110, 111, 119, 120, 124, 125, 126, 127, 129, 130, 132, 645, 646, 135, 136, 648, 649, 140, 142, 143, 144, 1167, 146, 148, 151, 153, 155, 156, 157, 159, 161, 164, 166, 167, 168, 171, 172, 173, 174, 176, 177, 178, 179, 181, 184, 701, 191, 195, 197, 199, 201, 202, 204, 205, 206, 207, 208, 215, 216, 217, 218, 1242, 223, 227, 231, 233, 235, 240, 241, 243, 245, 246, 248, 249, 253, 254, 255, 1068, 259, 264, 266, 267, 268, 271, 272, 274, 276, 277, 278, 279, 280, 282, 283, 285, 286, 287, 290, 295, 296, 297, 305, 837, 421, 422, 423, 424, 425]\n",
      "target node:  420\n",
      "epoch time:  1.204211950302124\n",
      "[195   0 192 194 193  61 101 150  87  52 105 124 144 188 125  80  39  38\n",
      "  57 177 102  82 170  33 149  11 121  42 134 117 122  35  69   2 187 175\n",
      "  65 113  86  95 114 145  10 146 186 136 161  54  72  56 174 137  45 116\n",
      "  16 159  31  27 119 158   1  15  48  25 155 126 171  20  12 109  79  19\n",
      "  76 157  29 165 133  46 108 173   8  34 120   7 143  32 181  58  74 190\n",
      " 189  13 176 148 185 156 140 163   9 142  59 162  75  81  66  78 138 118\n",
      " 182  68 127 115  89 152  77 130  91  90  44 172 147  30 183 179  21  55\n",
      "  93 166 112 139  62  43   3  37 128 110  92  18  24 129 100  50 123 107\n",
      "  14 104 164 103  71  99  83  41  88 191  26  22  94  96 168  23 141  36\n",
      "  97  51  85 169  49  40  28  63 184 131  98 154 180  60 132 178  17 135\n",
      "  67  84 153  70   6  73  53 160 111 196  47   4 106   5  64 151 167]\n",
      "0\n",
      "192\n",
      "194\n",
      "195\n",
      "193\n",
      "truth node:  [0, 192, 194, 195, 193, 101, 38, 39, 167, 102, 106, 105]\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.24\n",
      "mean auc:  0.6\n",
      "\n",
      "index:  425\n",
      "0 label:  1\n",
      "node range:  [425, 0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 27, 28, 30, 31, 37, 38, 39, 46, 49, 53, 55, 58, 59, 60, 61, 62, 64, 66, 67, 68, 69, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 88, 91, 93, 94, 95, 96, 101, 105, 106, 107, 115, 116, 118, 119, 123, 130, 139, 140, 141, 142, 144, 145, 146, 150, 151, 152, 153, 154, 157, 159, 164, 166, 169, 171, 172, 176, 177, 180, 181, 182, 184, 185, 191, 193, 194, 197, 201, 203, 205, 206, 217, 218, 220, 230, 232, 239, 240, 243, 247, 251, 252, 267, 269, 272, 278, 285, 292, 293, 295, 296, 300, 349, 400, 410, 420, 426, 427, 428, 429, 455, 472, 478, 488, 565, 569, 588, 605, 645, 646, 675, 677, 678, 698, 700, 701, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 740, 742, 743, 745, 746, 747, 749, 750, 751, 752, 754, 755, 756, 757, 758, 761, 762, 763, 764, 765, 767, 768, 769, 770, 771, 773, 777, 778, 779, 780, 781, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 798, 800, 801, 805, 806, 808, 809, 810, 811, 812, 813, 815, 817, 818, 820, 821, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 834, 835, 836, 837, 839, 843, 845, 846, 847, 848, 850, 854, 855, 856, 857, 859, 860, 861, 862, 864, 865, 868, 871, 872, 876, 877, 879, 881, 882, 883, 884, 889, 890, 891, 892, 895, 896, 898, 899, 900, 901, 903, 907, 908, 909, 910, 912, 914, 916, 918, 919, 921, 923, 924, 925, 926, 927, 930, 931, 933, 934, 936, 938, 939, 940, 944, 945, 946, 948, 952, 953, 955, 956, 957, 959, 960, 961, 962, 964, 965, 966, 970, 971, 972, 975, 977, 980, 981, 982, 983, 986, 987, 991, 995, 997, 1000, 1013, 1015, 1020, 1030, 1031, 1032, 1033, 1034, 1045, 1067, 1090, 1116, 1117, 1118, 1180, 1220, 1241, 1250, 1251, 1254, 1295, 1305, 1325, 1335, 1345, 1360, 1387]\n",
      "target node:  425\n",
      "epoch time:  2.4108452796936035\n",
      "[378 129 120 121 122 123 124 125 126 127 128 130 118 131 132 133 134 135\n",
      " 136 137 138 139 119 117  94 105  96  97  98  99 100 101 102 103 104 106\n",
      " 116 107 108 109 110 111 112 113 114 115 140 141 142 176 167 168 169 170\n",
      " 171 172 173 174 175 177 143 178 179 180 181 182 183 184 185 186 166 165\n",
      " 164 163 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161 162  95  93 188  34  25  26  27  28  29  30  31  32  33  35  23\n",
      "  36  37  38  39  40  41  42  43  44  24  22  92  10   1   2   3   4   5\n",
      "   6   7   8   9  11  21  12  13  14  15  16  17  18  19  20  45  46  47\n",
      "  81  72  73  74  75  76  77  78  79  80  82  48  83  84  85  86  87  88\n",
      "  89  90  91  71  70  69  68  49  50  51  52  53  54  55  56  57  58  59\n",
      "  60  61  62  63  64  65  66  67 187 189 377 319 310 311 312 313 314 315\n",
      " 316 317 318 320 308 321 322 323 324 325 326 327 328 329 309 307 284 295\n",
      " 286 287 288 289 290 291 292 293 294 296 306 297 298 299 300 301 302 303\n",
      " 304 305 330 331 332 366 357 358 359 360 361 362 363 364 365 367 333 368\n",
      " 369 370 371 372 373 374 375 376 356 355 354 353 334 335 336 337 338 339\n",
      " 340 341 342 343 344 345 346 347 348 349 350 351 352 285 283 190 224 215\n",
      " 216 217 218 219 220 221 222 223 225 213 226 227 228 229 230 231 232 233\n",
      " 234 214 212 282 200 191 192 193 194 195 196 197 198 199 201 211 202 203\n",
      " 204 205 206 207 208 209 210 235 236 237 271 262 263 264 265 266 267 268\n",
      " 269 270 272 238 273 274 275 276 277 278 279 280 281 261 260 259 258 239\n",
      " 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257\n",
      "   0]\n",
      "0\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "truth node:  [0, 130, 131, 132, 133, 138, 139, 142, 143, 144, 145, 146, 355, 356, 357, 358, 359, 363, 364, 365, 369, 370, 371]\n",
      "acc:  0.0\n",
      "auc:  0.5\n",
      "mean acc:  0.19999999999999998\n",
      "mean auc:  0.5833333333333334\n",
      "\n",
      "index:  430\n",
      "0 label:  1\n",
      "node range:  [430, 0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 525, 19, 20, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 545, 35, 547, 37, 1053, 39, 41, 42, 43, 44, 45, 46, 49, 50, 53, 565, 56, 60, 62, 63, 65, 69, 70, 71, 73, 75, 77, 78, 81, 84, 85, 86, 91, 93, 95, 96, 99, 100, 101, 615, 104, 106, 107, 108, 110, 111, 113, 114, 626, 628, 117, 627, 121, 124, 126, 129, 131, 135, 142, 143, 144, 146, 151, 1175, 153, 1176, 1179, 159, 163, 164, 165, 167, 169, 174, 178, 180, 182, 186, 188, 190, 194, 707, 196, 200, 204, 206, 721, 210, 213, 214, 215, 225, 235, 238, 242, 1267, 1266, 1268, 250, 256, 771, 260, 261, 270, 275, 280, 1305, 1306, 1307, 1308, 1309, 285, 800, 295, 297, 298, 299, 315, 836, 876, 883, 886, 405, 918, 929, 418, 431, 432, 433, 434, 959]\n",
      "target node:  430\n",
      "epoch time:  1.042419672012329\n",
      "[161  40  58  57  56  55  54  53  52  51  50  49  48  47  46  45  44  43\n",
      "  42  59  60  61  71  78  77  76  75  74  73  72  70  62  69  68  67  66\n",
      "  65  64  63  41  39 160  38  17  16  15  14  13  12  11  10   9   8   7\n",
      "   6   5   4   3   2   1  18  19  20  30  37  36  35  34  33  32  31  29\n",
      "  21  28  27  26  25  24  23  22  79  80  81  82 139 138 137 136 135 134\n",
      " 133 132 131 130 129 128 127 126 125 124 123 140 141 142 152 159 158 157\n",
      " 156 155 154 153 151 143 150 149 148 147 146 145 144 122 121 120  91  98\n",
      "  97  96  95  94  93  92  90 100  89  88  87  86  85  84  83  99 101 119\n",
      " 111 118 117 116 115 114 113 112 110 102 109 108 107 106 105 104 103   0]\n",
      "0\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "truth node:  [0, 128, 137, 138, 139, 140, 141, 157, 158, 159, 160, 79, 80, 82, 94, 96, 97, 126, 127]\n",
      "acc:  0.0\n",
      "auc:  0.5\n",
      "mean acc:  0.17142857142857143\n",
      "mean auc:  0.5714285714285714\n",
      "\n",
      "index:  435\n",
      "0 label:  1\n",
      "node range:  [435, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 1045, 23, 24, 25, 1047, 1049, 28, 29, 30, 1046, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 49, 51, 56, 60, 62, 65, 66, 68, 69, 70, 73, 74, 75, 77, 78, 81, 84, 85, 86, 87, 91, 93, 94, 95, 605, 98, 100, 101, 102, 106, 107, 109, 110, 111, 113, 118, 123, 126, 128, 129, 131, 140, 143, 147, 151, 163, 164, 178, 186, 187, 190, 192, 193, 196, 198, 201, 210, 215, 728, 732, 225, 226, 231, 233, 236, 238, 240, 242, 755, 244, 246, 247, 248, 252, 256, 265, 269, 270, 277, 790, 283, 284, 299, 315, 320, 834, 836, 400, 921, 924, 944, 436, 437, 438, 439, 959, 977, 978, 994, 997]\n",
      "target node:  435\n",
      "epoch time:  1.1475520133972168\n",
      "[143 142  51  50  49  48  47  46  45  44  43  42  41  40  39  38  37  52\n",
      "  53  54  63  69  68  67  66  65  64  62  55  61  60  59  58  57  56  36\n",
      "  35  34   8  14  13  12  11  10   9   7  16   6   5   4   3   2   1  15\n",
      "  17  33  26  32  31  30  29  28  27  25  18  24  23  22  21  20  19  70\n",
      "  71  72 117 123 122 121 120 119 118 116 125 115 114 113 112 111 110 124\n",
      " 126 108 135 141 140 139 138 137 136 134 127 133 132 131 130 129 128 109\n",
      " 107  73  81  87  86  85  84  83  82  80  89  79  78  77  76  75  74  88\n",
      "  90 106  99 105 104 103 102 101 100  98  91  97  96  95  94  93  92   0]\n",
      "0\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "truth node:  [0, 135, 136, 137, 138, 22, 26, 27, 31]\n",
      "acc:  0.0\n",
      "auc:  0.5\n",
      "mean acc:  0.15\n",
      "mean auc:  0.5625\n",
      "\n",
      "index:  440\n",
      "0 label:  1\n",
      "node range:  [440, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 26, 27, 28, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 61, 62, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 84, 87, 88, 92, 94, 96, 97, 105, 106, 108, 109, 110, 112, 114, 118, 1143, 121, 122, 123, 125, 126, 128, 129, 132, 136, 137, 138, 143, 144, 145, 146, 147, 154, 155, 157, 158, 160, 161, 164, 165, 167, 680, 170, 172, 175, 176, 179, 184, 185, 187, 189, 190, 191, 701, 193, 707, 196, 199, 204, 208, 211, 215, 216, 734, 223, 1248, 225, 226, 228, 229, 230, 1255, 1257, 234, 236, 244, 248, 250, 254, 255, 259, 260, 262, 265, 266, 783, 272, 274, 276, 277, 789, 280, 282, 283, 284, 795, 287, 291, 293, 1320, 1321, 298, 299, 1322, 1324, 320, 836, 330, 853, 876, 393, 905, 917, 926, 935, 441, 442, 443, 444, 445, 460]\n",
      "target node:  440\n",
      "epoch time:  1.3439562320709229\n",
      "[  0 181 183 184 182  66 113  71 126 149  38  13  99 124  12 141  14  78\n",
      "  69 127  27 155  49   1  10 162  22 152  41  30 107 153 135  47 158  21\n",
      "  87  65 164  33 130 143  88  26  32 122 116  20 142   4  85 176  34 104\n",
      "  60  17 159  61 120 136 125  42  45 148   8  51 132 128  25  76  48 140\n",
      "  28 145  36   7 178  83  23 175   9  59  52 117 150 163  55  18  86 118\n",
      "  44 156  31  39 168  24  50  70  73  53  16  43  57  93  98 102   3  29\n",
      "  77  54 103 101  37  11 154 108 121 173 160  84  19 100  95 109  62 144\n",
      " 133 111  35  15  56  72 123 106  80  40  68 185  58 171 167  79 119 110\n",
      "   5 105 114 139 174 157   2 112 186 180  75  74  82  97   6  92  46  94\n",
      "  89 131  96 169 115  63 177 137 147 151 161 172 138 129  67  64  91 170\n",
      "  81  90 165 134 146 179 166]\n",
      "0\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "truth node:  [0, 165, 166, 169, 170, 181, 182, 183, 184]\n",
      "acc:  1.0\n",
      "auc:  1.0\n",
      "mean acc:  0.24444444444444446\n",
      "mean auc:  0.6111111111111112\n",
      "\n",
      "index:  445\n",
      "0 label:  1\n",
      "node range:  [445, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 532, 24, 25, 26, 28, 29, 30, 32, 38, 39, 43, 46, 47, 49, 50, 54, 55, 56, 60, 62, 66, 68, 73, 74, 77, 79, 80, 81, 84, 86, 87, 92, 94, 96, 100, 105, 107, 110, 111, 112, 114, 117, 119, 123, 124, 125, 131, 136, 137, 138, 145, 146, 147, 155, 156, 157, 160, 162, 164, 167, 170, 1195, 1196, 173, 174, 175, 1199, 182, 184, 185, 188, 190, 196, 199, 206, 208, 211, 213, 214, 215, 1240, 218, 1248, 225, 226, 227, 1252, 228, 224, 1255, 744, 1256, 1258, 1259, 236, 242, 244, 1271, 251, 253, 254, 1280, 258, 259, 260, 264, 265, 1292, 270, 272, 277, 279, 280, 283, 284, 288, 297, 1321, 299, 1339, 320, 853, 357, 896, 926, 440, 446, 447, 448, 449, 460, 475, 1009, 505]\n",
      "target node:  445\n",
      "epoch time:  1.0448155403137207\n",
      "[152  47  54  53  52  51  50  49  48  46  75  45  44  43  42  41  40  39\n",
      "  55  56  57  58  73  72  71  70  69  68  67  66  65  64  63  62  61  60\n",
      "  59  38  37  36  17  15  14  13  12  11  10   9   8   7   6   5   4   3\n",
      "   2   1  16  18  35  19  34  33  32  31  30  29  28  27  26  25  24  23\n",
      "  22  21  20  74  76 151 124 131 130 129 128 127 126 125 123  77 122 121\n",
      " 120 119 118 117 116 132 133 134 135 150 149 148 147 146 145 144 143 142\n",
      " 141 140 139 138 137 136 115 114 113  94  92  91  90  89  88  87  86  85\n",
      "  84  83  82  81  80  79  78  93  95 112  96 111 110 109 108 107 106 105\n",
      " 104 103 102 101 100  99  98  97   0]\n",
      "0\n",
      "145\n",
      "147\n",
      "148\n",
      "146\n",
      "truth node:  [0, 108, 110, 111, 80, 145, 81, 147, 148, 85, 112, 146]\n",
      "acc:  0.0\n",
      "auc:  0.5\n",
      "mean acc:  0.22000000000000003\n",
      "mean auc:  0.6\n",
      "\n",
      "index:  450\n",
      "0 label:  1\n",
      "node range:  [450, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 16, 17, 19, 20, 22, 26, 1055, 32, 33, 34, 35, 37, 39, 41, 46, 47, 53, 54, 57, 61, 62, 63, 65, 66, 67, 72, 74, 77, 80, 82, 89, 90, 99, 102, 105, 108, 133, 140, 142, 144, 149, 151, 153, 164, 169, 171, 172, 176, 178, 179, 183, 706, 708, 710, 201, 716, 205, 718, 722, 723, 728, 729, 218, 223, 736, 738, 739, 234, 751, 754, 246, 1275, 1276, 253, 1277, 1279, 766, 259, 267, 274, 278, 281, 286, 1317, 298, 305, 833, 851, 852, 858, 889, 905, 395, 910, 912, 916, 410, 942, 949, 451, 452, 453, 454, 465, 984]\n",
      "target node:  450\n",
      "epoch time:  0.7828836441040039\n",
      "[117  43  31  32  33  34  35  36  37  38  39  40  41  42  44  29  45  46\n",
      "  47  48  49  50  51  52  53  54  55  56  30  28 116  13   1   2   3   4\n",
      "   5   6   7   8   9  10  11  12  14  27  15  16  17  18  19  20  21  22\n",
      "  23  24  25  26  57  58  59 102  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 103  60 104 105 106 107 108 109 110 111 112 113 114 115  89  88\n",
      "  87  86  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76\n",
      "  77  78  79  80  81  82  83  84  85   0]\n",
      "0\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "truth node:  [0, 112, 113, 114, 115, 84, 85, 87, 88]\n",
      "acc:  0.0\n",
      "auc:  0.5\n",
      "mean acc:  0.2\n",
      "mean auc:  0.5909090909090909\n",
      "\n",
      "index:  455\n",
      "0 label:  1\n",
      "node range:  [455, 0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 535, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 41, 43, 45, 46, 47, 48, 49, 51, 52, 53, 60, 61, 63, 66, 67, 69, 71, 72, 75, 76, 77, 78, 81, 82, 84, 86, 91, 93, 95, 99, 101, 104, 108, 110, 111, 114, 116, 23, 118, 119, 120, 121, 630, 123, 124, 632, 126, 127, 633, 132, 133, 136, 141, 142, 144, 146, 155, 157, 159, 163, 164, 166, 169, 170, 174, 180, 181, 191, 194, 197, 204, 205, 206, 209, 210, 213, 214, 224, 225, 235, 240, 241, 243, 249, 255, 256, 264, 268, 269, 1294, 272, 278, 279, 280, 282, 286, 287, 293, 295, 1320, 1321, 297, 1323, 298, 299, 1322, 1324, 400, 425, 456, 457, 458, 459]\n",
      "target node:  455\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-65eadab02ea5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mnode_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'node range: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mnode_sort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_subgraph_explain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_sort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/nightknight/新加卷/git/hierarchcal-gnn-interpretations/explain.py\u001b[0m in \u001b[0;36mprint_subgraph_explain\u001b[0;34m(dataset, model, idx, class_idx, visible, figsize, node_range, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mbegin_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mclass_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCD_explain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;31m#print(class_score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbegin_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/nightknight/新加卷/git/hierarchcal-gnn-interpretations/explain.py\u001b[0m in \u001b[0;36mCD_explain\u001b[0;34m(model, dataset, idx, mask_node_list, node_range, target_node)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# forward to explain according to mask list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target node: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mclass_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclass_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/nightknight/新加卷/git/hierarchcal-gnn-interpretations/explain.py\u001b[0m in \u001b[0;36mget_score\u001b[0;34m(model, data, input_mask_list, softmax, target_node)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmask_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mBinary_mask_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCD_explain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;31m#print(preds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m#print(data.y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/nightknight/新加卷/git/hierarchcal-gnn-interpretations/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, CD_explain, mask_index, Intermediate)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCD_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/nightknight/新加卷/git/hierarchcal-gnn-interpretations/CD_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             rel = self.propagate(edge_index, x=rel, edge_weight=edge_weight,\n\u001b[0;32m--> 151\u001b[0;31m                                 size=None)\n\u001b[0m\u001b[1;32m    152\u001b[0m             irrel = self.propagate(edge_index, x=irrel, edge_weight=edge_weight,\n\u001b[1;32m    153\u001b[0m                                 size=None) \n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0maggr_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aggregate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoll_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mupdate_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'update'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoll_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             return scatter(inputs, index, dim=self.node_dim, dim_size=dim_size,\n\u001b[0;32m--> 288\u001b[0;31m                            reduce=self.aggr)\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage_and_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_t\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/graph/lib/python3.7/site-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, out, dim_size, reduce)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \"\"\"\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sum'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'add'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "auc_list = []\n",
    "\n",
    "dataset.subgraph = False\n",
    "dataset.remap = False\n",
    "dataset.setting=1\n",
    "load_model = gcn_model\n",
    "#load_model = torch.load('./checkpoint/community_temp')\n",
    "#load_model = torch.load('./checkpoint/gcn_mix').to('cuda')\n",
    "load_model.eval()\n",
    "\n",
    "all_node_label = []\n",
    "all_node_color = []\n",
    "for idx in dataset.allnodes:\n",
    "    #idx = 313\n",
    "    print('\\nindex: ', idx)\n",
    "    sub_adj,sub_feature, sub_label,sub_edge_label_matrix = dataset.get_subgraph(idx)\n",
    "    #truth_node = np.where(sub_label[:,1] == True)[0]\n",
    "    truth_node = list(get_node_set(sub_edge_label_matrix))\n",
    "    \n",
    "    class_idx = np.argmax(sub_label[0],axis=-1)\n",
    "    print('0 label: ', class_idx)\n",
    "    node_range = dataset.extractor.nodes\n",
    "    print('node range: ', node_range)\n",
    "    node_sort, node_color = print_subgraph_explain(dataset = dataset, model = load_model, idx = 0, class_idx = class_idx, visible = False, figsize = (12,9), node_range = node_range)\n",
    "    print(node_sort)\n",
    "\n",
    "    node_label = np.array([0] * sub_label.shape[0])\n",
    "    #node_label[list(truth_node)] = 1\n",
    "    # find truth node, far node is not real truth\n",
    "    for n in truth_node:\n",
    "        if abs((node_range[n] - node_range[0])) <= 8:\n",
    "            node_label[n] = 1\n",
    "            print(n)\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(node_label, node_color)\n",
    "    except:\n",
    "        print('foo')\n",
    "        auc = 1.0\n",
    "\n",
    "    print(\"truth node: \", truth_node)\n",
    "    #print(node_sort)\n",
    "    acc = len([node for node in node_sort[:5] if node in truth_node])/5\n",
    "    acc_list.append(acc)\n",
    "    auc_list.append(auc)\n",
    "    #all_node_label.extend(node_label)\n",
    "    #all_node_color.extend(node_color)\n",
    "    print('acc: ', acc)\n",
    "    print('auc: ', auc)\n",
    "    #if acc == 0.0:\n",
    "    #    print(node_sort)\n",
    "    #    print_explain(dataset, load_model, idx, class_idx = np.argmax(sub_label[0],axis=-1), visible = True)\n",
    "    print('mean acc: ', np.mean(acc_list))\n",
    "    print('mean auc: ', np.mean(auc_list))\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}